{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28275e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSEED = 2\\ntorch.manual_seed(SEED)\\nrandom.seed(SEED)\\u3000\\u3000 \\ntorch.cuda.manual_seed(SEED) \\ntorch.backends.cudnn.deterministic = True\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following pytorch code is based on\n",
    "# https://github.com/snowbbbb/code-for-Global-Convergence-of-Over-parameterized-Deep-Equilibrium-Models\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cmath\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "'''\n",
    "SEED = 2\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)　　 \n",
    "torch.cuda.manual_seed(SEED) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "70f1a889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "root_train = '/Users/lantruong/Dataset/CIFAR10/'\n",
    "trainTransform = transforms.Compose([transforms.Grayscale(1),\n",
    "                                transforms.ToTensor()])\n",
    "                               \n",
    "trainset_full = torchvision.datasets.CIFAR10(root_train, train = True, download = True, transform = trainTransform)\n",
    "\n",
    "idx = (trainset_full.targets=='airplane')\n",
    "trainset_full.targets = trainset_full.targets[idx]\n",
    "trainset_full.data = trainset_full.data[idx]\n",
    "trainset0 = torch.utils.data.Subset(trainset_full, range(500))\n",
    "\n",
    "trainset_full = torchvision.datasets.CIFAR10(root_train, train = True, download = True, transform = trainTransform)\n",
    "\n",
    "idx = (trainset_full.targets=='automobile')\n",
    "trainset_full.targets = trainset_full.targets[idx]\n",
    "trainset_full.data = trainset_full.data[idx]\n",
    "trainset1 = torch.utils.data.Subset(trainset_full, range(500))\n",
    "\n",
    "trainset=torch.utils.data.ConcatDataset([trainset0,trainset1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "06b7bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Download and define the training set.\n",
    "\n",
    "samplesize = 10000\n",
    "netDepth = 2\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset_full, batch_size=len(trainset), shuffle=True)\n",
    "batchsize=1000\n",
    "dataiter = iter(trainloader)\n",
    "images, labels =next(dataiter)\n",
    "images=torch.flatten(images,start_dim=1)\n",
    "images = F.normalize(images, p=2, dim=1)\n",
    "allLabel =torch.rand(1000)\n",
    "train_ids = TensorDataset(images, allLabel)\n",
    "trainloader = torch.utils.data.DataLoader(dataset=train_ids, batch_size=len(train_ids), shuffle=True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "output_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b49e838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FPiter(f, x0, m=5, lam=1e-4, max_iter=50, tol=1e-2, beta=1.0):\n",
    "    #Anderson acceleration for fixed point iteration\n",
    "    bsz, D = x0.shape\n",
    "    X = torch.zeros(bsz, m, D, dtype=x0.dtype, device=x0.device)\n",
    "    F = torch.zeros(bsz, m, D, dtype=x0.dtype, device=x0.device)\n",
    "    X[:, 0], F[:, 0] = x0.view(bsz, -1), f(x0).view(bsz, -1)\n",
    "    X[:, 1], F[:, 1] = F[:, 0], f(F[:, 0].view_as(x0)).view(bsz, -1)\n",
    "\n",
    "    H = torch.zeros(bsz, m + 1, m + 1, dtype=x0.dtype, device=x0.device)\n",
    "    H[:, 0, 1:] = H[:, 1:, 0] = 1\n",
    "    y = torch.zeros(bsz, m + 1, 1, dtype=x0.dtype, device=x0.device)\n",
    "    y[:, 0] = 1\n",
    "\n",
    "    res = []\n",
    "    for k in range(2, max_iter):\n",
    "        n = min(k, m)\n",
    "        G = F[:, :n] - X[:, :n]\n",
    "        H[:, 1:n + 1, 1:n + 1] = torch.bmm(G, G.transpose(1, 2)) + lam * torch.eye(n, dtype=x0.dtype, device=x0.device)[\n",
    "            None]\n",
    "        alpha = torch.linalg.solve(H[:, :n + 1, :n + 1],y[:, :n + 1])[:, 1:n + 1, 0]  # (bsz x n)\n",
    "\n",
    "        X[:, k % m] = beta * (alpha[:, None] @ F[:, :n])[:, 0] + (1 - beta) * (alpha[:, None] @ X[:, :n])[:, 0]\n",
    "        F[:, k % m] = f(X[:, k % m].view_as(x0)).view(bsz, -1)\n",
    "        res.append((F[:, k % m] - X[:, k % m]).norm().item() / (1e-5 + F[:, k % m].norm().item()))\n",
    "        if (res[-1] < tol):\n",
    "            break\n",
    "    return X[:, k % m].view_as(x0), res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8687beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, width,Wstd):\n",
    "        super(Net, self).__init__()\n",
    "        self.wmatrix=nn.Linear(width,width)\n",
    "        torch.nn.init.normal_(self.wmatrix.weight, mean=0, std=Wstd)   \n",
    "\n",
    "\n",
    "    def forward(self, z, x):\n",
    "        y = F.sigmoid(self.wmatrix(z)+x) * (math.sqrt(1 / width))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "045f39ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DEQFixedPoint(nn.Module):\n",
    "    def __init__(self, f, solver, **kwargs):\n",
    "        super().__init__()\n",
    "        self.f = f\n",
    "        self.solver = solver\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def forward(self, x):\n",
    "        # compute forward pass and re-engage autograd tape\n",
    "        with torch.no_grad():\n",
    "            z, self.forward_res = self.solver(lambda z: self.f(z, x), torch.zeros_like(x), **self.kwargs)\n",
    "        z = self.f(z, x)\n",
    "\n",
    "        # set up Jacobian vector product (without additional forward calls)\n",
    "        z0 = z.clone().detach().requires_grad_()\n",
    "        f0 = self.f(z0, x)\n",
    "\n",
    "        def backward_hook(grad):\n",
    "            g, self.backward_res = self.solver(lambda y: autograd.grad(f0, z0, y, retain_graph=True)[0] + grad,\n",
    "                                               grad, **self.kwargs)\n",
    "            return g\n",
    "\n",
    "        z.register_hook(backward_hook)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "13ea1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jacobian(model, x):\n",
    "    nc = x.size()[0]\n",
    "    ny = x.size()[2]\n",
    "    nx = x.size()[1]\n",
    "    noutputs = 10\n",
    "    x = x.reshape(nc * nx * ny)\n",
    "    x = x.repeat(noutputs, 1)\n",
    "    x.requires_grad_(True)\n",
    "    y = model(x.reshape(noutputs, nc, nx, ny))\n",
    "    y.backward(torch.eye(noutputs).to(device))\n",
    "    return x.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0ccdbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_train(epochs, lr, width, Wstd):\n",
    "    ######################################################################\n",
    "    # Model setup\n",
    "    f = Net(width, Wstd)\n",
    "    linear_input = nn.Linear(1 *  32 * 32, width)\n",
    "    linear_output = nn.Linear(width, output_size)\n",
    "    torch.nn.init.normal_(linear_input.weight, mean=0, std=1)\n",
    "    torch.nn.init.normal_(linear_output.weight, mean=0, std=1)\n",
    "    model = nn.Sequential(linear_input,\n",
    "                          DEQFixedPoint(f, FPiter, tol=1e-2, max_iter=25),\n",
    "                          linear_output).to(device)\n",
    "    model.to(device);\n",
    "    newmodel = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "    ######################################################################\n",
    "    # Define criterion and optimizer\n",
    "    criterion = torch.nn.MSELoss(reduce=True, size_average=False)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.0)\n",
    "\n",
    "  \n",
    "    ###################################2###################################\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    loss_plot=[]\n",
    "    \n",
    "  \n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        epoch_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        log_interval = 100\n",
    "        train_acc = 0.0\n",
    "        for batch, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            if hasattr(torch.cuda, 'empty_cache'):\n",
    "               torch.cuda.empty_cache()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            outVector=newmodel(inputs)\n",
    "            if width <1000:\n",
    "               matrixA = torch.mm(outVector.T, outVector)\n",
    "            else:\n",
    "               matrixA = torch.mm(outVector, outVector.T)\n",
    "            (lambdamin,lambdaVec) = torch.linalg.eig(matrixA)\n",
    "            print(\"lambda_min\", lambdamin[-1])\n",
    "            WMatrix = f.wmatrix.weight * (math.sqrt(1 / width))\n",
    "            matrixA = torch.mm(WMatrix.T, WMatrix)\n",
    "            (singmax, singularVec) = torch.linalg.eig(matrixA)\n",
    "            print(\"singular_max\", torch.sqrt(singmax[0]))\n",
    "\n",
    "            loss= criterion(outputs.reshape(labels.shape),labels.float())\n",
    "            if hasattr(torch.cuda, 'empty_cache'): \n",
    "               torch.cuda.empty_cache()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        cur_loss = running_loss / (batch + 1)\n",
    "        print('| end of epoch {:3d} | time / epoch {:5.2f}s | loss {:5.2f} '.format\n",
    "              (epoch + 1, (time.time() - epoch_start_time), cur_loss))\n",
    "        loss_plot.append(cur_loss)  \n",
    "        running_loss = 0.\n",
    "    return loss_plot   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b3c26636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.6747e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch   1 | time / epoch 34.34s | loss 891.91 \n",
      "lambda_min tensor(2.6013e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch   2 | time / epoch 34.12s | loss 501.23 \n",
      "lambda_min tensor(2.4122e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch   3 | time / epoch 33.96s | loss 301.37 \n",
      "lambda_min tensor(2.2300e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch   4 | time / epoch 33.79s | loss 199.12 \n",
      "lambda_min tensor(2.1412e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch   5 | time / epoch 34.09s | loss 146.81 \n",
      "lambda_min tensor(2.3913e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch   6 | time / epoch 34.07s | loss 120.05 \n",
      "lambda_min tensor(6.2518e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch   7 | time / epoch 34.02s | loss 106.36 \n",
      "lambda_min tensor(2.2519e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch   8 | time / epoch 34.13s | loss 99.36 \n",
      "lambda_min tensor(4.6772e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch   9 | time / epoch 34.04s | loss 95.77 \n",
      "lambda_min tensor(2.7191e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  10 | time / epoch 34.01s | loss 93.94 \n",
      "lambda_min tensor(2.7162e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  11 | time / epoch 34.00s | loss 93.00 \n",
      "lambda_min tensor(4.1124e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  12 | time / epoch 33.83s | loss 92.51 \n",
      "lambda_min tensor(2.4792e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  13 | time / epoch 34.08s | loss 92.27 \n",
      "lambda_min tensor(2.0749e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  14 | time / epoch 34.02s | loss 92.14 \n",
      "lambda_min tensor(3.0741e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  15 | time / epoch 34.29s | loss 92.07 \n",
      "lambda_min tensor(2.0534e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  16 | time / epoch 33.89s | loss 92.04 \n",
      "lambda_min tensor(2.3332e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  17 | time / epoch 33.89s | loss 92.02 \n",
      "lambda_min tensor(2.6744e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  18 | time / epoch 33.90s | loss 92.00 \n",
      "lambda_min tensor(2.1216e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  19 | time / epoch 33.88s | loss 92.00 \n",
      "lambda_min tensor(2.1601e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  20 | time / epoch 33.93s | loss 91.99 \n",
      "lambda_min tensor(2.0633e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  21 | time / epoch 33.98s | loss 91.99 \n",
      "lambda_min tensor(3.9005e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  22 | time / epoch 34.13s | loss 91.99 \n",
      "lambda_min tensor(2.6003e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  23 | time / epoch 34.49s | loss 91.98 \n",
      "lambda_min tensor(2.2600e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  24 | time / epoch 34.17s | loss 91.98 \n",
      "lambda_min tensor(2.0656e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  25 | time / epoch 34.28s | loss 91.98 \n",
      "lambda_min tensor(2.0171e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  26 | time / epoch 34.05s | loss 91.98 \n",
      "lambda_min tensor(1.9126e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  27 | time / epoch 34.01s | loss 91.97 \n",
      "lambda_min tensor(2.2974e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  28 | time / epoch 33.87s | loss 91.97 \n",
      "lambda_min tensor(2.1965e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  29 | time / epoch 33.91s | loss 91.97 \n",
      "lambda_min tensor(2.1941e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  30 | time / epoch 33.67s | loss 91.97 \n",
      "lambda_min tensor(2.0229e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  31 | time / epoch 33.82s | loss 91.96 \n",
      "lambda_min tensor(2.5127e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  32 | time / epoch 33.83s | loss 91.96 \n",
      "lambda_min tensor(2.7649e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  33 | time / epoch 33.58s | loss 91.96 \n",
      "lambda_min tensor(2.0643e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  34 | time / epoch 34.03s | loss 91.96 \n",
      "lambda_min tensor(3.1520e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  35 | time / epoch 33.87s | loss 91.95 \n",
      "lambda_min tensor(3.1199e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  36 | time / epoch 33.88s | loss 91.95 \n",
      "lambda_min tensor(2.3321e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  37 | time / epoch 33.93s | loss 91.95 \n",
      "lambda_min tensor(2.4003e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  38 | time / epoch 34.20s | loss 91.95 \n",
      "lambda_min tensor(2.4866e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  39 | time / epoch 33.71s | loss 91.94 \n",
      "lambda_min tensor(2.0836e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  40 | time / epoch 33.92s | loss 91.94 \n",
      "lambda_min tensor(2.9723e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  41 | time / epoch 33.77s | loss 91.94 \n",
      "lambda_min tensor(2.2159e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  42 | time / epoch 33.79s | loss 91.94 \n",
      "lambda_min tensor(2.0453e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  43 | time / epoch 33.69s | loss 91.93 \n",
      "lambda_min tensor(2.0177e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  44 | time / epoch 33.63s | loss 91.93 \n",
      "lambda_min tensor(2.5854e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  45 | time / epoch 33.84s | loss 91.93 \n",
      "lambda_min tensor(2.8757e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  46 | time / epoch 34.09s | loss 91.93 \n",
      "lambda_min tensor(2.2468e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  47 | time / epoch 33.65s | loss 91.92 \n",
      "lambda_min tensor(2.5297e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  48 | time / epoch 33.76s | loss 91.92 \n",
      "lambda_min tensor(2.0788e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  49 | time / epoch 34.39s | loss 91.92 \n",
      "lambda_min tensor(2.7588e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  50 | time / epoch 34.03s | loss 91.92 \n",
      "lambda_min tensor(2.3060e-05-2.1716e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  51 | time / epoch 33.65s | loss 91.91 \n",
      "lambda_min tensor(2.3681e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  52 | time / epoch 33.78s | loss 91.91 \n",
      "lambda_min tensor(1.9223e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  53 | time / epoch 33.79s | loss 91.91 \n",
      "lambda_min tensor(2.7758e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  54 | time / epoch 33.83s | loss 91.91 \n",
      "lambda_min tensor(2.6083e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  55 | time / epoch 33.71s | loss 91.90 \n",
      "lambda_min tensor(2.0700e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  56 | time / epoch 33.63s | loss 91.90 \n",
      "lambda_min tensor(2.3985e-05-4.9666e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  57 | time / epoch 33.80s | loss 91.90 \n",
      "lambda_min tensor(2.4276e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  58 | time / epoch 34.01s | loss 91.90 \n",
      "lambda_min tensor(2.6149e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  59 | time / epoch 33.71s | loss 91.89 \n",
      "lambda_min tensor(2.3533e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  60 | time / epoch 33.65s | loss 91.89 \n",
      "lambda_min tensor(1.9027e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  61 | time / epoch 33.60s | loss 91.89 \n",
      "lambda_min tensor(2.0132e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  62 | time / epoch 33.71s | loss 91.89 \n",
      "lambda_min tensor(2.0960e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  63 | time / epoch 33.73s | loss 91.88 \n",
      "lambda_min tensor(2.3002e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  64 | time / epoch 33.63s | loss 91.88 \n",
      "lambda_min tensor(2.4559e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  65 | time / epoch 33.53s | loss 91.88 \n",
      "lambda_min tensor(2.8667e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  66 | time / epoch 33.89s | loss 91.88 \n",
      "lambda_min tensor(2.5031e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  67 | time / epoch 33.76s | loss 91.87 \n",
      "lambda_min tensor(3.7842e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  68 | time / epoch 33.59s | loss 91.87 \n",
      "lambda_min tensor(2.6348e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  69 | time / epoch 33.75s | loss 91.87 \n",
      "lambda_min tensor(2.9024e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  70 | time / epoch 33.86s | loss 91.87 \n",
      "lambda_min tensor(2.1747e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  71 | time / epoch 33.77s | loss 91.86 \n",
      "lambda_min tensor(2.0306e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  72 | time / epoch 33.86s | loss 91.86 \n",
      "lambda_min tensor(2.1350e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  73 | time / epoch 33.78s | loss 91.86 \n",
      "lambda_min tensor(4.2155e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  74 | time / epoch 33.79s | loss 91.86 \n",
      "lambda_min tensor(1.9058e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  75 | time / epoch 33.88s | loss 91.85 \n",
      "lambda_min tensor(4.9505e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  76 | time / epoch 33.77s | loss 91.85 \n",
      "lambda_min tensor(2.2027e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  77 | time / epoch 33.72s | loss 91.85 \n",
      "lambda_min tensor(2.2591e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  78 | time / epoch 33.69s | loss 91.85 \n",
      "lambda_min tensor(2.3497e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  79 | time / epoch 33.77s | loss 91.85 \n",
      "lambda_min tensor(3.7258e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  80 | time / epoch 33.58s | loss 91.84 \n",
      "lambda_min tensor(2.0666e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  81 | time / epoch 33.63s | loss 91.84 \n",
      "lambda_min tensor(2.0649e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  82 | time / epoch 33.91s | loss 91.84 \n",
      "lambda_min tensor(2.2304e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  83 | time / epoch 33.82s | loss 91.84 \n",
      "lambda_min tensor(2.3635e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  84 | time / epoch 33.84s | loss 91.83 \n",
      "lambda_min tensor(2.0702e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  85 | time / epoch 33.81s | loss 91.83 \n",
      "lambda_min tensor(1.9634e-05-6.5396e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  86 | time / epoch 34.21s | loss 91.83 \n",
      "lambda_min tensor(2.4589e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  87 | time / epoch 33.92s | loss 91.83 \n",
      "lambda_min tensor(2.3273e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  88 | time / epoch 33.59s | loss 91.82 \n",
      "lambda_min tensor(1.9928e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  89 | time / epoch 33.82s | loss 91.82 \n",
      "lambda_min tensor(5.0036e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  90 | time / epoch 33.90s | loss 91.82 \n",
      "lambda_min tensor(2.3111e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  91 | time / epoch 33.58s | loss 91.82 \n",
      "lambda_min tensor(2.3168e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  92 | time / epoch 33.79s | loss 91.81 \n",
      "lambda_min tensor(2.4029e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  93 | time / epoch 33.81s | loss 91.81 \n",
      "lambda_min tensor(1.8021e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  94 | time / epoch 33.81s | loss 91.81 \n",
      "lambda_min tensor(2.3560e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  95 | time / epoch 33.63s | loss 91.81 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.3334e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  96 | time / epoch 33.76s | loss 91.80 \n",
      "lambda_min tensor(2.5287e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  97 | time / epoch 33.75s | loss 91.80 \n",
      "lambda_min tensor(1.8928e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  98 | time / epoch 34.01s | loss 91.80 \n",
      "lambda_min tensor(2.2395e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch  99 | time / epoch 33.80s | loss 91.80 \n",
      "lambda_min tensor(4.0568e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 100 | time / epoch 34.08s | loss 91.79 \n",
      "lambda_min tensor(2.6472e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 101 | time / epoch 33.99s | loss 91.79 \n",
      "lambda_min tensor(2.7200e-05-3.1293e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 102 | time / epoch 33.54s | loss 91.79 \n",
      "lambda_min tensor(2.3164e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 103 | time / epoch 33.90s | loss 91.79 \n",
      "lambda_min tensor(2.5899e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 104 | time / epoch 33.80s | loss 91.78 \n",
      "lambda_min tensor(2.7737e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 105 | time / epoch 33.98s | loss 91.78 \n",
      "lambda_min tensor(2.5510e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 106 | time / epoch 34.07s | loss 91.78 \n",
      "lambda_min tensor(2.5224e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 107 | time / epoch 33.74s | loss 91.78 \n",
      "lambda_min tensor(2.1341e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 108 | time / epoch 33.80s | loss 91.78 \n",
      "lambda_min tensor(3.8874e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 109 | time / epoch 34.36s | loss 91.77 \n",
      "lambda_min tensor(2.0828e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 110 | time / epoch 33.37s | loss 91.77 \n",
      "lambda_min tensor(2.5395e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 111 | time / epoch 33.84s | loss 91.77 \n",
      "lambda_min tensor(2.2841e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 112 | time / epoch 34.28s | loss 91.77 \n",
      "lambda_min tensor(2.1180e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 113 | time / epoch 33.71s | loss 91.76 \n",
      "lambda_min tensor(2.6812e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 114 | time / epoch 33.58s | loss 91.76 \n",
      "lambda_min tensor(2.4306e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 115 | time / epoch 33.74s | loss 91.76 \n",
      "lambda_min tensor(2.5137e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 116 | time / epoch 34.03s | loss 91.76 \n",
      "lambda_min tensor(2.0422e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 117 | time / epoch 33.95s | loss 91.75 \n",
      "lambda_min tensor(2.1081e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 118 | time / epoch 34.30s | loss 91.75 \n",
      "lambda_min tensor(2.2954e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 119 | time / epoch 33.74s | loss 91.75 \n",
      "lambda_min tensor(2.0451e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 120 | time / epoch 33.78s | loss 91.75 \n",
      "lambda_min tensor(2.5661e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 121 | time / epoch 33.71s | loss 91.74 \n",
      "lambda_min tensor(2.5821e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 122 | time / epoch 33.88s | loss 91.74 \n",
      "lambda_min tensor(2.0985e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 123 | time / epoch 33.91s | loss 91.74 \n",
      "lambda_min tensor(2.4637e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 124 | time / epoch 33.85s | loss 91.74 \n",
      "lambda_min tensor(2.2088e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 125 | time / epoch 33.63s | loss 91.74 \n",
      "lambda_min tensor(2.1428e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 126 | time / epoch 33.85s | loss 91.73 \n",
      "lambda_min tensor(1.9507e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 127 | time / epoch 33.84s | loss 91.73 \n",
      "lambda_min tensor(2.1627e-05-2.0671e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 128 | time / epoch 33.67s | loss 91.73 \n",
      "lambda_min tensor(2.0274e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 129 | time / epoch 33.66s | loss 91.73 \n",
      "lambda_min tensor(2.0444e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 130 | time / epoch 34.50s | loss 91.72 \n",
      "lambda_min tensor(2.5274e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 131 | time / epoch 33.68s | loss 91.72 \n",
      "lambda_min tensor(2.1638e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 132 | time / epoch 34.07s | loss 91.72 \n",
      "lambda_min tensor(2.7576e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 133 | time / epoch 33.91s | loss 91.72 \n",
      "lambda_min tensor(2.8068e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 134 | time / epoch 33.67s | loss 91.71 \n",
      "lambda_min tensor(1.9912e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 135 | time / epoch 33.71s | loss 91.71 \n",
      "lambda_min tensor(1.9523e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 136 | time / epoch 33.78s | loss 91.71 \n",
      "lambda_min tensor(2.4331e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 137 | time / epoch 33.80s | loss 91.71 \n",
      "lambda_min tensor(2.2829e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 138 | time / epoch 33.59s | loss 91.70 \n",
      "lambda_min tensor(2.3420e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 139 | time / epoch 33.78s | loss 91.70 \n",
      "lambda_min tensor(2.7656e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 140 | time / epoch 34.01s | loss 91.70 \n",
      "lambda_min tensor(2.2542e-05-2.1519e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 141 | time / epoch 33.83s | loss 91.70 \n",
      "lambda_min tensor(1.7653e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 142 | time / epoch 34.03s | loss 91.70 \n",
      "lambda_min tensor(2.2966e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 143 | time / epoch 34.22s | loss 91.69 \n",
      "lambda_min tensor(2.9423e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 144 | time / epoch 33.73s | loss 91.69 \n",
      "lambda_min tensor(2.6711e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 145 | time / epoch 33.71s | loss 91.69 \n",
      "lambda_min tensor(2.1331e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 146 | time / epoch 33.76s | loss 91.69 \n",
      "lambda_min tensor(2.2668e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 147 | time / epoch 33.70s | loss 91.68 \n",
      "lambda_min tensor(2.2721e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 148 | time / epoch 33.77s | loss 91.68 \n",
      "lambda_min tensor(1.9956e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 149 | time / epoch 33.58s | loss 91.68 \n",
      "lambda_min tensor(2.8521e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 150 | time / epoch 34.28s | loss 91.68 \n",
      "lambda_min tensor(1.9341e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 151 | time / epoch 33.88s | loss 91.67 \n",
      "lambda_min tensor(2.7775e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 152 | time / epoch 33.75s | loss 91.67 \n",
      "lambda_min tensor(2.0383e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 153 | time / epoch 33.56s | loss 91.67 \n",
      "lambda_min tensor(2.2355e-05-3.0667e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 154 | time / epoch 34.03s | loss 91.67 \n",
      "lambda_min tensor(3.8731e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 155 | time / epoch 33.96s | loss 91.66 \n",
      "lambda_min tensor(4.9122e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 156 | time / epoch 33.69s | loss 91.66 \n",
      "lambda_min tensor(2.4137e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 157 | time / epoch 34.00s | loss 91.66 \n",
      "lambda_min tensor(2.3654e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 158 | time / epoch 33.61s | loss 91.66 \n",
      "lambda_min tensor(2.6449e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 159 | time / epoch 33.75s | loss 91.66 \n",
      "lambda_min tensor(2.4656e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 160 | time / epoch 33.83s | loss 91.65 \n",
      "lambda_min tensor(2.5091e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 161 | time / epoch 33.69s | loss 91.65 \n",
      "lambda_min tensor(2.3091e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 162 | time / epoch 33.82s | loss 91.65 \n",
      "lambda_min tensor(2.3396e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 163 | time / epoch 33.95s | loss 91.65 \n",
      "lambda_min tensor(2.8392e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 164 | time / epoch 33.64s | loss 91.64 \n",
      "lambda_min tensor(2.2881e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 165 | time / epoch 34.22s | loss 91.64 \n",
      "lambda_min tensor(2.4776e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 166 | time / epoch 33.87s | loss 91.64 \n",
      "lambda_min tensor(1.7832e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 167 | time / epoch 33.73s | loss 91.64 \n",
      "lambda_min tensor(4.9368e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 168 | time / epoch 34.12s | loss 91.63 \n",
      "lambda_min tensor(3.0491e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 169 | time / epoch 33.77s | loss 91.63 \n",
      "lambda_min tensor(2.0849e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 170 | time / epoch 33.87s | loss 91.63 \n",
      "lambda_min tensor(2.1126e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 171 | time / epoch 33.67s | loss 91.63 \n",
      "lambda_min tensor(2.4080e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 172 | time / epoch 33.84s | loss 91.63 \n",
      "lambda_min tensor(2.4154e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 173 | time / epoch 33.85s | loss 91.62 \n",
      "lambda_min tensor(2.1136e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 174 | time / epoch 33.88s | loss 91.62 \n",
      "lambda_min tensor(2.0586e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 175 | time / epoch 33.98s | loss 91.62 \n",
      "lambda_min tensor(2.3519e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 176 | time / epoch 34.11s | loss 91.62 \n",
      "lambda_min tensor(2.3503e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 177 | time / epoch 33.72s | loss 91.61 \n",
      "lambda_min tensor(2.5515e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 178 | time / epoch 33.65s | loss 91.61 \n",
      "lambda_min tensor(2.3066e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 179 | time / epoch 33.78s | loss 91.61 \n",
      "lambda_min tensor(2.2542e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 180 | time / epoch 33.86s | loss 91.61 \n",
      "lambda_min tensor(2.2861e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 181 | time / epoch 34.00s | loss 91.60 \n",
      "lambda_min tensor(2.6753e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 182 | time / epoch 33.58s | loss 91.60 \n",
      "lambda_min tensor(2.4891e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 183 | time / epoch 33.56s | loss 91.60 \n",
      "lambda_min tensor(2.6969e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 184 | time / epoch 33.92s | loss 91.60 \n",
      "lambda_min tensor(2.3884e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 185 | time / epoch 33.87s | loss 91.60 \n",
      "lambda_min tensor(2.8795e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 186 | time / epoch 33.80s | loss 91.59 \n",
      "lambda_min tensor(2.5315e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 187 | time / epoch 33.75s | loss 91.59 \n",
      "lambda_min tensor(2.6452e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 188 | time / epoch 34.00s | loss 91.59 \n",
      "lambda_min tensor(2.0256e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 189 | time / epoch 33.61s | loss 91.59 \n",
      "lambda_min tensor(2.4665e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 190 | time / epoch 33.93s | loss 91.58 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.4126e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 191 | time / epoch 33.75s | loss 91.58 \n",
      "lambda_min tensor(2.4488e-05-6.6237e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 192 | time / epoch 33.89s | loss 91.58 \n",
      "lambda_min tensor(2.8550e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 193 | time / epoch 33.77s | loss 91.58 \n",
      "lambda_min tensor(2.4992e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 194 | time / epoch 34.11s | loss 91.58 \n",
      "lambda_min tensor(2.7429e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 195 | time / epoch 33.81s | loss 91.57 \n",
      "lambda_min tensor(2.1910e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 196 | time / epoch 33.75s | loss 91.57 \n",
      "lambda_min tensor(2.8009e-05-1.1117e-07j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 197 | time / epoch 34.06s | loss 91.57 \n",
      "lambda_min tensor(2.6705e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 198 | time / epoch 33.84s | loss 91.57 \n",
      "lambda_min tensor(4.4733e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 199 | time / epoch 33.89s | loss 91.56 \n",
      "lambda_min tensor(2.5045e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 200 | time / epoch 2865.05s | loss 91.56 \n",
      "lambda_min tensor(2.6357e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 201 | time / epoch 70.31s | loss 91.56 \n",
      "lambda_min tensor(2.8942e-05-1.4715e-07j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 202 | time / epoch 33.83s | loss 91.56 \n",
      "lambda_min tensor(2.8150e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 203 | time / epoch 33.91s | loss 91.55 \n",
      "lambda_min tensor(2.4226e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 204 | time / epoch 33.80s | loss 91.55 \n",
      "lambda_min tensor(2.0854e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 205 | time / epoch 34.03s | loss 91.55 \n",
      "lambda_min tensor(2.2557e-05-3.6833e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 206 | time / epoch 34.04s | loss 91.55 \n",
      "lambda_min tensor(2.1428e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 207 | time / epoch 33.78s | loss 91.55 \n",
      "lambda_min tensor(2.2743e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 208 | time / epoch 33.86s | loss 91.54 \n",
      "lambda_min tensor(3.0328e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 209 | time / epoch 33.98s | loss 91.54 \n",
      "lambda_min tensor(2.4218e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 210 | time / epoch 34.05s | loss 91.54 \n",
      "lambda_min tensor(1.9442e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 211 | time / epoch 33.89s | loss 91.54 \n",
      "lambda_min tensor(2.4606e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 212 | time / epoch 33.77s | loss 91.53 \n",
      "lambda_min tensor(2.2823e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 213 | time / epoch 33.66s | loss 91.53 \n",
      "lambda_min tensor(2.7312e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 214 | time / epoch 33.77s | loss 91.53 \n",
      "lambda_min tensor(2.0249e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 215 | time / epoch 33.85s | loss 91.53 \n",
      "lambda_min tensor(2.4370e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 216 | time / epoch 33.90s | loss 91.53 \n",
      "lambda_min tensor(2.7896e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 217 | time / epoch 34.05s | loss 91.52 \n",
      "lambda_min tensor(1.9969e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 218 | time / epoch 34.00s | loss 91.52 \n",
      "lambda_min tensor(2.2175e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 219 | time / epoch 34.28s | loss 91.52 \n",
      "lambda_min tensor(2.3626e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 220 | time / epoch 33.87s | loss 91.52 \n",
      "lambda_min tensor(2.5511e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 221 | time / epoch 33.94s | loss 91.51 \n",
      "lambda_min tensor(2.3012e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 222 | time / epoch 33.90s | loss 91.51 \n",
      "lambda_min tensor(3.8039e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 223 | time / epoch 34.08s | loss 91.51 \n",
      "lambda_min tensor(6.2533e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 224 | time / epoch 34.12s | loss 91.51 \n",
      "lambda_min tensor(2.5628e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 225 | time / epoch 33.98s | loss 91.51 \n",
      "lambda_min tensor(2.5766e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 226 | time / epoch 33.89s | loss 91.50 \n",
      "lambda_min tensor(2.3511e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 227 | time / epoch 34.12s | loss 91.50 \n",
      "lambda_min tensor(2.5513e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 228 | time / epoch 33.74s | loss 91.50 \n",
      "lambda_min tensor(2.6441e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 229 | time / epoch 34.07s | loss 91.50 \n",
      "lambda_min tensor(2.6120e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 230 | time / epoch 34.23s | loss 91.49 \n",
      "lambda_min tensor(2.0232e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 231 | time / epoch 34.16s | loss 91.49 \n",
      "lambda_min tensor(2.1480e-05-8.1406e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 232 | time / epoch 33.71s | loss 91.49 \n",
      "lambda_min tensor(2.2401e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 233 | time / epoch 34.45s | loss 91.49 \n",
      "lambda_min tensor(2.4551e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 234 | time / epoch 33.85s | loss 91.49 \n",
      "lambda_min tensor(2.2502e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 235 | time / epoch 34.00s | loss 91.48 \n",
      "lambda_min tensor(2.4282e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 236 | time / epoch 33.77s | loss 91.48 \n",
      "lambda_min tensor(2.4502e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 237 | time / epoch 34.87s | loss 91.48 \n",
      "lambda_min tensor(3.0601e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 238 | time / epoch 3907.67s | loss 91.48 \n",
      "lambda_min tensor(2.7995e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 239 | time / epoch 5191.26s | loss 91.47 \n",
      "lambda_min tensor(2.3217e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 240 | time / epoch 2931.69s | loss 91.47 \n",
      "lambda_min tensor(2.5275e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 241 | time / epoch 34.22s | loss 91.47 \n",
      "lambda_min tensor(2.3374e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 242 | time / epoch 33.86s | loss 91.47 \n",
      "lambda_min tensor(3.4380e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 243 | time / epoch 33.74s | loss 91.47 \n",
      "lambda_min tensor(2.1571e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 244 | time / epoch 33.57s | loss 91.46 \n",
      "lambda_min tensor(2.4529e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 245 | time / epoch 33.74s | loss 91.46 \n",
      "lambda_min tensor(2.3812e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 246 | time / epoch 33.71s | loss 91.46 \n",
      "lambda_min tensor(2.1325e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 247 | time / epoch 33.77s | loss 91.46 \n",
      "lambda_min tensor(2.4251e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 248 | time / epoch 33.88s | loss 91.45 \n",
      "lambda_min tensor(2.4683e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 249 | time / epoch 33.64s | loss 91.45 \n",
      "lambda_min tensor(2.2300e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 250 | time / epoch 33.60s | loss 91.45 \n",
      "lambda_min tensor(2.0808e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 251 | time / epoch 33.75s | loss 91.45 \n",
      "lambda_min tensor(2.5736e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 252 | time / epoch 33.77s | loss 91.45 \n",
      "lambda_min tensor(2.4804e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 253 | time / epoch 33.94s | loss 91.44 \n",
      "lambda_min tensor(2.0215e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 254 | time / epoch 34.09s | loss 91.44 \n",
      "lambda_min tensor(2.9246e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 255 | time / epoch 33.75s | loss 91.44 \n",
      "lambda_min tensor(1.9399e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 256 | time / epoch 33.75s | loss 91.44 \n",
      "lambda_min tensor(2.4319e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 257 | time / epoch 33.69s | loss 91.43 \n",
      "lambda_min tensor(2.7286e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 258 | time / epoch 33.89s | loss 91.43 \n",
      "lambda_min tensor(2.7953e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 259 | time / epoch 33.82s | loss 91.43 \n",
      "lambda_min tensor(2.7725e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 260 | time / epoch 33.69s | loss 91.43 \n",
      "lambda_min tensor(2.7635e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 261 | time / epoch 33.75s | loss 91.43 \n",
      "lambda_min tensor(2.7222e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 262 | time / epoch 34.14s | loss 91.42 \n",
      "lambda_min tensor(2.8951e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 263 | time / epoch 33.86s | loss 91.42 \n",
      "lambda_min tensor(2.7722e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 264 | time / epoch 33.69s | loss 91.42 \n",
      "lambda_min tensor(1.9977e-05-1.2843e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 265 | time / epoch 34.27s | loss 91.42 \n",
      "lambda_min tensor(1.9768e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 266 | time / epoch 34.03s | loss 91.41 \n",
      "lambda_min tensor(2.7267e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 267 | time / epoch 33.99s | loss 91.41 \n",
      "lambda_min tensor(2.0789e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 268 | time / epoch 34.52s | loss 91.41 \n",
      "lambda_min tensor(2.5176e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 269 | time / epoch 33.88s | loss 91.41 \n",
      "lambda_min tensor(2.2571e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 270 | time / epoch 33.99s | loss 91.41 \n",
      "lambda_min tensor(2.3487e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 271 | time / epoch 33.63s | loss 91.40 \n",
      "lambda_min tensor(2.2958e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 272 | time / epoch 33.93s | loss 91.40 \n",
      "lambda_min tensor(1.9832e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 273 | time / epoch 33.61s | loss 91.40 \n",
      "lambda_min tensor(2.2443e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 274 | time / epoch 34.28s | loss 91.40 \n",
      "lambda_min tensor(4.4941e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 275 | time / epoch 33.65s | loss 91.40 \n",
      "lambda_min tensor(2.1035e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 276 | time / epoch 33.70s | loss 91.39 \n",
      "lambda_min tensor(2.7689e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 277 | time / epoch 33.82s | loss 91.39 \n",
      "lambda_min tensor(2.1149e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 278 | time / epoch 33.86s | loss 91.39 \n",
      "lambda_min tensor(2.0359e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 279 | time / epoch 33.63s | loss 91.39 \n",
      "lambda_min tensor(3.0159e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 280 | time / epoch 33.89s | loss 91.38 \n",
      "lambda_min tensor(2.7678e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 281 | time / epoch 34.44s | loss 91.38 \n",
      "lambda_min tensor(1.9441e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 282 | time / epoch 33.71s | loss 91.38 \n",
      "lambda_min tensor(2.8153e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 283 | time / epoch 33.81s | loss 91.38 \n",
      "lambda_min tensor(1.9439e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 284 | time / epoch 33.76s | loss 91.38 \n",
      "lambda_min tensor(1.9285e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 285 | time / epoch 33.60s | loss 91.37 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.3517e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 286 | time / epoch 33.82s | loss 91.37 \n",
      "lambda_min tensor(2.4275e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 287 | time / epoch 33.64s | loss 91.37 \n",
      "lambda_min tensor(2.1713e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 288 | time / epoch 33.84s | loss 91.37 \n",
      "lambda_min tensor(2.7225e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 289 | time / epoch 34.02s | loss 91.36 \n",
      "lambda_min tensor(2.7376e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 290 | time / epoch 34.50s | loss 91.36 \n",
      "lambda_min tensor(2.2879e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 291 | time / epoch 33.71s | loss 91.36 \n",
      "lambda_min tensor(1.9094e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 292 | time / epoch 33.81s | loss 91.36 \n",
      "lambda_min tensor(2.4165e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 293 | time / epoch 33.89s | loss 91.36 \n",
      "lambda_min tensor(2.0707e-05-1.2180e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 294 | time / epoch 33.80s | loss 91.35 \n",
      "lambda_min tensor(2.1197e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 295 | time / epoch 33.98s | loss 91.35 \n",
      "lambda_min tensor(2.6263e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 296 | time / epoch 33.74s | loss 91.35 \n",
      "lambda_min tensor(2.1295e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 297 | time / epoch 33.79s | loss 91.35 \n",
      "lambda_min tensor(2.6747e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 298 | time / epoch 33.59s | loss 91.35 \n",
      "lambda_min tensor(2.4946e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 299 | time / epoch 33.72s | loss 91.34 \n",
      "lambda_min tensor(2.0747e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 300 | time / epoch 33.92s | loss 91.34 \n",
      "lambda_min tensor(2.2406e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 301 | time / epoch 33.68s | loss 91.34 \n",
      "lambda_min tensor(1.9777e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 302 | time / epoch 33.95s | loss 91.34 \n",
      "lambda_min tensor(2.3480e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 303 | time / epoch 33.67s | loss 91.33 \n",
      "lambda_min tensor(2.5490e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 304 | time / epoch 33.70s | loss 91.33 \n",
      "lambda_min tensor(2.1034e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 305 | time / epoch 33.84s | loss 91.33 \n",
      "lambda_min tensor(2.5799e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 306 | time / epoch 33.80s | loss 91.33 \n",
      "lambda_min tensor(2.5487e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 307 | time / epoch 33.54s | loss 91.33 \n",
      "lambda_min tensor(1.9128e-05-6.2087e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 308 | time / epoch 33.63s | loss 91.32 \n",
      "lambda_min tensor(2.5573e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 309 | time / epoch 33.68s | loss 91.32 \n",
      "lambda_min tensor(2.7863e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 310 | time / epoch 33.74s | loss 91.32 \n",
      "lambda_min tensor(2.4115e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 311 | time / epoch 33.56s | loss 91.32 \n",
      "lambda_min tensor(2.5234e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 312 | time / epoch 33.72s | loss 91.32 \n",
      "lambda_min tensor(2.5062e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 313 | time / epoch 34.01s | loss 91.31 \n",
      "lambda_min tensor(2.3057e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 314 | time / epoch 33.52s | loss 91.31 \n",
      "lambda_min tensor(2.4283e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 315 | time / epoch 33.75s | loss 91.31 \n",
      "lambda_min tensor(1.9155e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 316 | time / epoch 33.60s | loss 91.31 \n",
      "lambda_min tensor(2.4820e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 317 | time / epoch 33.84s | loss 91.30 \n",
      "lambda_min tensor(1.6465e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 318 | time / epoch 33.82s | loss 91.30 \n",
      "lambda_min tensor(2.5411e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 319 | time / epoch 33.75s | loss 91.30 \n",
      "lambda_min tensor(3.0095e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 320 | time / epoch 34.06s | loss 91.30 \n",
      "lambda_min tensor(2.1986e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 321 | time / epoch 33.77s | loss 91.30 \n",
      "lambda_min tensor(1.7809e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 322 | time / epoch 34.22s | loss 91.29 \n",
      "lambda_min tensor(2.4937e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 323 | time / epoch 33.64s | loss 91.29 \n",
      "lambda_min tensor(2.1621e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 324 | time / epoch 34.17s | loss 91.29 \n",
      "lambda_min tensor(1.9377e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 325 | time / epoch 33.72s | loss 91.29 \n",
      "lambda_min tensor(1.8409e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 326 | time / epoch 33.55s | loss 91.29 \n",
      "lambda_min tensor(2.8322e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 327 | time / epoch 33.91s | loss 91.28 \n",
      "lambda_min tensor(2.1370e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 328 | time / epoch 33.77s | loss 91.28 \n",
      "lambda_min tensor(2.1762e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 329 | time / epoch 33.80s | loss 91.28 \n",
      "lambda_min tensor(2.6032e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 330 | time / epoch 33.67s | loss 91.28 \n",
      "lambda_min tensor(1.8991e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 331 | time / epoch 33.74s | loss 91.28 \n",
      "lambda_min tensor(2.6298e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 332 | time / epoch 34.09s | loss 91.27 \n",
      "lambda_min tensor(3.9006e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 333 | time / epoch 33.64s | loss 91.27 \n",
      "lambda_min tensor(1.7967e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 334 | time / epoch 33.98s | loss 91.27 \n",
      "lambda_min tensor(2.0689e-05-5.3591e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 335 | time / epoch 33.65s | loss 91.27 \n",
      "lambda_min tensor(2.5358e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 336 | time / epoch 33.71s | loss 91.26 \n",
      "lambda_min tensor(2.5933e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 337 | time / epoch 33.77s | loss 91.26 \n",
      "lambda_min tensor(2.2995e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 338 | time / epoch 33.91s | loss 91.26 \n",
      "lambda_min tensor(2.3853e-05-2.8440e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 339 | time / epoch 33.95s | loss 91.26 \n",
      "lambda_min tensor(1.9683e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 340 | time / epoch 33.45s | loss 91.26 \n",
      "lambda_min tensor(2.2829e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 341 | time / epoch 34.09s | loss 91.25 \n",
      "lambda_min tensor(2.3754e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 342 | time / epoch 33.82s | loss 91.25 \n",
      "lambda_min tensor(2.5443e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 343 | time / epoch 34.11s | loss 91.25 \n",
      "lambda_min tensor(1.9554e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 344 | time / epoch 33.41s | loss 91.25 \n",
      "lambda_min tensor(2.4894e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 345 | time / epoch 33.60s | loss 91.25 \n",
      "lambda_min tensor(1.7950e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 346 | time / epoch 33.76s | loss 91.24 \n",
      "lambda_min tensor(2.4587e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 347 | time / epoch 33.91s | loss 91.24 \n",
      "lambda_min tensor(2.6261e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 348 | time / epoch 33.85s | loss 91.24 \n",
      "lambda_min tensor(2.1485e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 349 | time / epoch 33.93s | loss 91.24 \n",
      "lambda_min tensor(1.9916e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 350 | time / epoch 33.80s | loss 91.24 \n",
      "lambda_min tensor(2.7637e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 351 | time / epoch 33.88s | loss 91.23 \n",
      "lambda_min tensor(2.5926e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 352 | time / epoch 33.99s | loss 91.23 \n",
      "lambda_min tensor(2.4271e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 353 | time / epoch 33.83s | loss 91.23 \n",
      "lambda_min tensor(2.3745e-05-2.0087e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 354 | time / epoch 33.66s | loss 91.23 \n",
      "lambda_min tensor(2.1368e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 355 | time / epoch 33.75s | loss 91.22 \n",
      "lambda_min tensor(2.0119e-05-2.6482e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 356 | time / epoch 33.77s | loss 91.22 \n",
      "lambda_min tensor(2.0761e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 357 | time / epoch 33.87s | loss 91.22 \n",
      "lambda_min tensor(2.3950e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 358 | time / epoch 33.75s | loss 91.22 \n",
      "lambda_min tensor(1.9683e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 359 | time / epoch 33.69s | loss 91.22 \n",
      "lambda_min tensor(2.2022e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 360 | time / epoch 33.70s | loss 91.21 \n",
      "lambda_min tensor(2.7035e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 361 | time / epoch 33.73s | loss 91.21 \n",
      "lambda_min tensor(1.9684e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 362 | time / epoch 33.83s | loss 91.21 \n",
      "lambda_min tensor(2.6149e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 363 | time / epoch 33.58s | loss 91.21 \n",
      "lambda_min tensor(3.9817e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 364 | time / epoch 33.91s | loss 91.21 \n",
      "lambda_min tensor(2.6264e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 365 | time / epoch 33.53s | loss 91.20 \n",
      "lambda_min tensor(2.5774e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 366 | time / epoch 33.71s | loss 91.20 \n",
      "lambda_min tensor(2.4886e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 367 | time / epoch 33.51s | loss 91.20 \n",
      "lambda_min tensor(2.7990e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 368 | time / epoch 34.40s | loss 91.20 \n",
      "lambda_min tensor(1.9593e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 369 | time / epoch 34.08s | loss 91.20 \n",
      "lambda_min tensor(2.5854e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 370 | time / epoch 33.46s | loss 91.19 \n",
      "lambda_min tensor(2.7809e-05-7.5131e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 371 | time / epoch 33.79s | loss 91.19 \n",
      "lambda_min tensor(2.7970e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 372 | time / epoch 33.65s | loss 91.19 \n",
      "lambda_min tensor(2.0884e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 373 | time / epoch 33.75s | loss 91.19 \n",
      "lambda_min tensor(2.1154e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 374 | time / epoch 33.69s | loss 91.19 \n",
      "lambda_min tensor(2.4217e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 375 | time / epoch 33.76s | loss 91.18 \n",
      "lambda_min tensor(2.8485e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 376 | time / epoch 33.79s | loss 91.18 \n",
      "lambda_min tensor(2.4098e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 377 | time / epoch 34.08s | loss 91.18 \n",
      "lambda_min tensor(2.2724e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 378 | time / epoch 33.65s | loss 91.18 \n",
      "lambda_min tensor(1.9283e-05-2.8213e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 379 | time / epoch 33.70s | loss 91.18 \n",
      "lambda_min tensor(1.9618e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 380 | time / epoch 34.05s | loss 91.17 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.5974e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 381 | time / epoch 33.79s | loss 91.17 \n",
      "lambda_min tensor(2.4279e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 382 | time / epoch 33.85s | loss 91.17 \n",
      "lambda_min tensor(7.5657e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 383 | time / epoch 33.98s | loss 91.17 \n",
      "lambda_min tensor(2.7980e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 384 | time / epoch 33.86s | loss 91.16 \n",
      "lambda_min tensor(2.7091e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 385 | time / epoch 33.91s | loss 91.16 \n",
      "lambda_min tensor(2.7232e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 386 | time / epoch 33.92s | loss 91.16 \n",
      "lambda_min tensor(2.6049e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 387 | time / epoch 33.53s | loss 91.16 \n",
      "lambda_min tensor(2.6310e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 388 | time / epoch 33.83s | loss 91.16 \n",
      "lambda_min tensor(2.8117e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 389 | time / epoch 33.42s | loss 91.15 \n",
      "lambda_min tensor(2.3056e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 390 | time / epoch 33.59s | loss 91.15 \n",
      "lambda_min tensor(2.4628e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 391 | time / epoch 33.66s | loss 91.15 \n",
      "lambda_min tensor(2.5303e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 392 | time / epoch 33.52s | loss 91.15 \n",
      "lambda_min tensor(2.7396e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 393 | time / epoch 34.06s | loss 91.15 \n",
      "lambda_min tensor(2.4634e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 394 | time / epoch 33.73s | loss 91.14 \n",
      "lambda_min tensor(2.5506e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 395 | time / epoch 33.53s | loss 91.14 \n",
      "lambda_min tensor(2.3637e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 396 | time / epoch 33.50s | loss 91.14 \n",
      "lambda_min tensor(2.6798e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 397 | time / epoch 34.04s | loss 91.14 \n",
      "lambda_min tensor(2.8480e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 398 | time / epoch 33.72s | loss 91.14 \n",
      "lambda_min tensor(3.0171e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 399 | time / epoch 34.00s | loss 91.13 \n",
      "lambda_min tensor(2.2908e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 400 | time / epoch 33.60s | loss 91.13 \n",
      "lambda_min tensor(3.1288e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 401 | time / epoch 33.59s | loss 91.13 \n",
      "lambda_min tensor(2.1404e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 402 | time / epoch 33.97s | loss 91.13 \n",
      "lambda_min tensor(2.1440e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 403 | time / epoch 33.64s | loss 91.13 \n",
      "lambda_min tensor(2.6275e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 404 | time / epoch 33.68s | loss 91.12 \n",
      "lambda_min tensor(2.5739e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 405 | time / epoch 33.63s | loss 91.12 \n",
      "lambda_min tensor(2.0658e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 406 | time / epoch 33.53s | loss 91.12 \n",
      "lambda_min tensor(2.1601e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 407 | time / epoch 33.57s | loss 91.12 \n",
      "lambda_min tensor(2.1780e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 408 | time / epoch 34.73s | loss 91.12 \n",
      "lambda_min tensor(2.7423e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 409 | time / epoch 36.01s | loss 91.11 \n",
      "lambda_min tensor(1.7994e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 410 | time / epoch 35.92s | loss 91.11 \n",
      "lambda_min tensor(1.9182e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 411 | time / epoch 35.99s | loss 91.11 \n",
      "lambda_min tensor(2.8307e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 412 | time / epoch 35.91s | loss 91.11 \n",
      "lambda_min tensor(2.7591e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 413 | time / epoch 35.71s | loss 91.11 \n",
      "lambda_min tensor(2.0399e-05-4.1675e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 414 | time / epoch 36.08s | loss 91.10 \n",
      "lambda_min tensor(2.0590e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 415 | time / epoch 35.97s | loss 91.10 \n",
      "lambda_min tensor(2.7065e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 416 | time / epoch 35.79s | loss 91.10 \n",
      "lambda_min tensor(2.0603e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 417 | time / epoch 35.73s | loss 91.10 \n",
      "lambda_min tensor(2.0554e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 418 | time / epoch 5738.13s | loss 91.10 \n",
      "lambda_min tensor(2.4092e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 419 | time / epoch 39.46s | loss 91.09 \n",
      "lambda_min tensor(2.0444e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 420 | time / epoch 37.50s | loss 91.09 \n",
      "lambda_min tensor(2.2393e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 421 | time / epoch 36.92s | loss 91.09 \n",
      "lambda_min tensor(2.5254e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 422 | time / epoch 35.99s | loss 91.09 \n",
      "lambda_min tensor(1.9372e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 423 | time / epoch 36.04s | loss 91.09 \n",
      "lambda_min tensor(2.8926e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 424 | time / epoch 36.51s | loss 91.08 \n",
      "lambda_min tensor(2.0544e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 425 | time / epoch 38.26s | loss 91.08 \n",
      "lambda_min tensor(2.0641e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 426 | time / epoch 37.56s | loss 91.08 \n",
      "lambda_min tensor(2.2635e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 427 | time / epoch 35.74s | loss 91.08 \n",
      "lambda_min tensor(2.6977e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 428 | time / epoch 33.85s | loss 91.08 \n",
      "lambda_min tensor(1.7730e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 429 | time / epoch 33.66s | loss 91.07 \n",
      "lambda_min tensor(2.5531e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 430 | time / epoch 33.83s | loss 91.07 \n",
      "lambda_min tensor(2.2570e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 431 | time / epoch 33.69s | loss 91.07 \n",
      "lambda_min tensor(2.3637e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 432 | time / epoch 34.57s | loss 91.07 \n",
      "lambda_min tensor(1.8547e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 433 | time / epoch 33.72s | loss 91.07 \n",
      "lambda_min tensor(2.3144e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 434 | time / epoch 33.60s | loss 91.06 \n",
      "lambda_min tensor(2.3535e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 435 | time / epoch 34.17s | loss 91.06 \n",
      "lambda_min tensor(2.5012e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 436 | time / epoch 33.72s | loss 91.06 \n",
      "lambda_min tensor(2.7955e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 437 | time / epoch 34.52s | loss 91.06 \n",
      "lambda_min tensor(2.6917e-05-7.5967e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 438 | time / epoch 33.68s | loss 91.06 \n",
      "lambda_min tensor(2.0446e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 439 | time / epoch 33.76s | loss 91.05 \n",
      "lambda_min tensor(2.5649e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 440 | time / epoch 33.74s | loss 91.05 \n",
      "lambda_min tensor(2.0641e-05-4.5696e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 441 | time / epoch 34.13s | loss 91.05 \n",
      "lambda_min tensor(2.5457e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 442 | time / epoch 33.99s | loss 91.05 \n",
      "lambda_min tensor(1.9775e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 443 | time / epoch 33.88s | loss 91.05 \n",
      "lambda_min tensor(2.2567e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 444 | time / epoch 33.74s | loss 91.04 \n",
      "lambda_min tensor(2.7027e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 445 | time / epoch 33.61s | loss 91.04 \n",
      "lambda_min tensor(5.4852e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 446 | time / epoch 33.78s | loss 91.04 \n",
      "lambda_min tensor(2.1321e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 447 | time / epoch 33.56s | loss 91.04 \n",
      "lambda_min tensor(1.9076e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 448 | time / epoch 33.41s | loss 91.04 \n",
      "lambda_min tensor(1.9232e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 449 | time / epoch 33.46s | loss 91.03 \n",
      "lambda_min tensor(2.5486e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 450 | time / epoch 33.73s | loss 91.03 \n",
      "lambda_min tensor(2.1704e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 451 | time / epoch 33.58s | loss 91.03 \n",
      "lambda_min tensor(2.6993e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 452 | time / epoch 33.60s | loss 91.03 \n",
      "lambda_min tensor(2.2999e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 453 | time / epoch 33.62s | loss 91.03 \n",
      "lambda_min tensor(2.8638e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 454 | time / epoch 33.67s | loss 91.02 \n",
      "lambda_min tensor(2.0846e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 455 | time / epoch 33.95s | loss 91.02 \n",
      "lambda_min tensor(2.2364e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 456 | time / epoch 33.50s | loss 91.02 \n",
      "lambda_min tensor(5.5895e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 457 | time / epoch 33.50s | loss 91.02 \n",
      "lambda_min tensor(2.6781e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 458 | time / epoch 33.64s | loss 91.02 \n",
      "lambda_min tensor(2.6367e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 459 | time / epoch 33.79s | loss 91.01 \n",
      "lambda_min tensor(4.3675e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 460 | time / epoch 33.59s | loss 91.01 \n",
      "lambda_min tensor(2.5443e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 461 | time / epoch 33.79s | loss 91.01 \n",
      "lambda_min tensor(2.5088e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 462 | time / epoch 33.86s | loss 91.01 \n",
      "lambda_min tensor(2.6528e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 463 | time / epoch 33.50s | loss 91.01 \n",
      "lambda_min tensor(2.4348e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 464 | time / epoch 33.86s | loss 91.00 \n",
      "lambda_min tensor(2.1761e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 465 | time / epoch 33.83s | loss 91.00 \n",
      "lambda_min tensor(1.6840e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 466 | time / epoch 33.51s | loss 91.00 \n",
      "lambda_min tensor(2.2590e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 467 | time / epoch 33.72s | loss 91.00 \n",
      "lambda_min tensor(2.6995e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 468 | time / epoch 33.93s | loss 91.00 \n",
      "lambda_min tensor(2.2522e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 469 | time / epoch 33.74s | loss 90.99 \n",
      "lambda_min tensor(2.0758e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 470 | time / epoch 33.71s | loss 90.99 \n",
      "lambda_min tensor(2.4667e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 471 | time / epoch 33.86s | loss 90.99 \n",
      "lambda_min tensor(2.6014e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 472 | time / epoch 33.45s | loss 90.99 \n",
      "lambda_min tensor(1.9882e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 473 | time / epoch 34.00s | loss 90.99 \n",
      "lambda_min tensor(2.4581e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 474 | time / epoch 33.82s | loss 90.98 \n",
      "lambda_min tensor(2.8097e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 475 | time / epoch 33.70s | loss 90.98 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(4.2207e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 476 | time / epoch 33.85s | loss 90.98 \n",
      "lambda_min tensor(2.3182e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 477 | time / epoch 33.58s | loss 90.98 \n",
      "lambda_min tensor(1.8350e-05-1.0183e-07j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 478 | time / epoch 33.52s | loss 90.98 \n",
      "lambda_min tensor(2.6956e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 479 | time / epoch 33.76s | loss 90.97 \n",
      "lambda_min tensor(2.4316e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 480 | time / epoch 33.87s | loss 90.97 \n",
      "lambda_min tensor(2.8266e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 481 | time / epoch 33.56s | loss 90.97 \n",
      "lambda_min tensor(2.5116e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 482 | time / epoch 33.82s | loss 90.97 \n",
      "lambda_min tensor(2.4342e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 483 | time / epoch 33.75s | loss 90.97 \n",
      "lambda_min tensor(2.0948e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 484 | time / epoch 33.88s | loss 90.96 \n",
      "lambda_min tensor(1.8494e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 485 | time / epoch 33.53s | loss 90.96 \n",
      "lambda_min tensor(1.9093e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 486 | time / epoch 33.55s | loss 90.96 \n",
      "lambda_min tensor(2.0416e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 487 | time / epoch 33.91s | loss 90.96 \n",
      "lambda_min tensor(1.8019e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 488 | time / epoch 33.82s | loss 90.96 \n",
      "lambda_min tensor(2.9914e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 489 | time / epoch 33.58s | loss 90.95 \n",
      "lambda_min tensor(2.4495e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 490 | time / epoch 33.63s | loss 90.95 \n",
      "lambda_min tensor(2.3193e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 491 | time / epoch 33.42s | loss 90.95 \n",
      "lambda_min tensor(2.7655e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 492 | time / epoch 33.74s | loss 90.95 \n",
      "lambda_min tensor(1.7015e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 493 | time / epoch 33.47s | loss 90.95 \n",
      "lambda_min tensor(2.3389e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 494 | time / epoch 34.04s | loss 90.94 \n",
      "lambda_min tensor(2.5206e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 495 | time / epoch 33.71s | loss 90.94 \n",
      "lambda_min tensor(2.2352e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 496 | time / epoch 33.74s | loss 90.94 \n",
      "lambda_min tensor(4.6779e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 497 | time / epoch 34.48s | loss 90.94 \n",
      "lambda_min tensor(2.4060e-05-3.5839e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 498 | time / epoch 33.60s | loss 90.94 \n",
      "lambda_min tensor(2.2654e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 499 | time / epoch 33.86s | loss 90.94 \n",
      "lambda_min tensor(2.5560e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 500 | time / epoch 34.02s | loss 90.93 \n",
      "lambda_min tensor(2.5102e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 501 | time / epoch 33.91s | loss 90.93 \n",
      "lambda_min tensor(3.2071e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 502 | time / epoch 33.83s | loss 90.93 \n",
      "lambda_min tensor(2.5605e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 503 | time / epoch 34.03s | loss 90.93 \n",
      "lambda_min tensor(2.1028e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 504 | time / epoch 33.84s | loss 90.93 \n",
      "lambda_min tensor(2.1769e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 505 | time / epoch 33.85s | loss 90.92 \n",
      "lambda_min tensor(2.0738e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 506 | time / epoch 34.01s | loss 90.92 \n",
      "lambda_min tensor(2.6933e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 507 | time / epoch 33.77s | loss 90.92 \n",
      "lambda_min tensor(2.4916e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 508 | time / epoch 34.02s | loss 90.92 \n",
      "lambda_min tensor(2.3839e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 509 | time / epoch 33.87s | loss 90.92 \n",
      "lambda_min tensor(2.5428e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 510 | time / epoch 33.76s | loss 90.91 \n",
      "lambda_min tensor(2.2540e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 511 | time / epoch 33.67s | loss 90.91 \n",
      "lambda_min tensor(2.2526e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 512 | time / epoch 33.66s | loss 90.91 \n",
      "lambda_min tensor(2.2845e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 513 | time / epoch 33.68s | loss 90.91 \n",
      "lambda_min tensor(2.3517e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 514 | time / epoch 33.60s | loss 90.91 \n",
      "lambda_min tensor(3.0808e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 515 | time / epoch 33.58s | loss 90.90 \n",
      "lambda_min tensor(3.2326e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 516 | time / epoch 33.65s | loss 90.90 \n",
      "lambda_min tensor(2.1853e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 517 | time / epoch 33.69s | loss 90.90 \n",
      "lambda_min tensor(2.2194e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 518 | time / epoch 33.58s | loss 90.90 \n",
      "lambda_min tensor(2.4150e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 519 | time / epoch 33.66s | loss 90.90 \n",
      "lambda_min tensor(2.6178e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 520 | time / epoch 33.86s | loss 90.89 \n",
      "lambda_min tensor(2.1091e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 521 | time / epoch 33.76s | loss 90.89 \n",
      "lambda_min tensor(2.5650e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 522 | time / epoch 33.51s | loss 90.89 \n",
      "lambda_min tensor(2.2828e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 523 | time / epoch 33.84s | loss 90.89 \n",
      "lambda_min tensor(2.4496e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 524 | time / epoch 33.71s | loss 90.89 \n",
      "lambda_min tensor(2.4160e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 525 | time / epoch 33.58s | loss 90.89 \n",
      "lambda_min tensor(2.9750e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 526 | time / epoch 33.88s | loss 90.88 \n",
      "lambda_min tensor(2.3227e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 527 | time / epoch 33.68s | loss 90.88 \n",
      "lambda_min tensor(2.3597e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 528 | time / epoch 33.78s | loss 90.88 \n",
      "lambda_min tensor(2.3822e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 529 | time / epoch 33.85s | loss 90.88 \n",
      "lambda_min tensor(2.0394e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 530 | time / epoch 33.68s | loss 90.88 \n",
      "lambda_min tensor(2.2794e-05-3.5501e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 531 | time / epoch 33.71s | loss 90.87 \n",
      "lambda_min tensor(2.4883e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 532 | time / epoch 33.68s | loss 90.87 \n",
      "lambda_min tensor(2.3661e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 533 | time / epoch 33.71s | loss 90.87 \n",
      "lambda_min tensor(2.4100e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 534 | time / epoch 33.75s | loss 90.87 \n",
      "lambda_min tensor(1.9861e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 535 | time / epoch 33.94s | loss 90.87 \n",
      "lambda_min tensor(2.2941e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 536 | time / epoch 33.70s | loss 90.86 \n",
      "lambda_min tensor(2.4256e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 537 | time / epoch 33.55s | loss 90.86 \n",
      "lambda_min tensor(2.7716e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 538 | time / epoch 33.96s | loss 90.86 \n",
      "lambda_min tensor(2.4249e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 539 | time / epoch 33.79s | loss 90.86 \n",
      "lambda_min tensor(2.2986e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 540 | time / epoch 33.84s | loss 90.86 \n",
      "lambda_min tensor(2.5577e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 541 | time / epoch 34.56s | loss 90.85 \n",
      "lambda_min tensor(2.6815e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 542 | time / epoch 33.54s | loss 90.85 \n",
      "lambda_min tensor(1.7597e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 543 | time / epoch 33.84s | loss 90.85 \n",
      "lambda_min tensor(3.1101e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 544 | time / epoch 33.91s | loss 90.85 \n",
      "lambda_min tensor(2.5111e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 545 | time / epoch 33.53s | loss 90.85 \n",
      "lambda_min tensor(2.0057e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 546 | time / epoch 33.53s | loss 90.85 \n",
      "lambda_min tensor(2.6912e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 547 | time / epoch 33.54s | loss 90.84 \n",
      "lambda_min tensor(2.5472e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 548 | time / epoch 33.77s | loss 90.84 \n",
      "lambda_min tensor(2.1826e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 549 | time / epoch 33.86s | loss 90.84 \n",
      "lambda_min tensor(1.9839e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 550 | time / epoch 33.73s | loss 90.84 \n",
      "lambda_min tensor(2.7124e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 551 | time / epoch 33.77s | loss 90.84 \n",
      "lambda_min tensor(2.2694e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 552 | time / epoch 33.88s | loss 90.83 \n",
      "lambda_min tensor(2.0896e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 553 | time / epoch 33.66s | loss 90.83 \n",
      "lambda_min tensor(2.1974e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 554 | time / epoch 33.25s | loss 90.83 \n",
      "lambda_min tensor(2.1164e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 555 | time / epoch 33.54s | loss 90.83 \n",
      "lambda_min tensor(2.5455e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 556 | time / epoch 33.58s | loss 90.83 \n",
      "lambda_min tensor(2.5434e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 557 | time / epoch 33.74s | loss 90.82 \n",
      "lambda_min tensor(2.0620e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 558 | time / epoch 33.79s | loss 90.82 \n",
      "lambda_min tensor(2.6872e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 559 | time / epoch 33.56s | loss 90.82 \n",
      "lambda_min tensor(2.5506e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 560 | time / epoch 33.88s | loss 90.82 \n",
      "lambda_min tensor(2.2863e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 561 | time / epoch 33.59s | loss 90.82 \n",
      "lambda_min tensor(2.0532e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 562 | time / epoch 33.48s | loss 90.81 \n",
      "lambda_min tensor(2.2589e-05-2.8722e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 563 | time / epoch 33.54s | loss 90.81 \n",
      "lambda_min tensor(2.6986e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 564 | time / epoch 33.52s | loss 90.81 \n",
      "lambda_min tensor(2.8963e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 565 | time / epoch 33.55s | loss 90.81 \n",
      "lambda_min tensor(2.2467e-05-2.7879e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 566 | time / epoch 33.88s | loss 90.81 \n",
      "lambda_min tensor(1.9268e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 567 | time / epoch 33.66s | loss 90.81 \n",
      "lambda_min tensor(2.5775e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 568 | time / epoch 33.68s | loss 90.80 \n",
      "lambda_min tensor(2.0401e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 569 | time / epoch 33.85s | loss 90.80 \n",
      "lambda_min tensor(2.5570e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 570 | time / epoch 33.81s | loss 90.80 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.0657e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 571 | time / epoch 34.04s | loss 90.80 \n",
      "lambda_min tensor(2.7381e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 572 | time / epoch 33.73s | loss 90.80 \n",
      "lambda_min tensor(2.0963e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 573 | time / epoch 33.57s | loss 90.79 \n",
      "lambda_min tensor(4.7591e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 574 | time / epoch 33.89s | loss 90.79 \n",
      "lambda_min tensor(2.6668e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 575 | time / epoch 33.71s | loss 90.79 \n",
      "lambda_min tensor(2.2374e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 576 | time / epoch 33.88s | loss 90.79 \n",
      "lambda_min tensor(2.2992e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 577 | time / epoch 33.98s | loss 90.79 \n",
      "lambda_min tensor(1.8237e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 578 | time / epoch 34.05s | loss 90.78 \n",
      "lambda_min tensor(2.2085e-05-7.2655e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 579 | time / epoch 33.95s | loss 90.78 \n",
      "lambda_min tensor(2.5842e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 580 | time / epoch 33.90s | loss 90.78 \n",
      "lambda_min tensor(2.2911e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 581 | time / epoch 34.12s | loss 90.78 \n",
      "lambda_min tensor(2.6117e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 582 | time / epoch 33.68s | loss 90.78 \n",
      "lambda_min tensor(2.5852e-05-4.0737e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 583 | time / epoch 33.87s | loss 90.78 \n",
      "lambda_min tensor(2.5035e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 584 | time / epoch 33.78s | loss 90.77 \n",
      "lambda_min tensor(2.2350e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 585 | time / epoch 33.52s | loss 90.77 \n",
      "lambda_min tensor(2.3178e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 586 | time / epoch 33.84s | loss 90.77 \n",
      "lambda_min tensor(2.9127e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 587 | time / epoch 33.75s | loss 90.77 \n",
      "lambda_min tensor(2.3031e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 588 | time / epoch 33.74s | loss 90.77 \n",
      "lambda_min tensor(1.6035e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 589 | time / epoch 33.80s | loss 90.76 \n",
      "lambda_min tensor(2.5527e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 590 | time / epoch 33.98s | loss 90.76 \n",
      "lambda_min tensor(2.2718e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 591 | time / epoch 33.72s | loss 90.76 \n",
      "lambda_min tensor(2.3631e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 592 | time / epoch 33.87s | loss 90.76 \n",
      "lambda_min tensor(2.3335e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 593 | time / epoch 33.62s | loss 90.76 \n",
      "lambda_min tensor(2.2400e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 594 | time / epoch 33.64s | loss 90.76 \n",
      "lambda_min tensor(2.2224e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 595 | time / epoch 33.68s | loss 90.75 \n",
      "lambda_min tensor(2.0752e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 596 | time / epoch 34.07s | loss 90.75 \n",
      "lambda_min tensor(2.0348e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 597 | time / epoch 33.70s | loss 90.75 \n",
      "lambda_min tensor(1.9087e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 598 | time / epoch 33.56s | loss 90.75 \n",
      "lambda_min tensor(2.3040e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 599 | time / epoch 33.98s | loss 90.75 \n",
      "lambda_min tensor(4.2932e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 600 | time / epoch 33.65s | loss 90.74 \n",
      "lambda_min tensor(1.8785e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 601 | time / epoch 33.86s | loss 90.74 \n",
      "lambda_min tensor(2.4704e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 602 | time / epoch 33.57s | loss 90.74 \n",
      "lambda_min tensor(2.2587e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 603 | time / epoch 34.27s | loss 90.74 \n",
      "lambda_min tensor(2.6086e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 604 | time / epoch 34.21s | loss 90.74 \n",
      "lambda_min tensor(2.3339e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 605 | time / epoch 34.11s | loss 90.73 \n",
      "lambda_min tensor(2.3092e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 606 | time / epoch 33.59s | loss 90.73 \n",
      "lambda_min tensor(4.0299e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 607 | time / epoch 33.55s | loss 90.73 \n",
      "lambda_min tensor(2.0368e-05-4.4122e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 608 | time / epoch 34.46s | loss 90.73 \n",
      "lambda_min tensor(2.2734e-05-4.0351e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 609 | time / epoch 33.91s | loss 90.73 \n",
      "lambda_min tensor(1.8929e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 610 | time / epoch 33.79s | loss 90.73 \n",
      "lambda_min tensor(2.3174e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 611 | time / epoch 33.76s | loss 90.72 \n",
      "lambda_min tensor(2.5608e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 612 | time / epoch 33.71s | loss 90.72 \n",
      "lambda_min tensor(2.5202e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 613 | time / epoch 33.57s | loss 90.72 \n",
      "lambda_min tensor(2.2590e-05-3.0694e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 614 | time / epoch 33.76s | loss 90.72 \n",
      "lambda_min tensor(2.5214e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 615 | time / epoch 34.19s | loss 90.72 \n",
      "lambda_min tensor(2.5215e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 616 | time / epoch 33.82s | loss 90.71 \n",
      "lambda_min tensor(2.6679e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 617 | time / epoch 34.18s | loss 90.71 \n",
      "lambda_min tensor(2.3016e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 618 | time / epoch 33.96s | loss 90.71 \n",
      "lambda_min tensor(2.6021e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 619 | time / epoch 33.97s | loss 90.71 \n",
      "lambda_min tensor(2.2034e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 620 | time / epoch 33.87s | loss 90.71 \n",
      "lambda_min tensor(2.1962e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 621 | time / epoch 34.27s | loss 90.71 \n",
      "lambda_min tensor(2.9766e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 622 | time / epoch 34.11s | loss 90.70 \n",
      "lambda_min tensor(2.5362e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 623 | time / epoch 33.78s | loss 90.70 \n",
      "lambda_min tensor(3.0658e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 624 | time / epoch 33.58s | loss 90.70 \n",
      "lambda_min tensor(2.1061e-05-9.8631e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 625 | time / epoch 33.77s | loss 90.70 \n",
      "lambda_min tensor(2.2350e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 626 | time / epoch 33.86s | loss 90.70 \n",
      "lambda_min tensor(2.6636e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 627 | time / epoch 33.79s | loss 90.69 \n",
      "lambda_min tensor(2.5772e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 628 | time / epoch 33.81s | loss 90.69 \n",
      "lambda_min tensor(2.3063e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 629 | time / epoch 34.25s | loss 90.69 \n",
      "lambda_min tensor(2.0318e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 630 | time / epoch 33.42s | loss 90.69 \n",
      "lambda_min tensor(2.2408e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 631 | time / epoch 33.60s | loss 90.69 \n",
      "lambda_min tensor(2.1542e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 632 | time / epoch 33.69s | loss 90.69 \n",
      "lambda_min tensor(1.8988e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 633 | time / epoch 33.77s | loss 90.68 \n",
      "lambda_min tensor(4.2644e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 634 | time / epoch 34.04s | loss 90.68 \n",
      "lambda_min tensor(2.8638e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 635 | time / epoch 33.75s | loss 90.68 \n",
      "lambda_min tensor(2.6387e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 636 | time / epoch 33.74s | loss 90.68 \n",
      "lambda_min tensor(2.3356e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 637 | time / epoch 33.63s | loss 90.68 \n",
      "lambda_min tensor(2.0069e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 638 | time / epoch 33.66s | loss 90.67 \n",
      "lambda_min tensor(2.1776e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 639 | time / epoch 33.67s | loss 90.67 \n",
      "lambda_min tensor(2.2523e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 640 | time / epoch 34.36s | loss 90.67 \n",
      "lambda_min tensor(2.5650e-05-1.0560e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 641 | time / epoch 34.09s | loss 90.67 \n",
      "lambda_min tensor(2.6430e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 642 | time / epoch 33.97s | loss 90.67 \n",
      "lambda_min tensor(1.7748e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 643 | time / epoch 33.87s | loss 90.67 \n",
      "lambda_min tensor(2.8308e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 644 | time / epoch 33.57s | loss 90.66 \n",
      "lambda_min tensor(2.1540e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 645 | time / epoch 33.68s | loss 90.66 \n",
      "lambda_min tensor(2.1402e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 646 | time / epoch 33.78s | loss 90.66 \n",
      "lambda_min tensor(2.4932e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 647 | time / epoch 33.57s | loss 90.66 \n",
      "lambda_min tensor(2.3273e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 648 | time / epoch 33.86s | loss 90.66 \n",
      "lambda_min tensor(2.0896e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 649 | time / epoch 34.14s | loss 90.65 \n",
      "lambda_min tensor(2.2862e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 650 | time / epoch 33.91s | loss 90.65 \n",
      "lambda_min tensor(2.6340e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 651 | time / epoch 33.53s | loss 90.65 \n",
      "lambda_min tensor(1.9788e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 652 | time / epoch 33.75s | loss 90.65 \n",
      "lambda_min tensor(1.8218e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 653 | time / epoch 33.64s | loss 90.65 \n",
      "lambda_min tensor(2.0004e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 654 | time / epoch 33.99s | loss 90.65 \n",
      "lambda_min tensor(2.3813e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 655 | time / epoch 33.83s | loss 90.64 \n",
      "lambda_min tensor(2.1052e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 656 | time / epoch 33.89s | loss 90.64 \n",
      "lambda_min tensor(2.0854e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 657 | time / epoch 33.72s | loss 90.64 \n",
      "lambda_min tensor(3.0761e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 658 | time / epoch 33.64s | loss 90.64 \n",
      "lambda_min tensor(2.0284e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 659 | time / epoch 33.85s | loss 90.64 \n",
      "lambda_min tensor(1.9207e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 660 | time / epoch 33.58s | loss 90.63 \n",
      "lambda_min tensor(2.1049e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 661 | time / epoch 34.05s | loss 90.63 \n",
      "lambda_min tensor(2.7354e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 662 | time / epoch 33.88s | loss 90.63 \n",
      "lambda_min tensor(2.4193e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 663 | time / epoch 33.87s | loss 90.63 \n",
      "lambda_min tensor(2.5990e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 664 | time / epoch 33.73s | loss 90.63 \n",
      "lambda_min tensor(2.9449e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 665 | time / epoch 33.89s | loss 90.63 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.1463e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 666 | time / epoch 33.81s | loss 90.62 \n",
      "lambda_min tensor(2.0371e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 667 | time / epoch 34.27s | loss 90.62 \n",
      "lambda_min tensor(2.5855e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 668 | time / epoch 33.74s | loss 90.62 \n",
      "lambda_min tensor(2.7537e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 669 | time / epoch 33.97s | loss 90.62 \n",
      "lambda_min tensor(5.0627e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 670 | time / epoch 33.86s | loss 90.62 \n",
      "lambda_min tensor(1.9972e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 671 | time / epoch 33.60s | loss 90.61 \n",
      "lambda_min tensor(2.2969e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 672 | time / epoch 33.90s | loss 90.61 \n",
      "lambda_min tensor(2.0882e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 673 | time / epoch 33.71s | loss 90.61 \n",
      "lambda_min tensor(2.2312e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 674 | time / epoch 33.95s | loss 90.61 \n",
      "lambda_min tensor(2.2805e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 675 | time / epoch 33.71s | loss 90.61 \n",
      "lambda_min tensor(2.2948e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 676 | time / epoch 33.78s | loss 90.61 \n",
      "lambda_min tensor(2.8759e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 677 | time / epoch 33.96s | loss 90.60 \n",
      "lambda_min tensor(2.2722e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 678 | time / epoch 33.75s | loss 90.60 \n",
      "lambda_min tensor(3.0267e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 679 | time / epoch 33.75s | loss 90.60 \n",
      "lambda_min tensor(2.6190e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 680 | time / epoch 34.16s | loss 90.60 \n",
      "lambda_min tensor(2.4854e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 681 | time / epoch 33.82s | loss 90.60 \n",
      "lambda_min tensor(2.0402e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 682 | time / epoch 33.65s | loss 90.59 \n",
      "lambda_min tensor(2.1412e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 683 | time / epoch 34.32s | loss 90.59 \n",
      "lambda_min tensor(2.4238e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 684 | time / epoch 33.59s | loss 90.59 \n",
      "lambda_min tensor(2.3622e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 685 | time / epoch 33.93s | loss 90.59 \n",
      "lambda_min tensor(1.9778e-05-1.7977e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 686 | time / epoch 33.87s | loss 90.59 \n",
      "lambda_min tensor(2.6812e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 687 | time / epoch 33.84s | loss 90.59 \n",
      "lambda_min tensor(1.9661e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 688 | time / epoch 33.63s | loss 90.58 \n",
      "lambda_min tensor(2.4570e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 689 | time / epoch 33.87s | loss 90.58 \n",
      "lambda_min tensor(1.7967e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 690 | time / epoch 33.73s | loss 90.58 \n",
      "lambda_min tensor(2.5466e-05-1.4313e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 691 | time / epoch 33.73s | loss 90.58 \n",
      "lambda_min tensor(1.8685e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 692 | time / epoch 34.06s | loss 90.58 \n",
      "lambda_min tensor(2.9832e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 693 | time / epoch 33.65s | loss 90.58 \n",
      "lambda_min tensor(2.0847e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 694 | time / epoch 33.71s | loss 90.57 \n",
      "lambda_min tensor(2.6486e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 695 | time / epoch 33.65s | loss 90.57 \n",
      "lambda_min tensor(3.2415e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 696 | time / epoch 34.24s | loss 90.57 \n",
      "lambda_min tensor(2.1610e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 697 | time / epoch 33.69s | loss 90.57 \n",
      "lambda_min tensor(2.3322e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 698 | time / epoch 33.56s | loss 90.57 \n",
      "lambda_min tensor(2.2086e-05-1.6617e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 699 | time / epoch 34.00s | loss 90.56 \n",
      "lambda_min tensor(1.7538e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 700 | time / epoch 33.54s | loss 90.56 \n",
      "lambda_min tensor(2.4846e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 701 | time / epoch 33.99s | loss 90.56 \n",
      "lambda_min tensor(2.8645e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 702 | time / epoch 33.68s | loss 90.56 \n",
      "lambda_min tensor(2.6376e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 703 | time / epoch 33.78s | loss 90.56 \n",
      "lambda_min tensor(2.5498e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 704 | time / epoch 34.45s | loss 90.56 \n",
      "lambda_min tensor(2.3712e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 705 | time / epoch 33.73s | loss 90.55 \n",
      "lambda_min tensor(2.4262e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 706 | time / epoch 33.74s | loss 90.55 \n",
      "lambda_min tensor(2.0577e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 707 | time / epoch 33.60s | loss 90.55 \n",
      "lambda_min tensor(2.1090e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 708 | time / epoch 33.85s | loss 90.55 \n",
      "lambda_min tensor(2.1839e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 709 | time / epoch 33.74s | loss 90.55 \n",
      "lambda_min tensor(2.6895e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 710 | time / epoch 33.65s | loss 90.55 \n",
      "lambda_min tensor(2.6089e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 711 | time / epoch 33.93s | loss 90.54 \n",
      "lambda_min tensor(2.0604e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 712 | time / epoch 33.72s | loss 90.54 \n",
      "lambda_min tensor(2.7853e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 713 | time / epoch 33.58s | loss 90.54 \n",
      "lambda_min tensor(2.4757e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 714 | time / epoch 33.73s | loss 90.54 \n",
      "lambda_min tensor(2.2700e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 715 | time / epoch 33.73s | loss 90.54 \n",
      "lambda_min tensor(2.0903e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 716 | time / epoch 33.73s | loss 90.53 \n",
      "lambda_min tensor(2.7008e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 717 | time / epoch 34.02s | loss 90.53 \n",
      "lambda_min tensor(3.1529e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 718 | time / epoch 33.88s | loss 90.53 \n",
      "lambda_min tensor(2.5933e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 719 | time / epoch 33.86s | loss 90.53 \n",
      "lambda_min tensor(2.9034e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 720 | time / epoch 33.65s | loss 90.53 \n",
      "lambda_min tensor(2.5098e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 721 | time / epoch 33.65s | loss 90.53 \n",
      "lambda_min tensor(2.9267e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 722 | time / epoch 33.66s | loss 90.52 \n",
      "lambda_min tensor(5.6103e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 723 | time / epoch 33.58s | loss 90.52 \n",
      "lambda_min tensor(2.3664e-05-3.3508e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 724 | time / epoch 33.88s | loss 90.52 \n",
      "lambda_min tensor(2.5405e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 725 | time / epoch 33.66s | loss 90.52 \n",
      "lambda_min tensor(2.0157e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 726 | time / epoch 33.73s | loss 90.52 \n",
      "lambda_min tensor(2.5741e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 727 | time / epoch 33.82s | loss 90.52 \n",
      "lambda_min tensor(2.2133e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 728 | time / epoch 33.79s | loss 90.51 \n",
      "lambda_min tensor(2.8968e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 729 | time / epoch 33.64s | loss 90.51 \n",
      "lambda_min tensor(1.6655e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 730 | time / epoch 33.65s | loss 90.51 \n",
      "lambda_min tensor(2.1234e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 731 | time / epoch 33.75s | loss 90.51 \n",
      "lambda_min tensor(2.7098e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 732 | time / epoch 33.53s | loss 90.51 \n",
      "lambda_min tensor(2.6874e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 733 | time / epoch 33.90s | loss 90.51 \n",
      "lambda_min tensor(2.6733e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 734 | time / epoch 33.68s | loss 90.50 \n",
      "lambda_min tensor(2.6341e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 735 | time / epoch 33.79s | loss 90.50 \n",
      "lambda_min tensor(2.6115e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 736 | time / epoch 33.57s | loss 90.50 \n",
      "lambda_min tensor(2.1075e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 737 | time / epoch 33.78s | loss 90.50 \n",
      "lambda_min tensor(2.5898e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 738 | time / epoch 33.98s | loss 90.50 \n",
      "lambda_min tensor(2.6492e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 739 | time / epoch 33.59s | loss 90.49 \n",
      "lambda_min tensor(2.6342e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 740 | time / epoch 33.76s | loss 90.49 \n",
      "lambda_min tensor(4.8749e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 741 | time / epoch 33.77s | loss 90.49 \n",
      "lambda_min tensor(2.1364e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 742 | time / epoch 33.72s | loss 90.49 \n",
      "lambda_min tensor(2.5969e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 743 | time / epoch 33.73s | loss 90.49 \n",
      "lambda_min tensor(1.8694e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 744 | time / epoch 33.50s | loss 90.49 \n",
      "lambda_min tensor(3.0191e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 745 | time / epoch 33.74s | loss 90.48 \n",
      "lambda_min tensor(2.5671e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 746 | time / epoch 33.73s | loss 90.48 \n",
      "lambda_min tensor(2.7095e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 747 | time / epoch 33.83s | loss 90.48 \n",
      "lambda_min tensor(2.7297e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 748 | time / epoch 33.73s | loss 90.48 \n",
      "lambda_min tensor(2.2546e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 749 | time / epoch 33.78s | loss 90.48 \n",
      "lambda_min tensor(2.1114e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 750 | time / epoch 33.51s | loss 90.48 \n",
      "lambda_min tensor(2.3542e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 751 | time / epoch 33.75s | loss 90.47 \n",
      "lambda_min tensor(2.0973e-05-1.2108e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 752 | time / epoch 33.62s | loss 90.47 \n",
      "lambda_min tensor(2.3487e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 753 | time / epoch 33.84s | loss 90.47 \n",
      "lambda_min tensor(2.3800e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 754 | time / epoch 33.76s | loss 90.47 \n",
      "lambda_min tensor(2.1420e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 755 | time / epoch 33.53s | loss 90.47 \n",
      "lambda_min tensor(2.5758e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 756 | time / epoch 33.59s | loss 90.47 \n",
      "lambda_min tensor(2.3882e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 757 | time / epoch 33.62s | loss 90.46 \n",
      "lambda_min tensor(2.1209e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 758 | time / epoch 33.56s | loss 90.46 \n",
      "lambda_min tensor(2.4671e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 759 | time / epoch 33.87s | loss 90.46 \n",
      "lambda_min tensor(2.6999e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 760 | time / epoch 33.94s | loss 90.46 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.7947e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 761 | time / epoch 33.56s | loss 90.46 \n",
      "lambda_min tensor(2.2092e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 762 | time / epoch 33.69s | loss 90.45 \n",
      "lambda_min tensor(2.2484e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 763 | time / epoch 33.78s | loss 90.45 \n",
      "lambda_min tensor(2.7192e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 764 | time / epoch 33.79s | loss 90.45 \n",
      "lambda_min tensor(2.3695e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 765 | time / epoch 33.67s | loss 90.45 \n",
      "lambda_min tensor(2.1312e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 766 | time / epoch 33.55s | loss 90.45 \n",
      "lambda_min tensor(2.4058e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 767 | time / epoch 33.74s | loss 90.45 \n",
      "lambda_min tensor(2.2987e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 768 | time / epoch 33.66s | loss 90.44 \n",
      "lambda_min tensor(2.2470e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 769 | time / epoch 33.78s | loss 90.44 \n",
      "lambda_min tensor(2.2870e-05-2.2056e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 770 | time / epoch 33.91s | loss 90.44 \n",
      "lambda_min tensor(2.2750e-05-1.6041e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 771 | time / epoch 34.52s | loss 90.44 \n",
      "lambda_min tensor(2.3101e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 772 | time / epoch 33.86s | loss 90.44 \n",
      "lambda_min tensor(2.2501e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 773 | time / epoch 33.77s | loss 90.44 \n",
      "lambda_min tensor(2.1217e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 774 | time / epoch 33.53s | loss 90.43 \n",
      "lambda_min tensor(2.2030e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 775 | time / epoch 33.96s | loss 90.43 \n",
      "lambda_min tensor(1.8657e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 776 | time / epoch 33.99s | loss 90.43 \n",
      "lambda_min tensor(2.7361e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 777 | time / epoch 33.91s | loss 90.43 \n",
      "lambda_min tensor(2.0462e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 778 | time / epoch 34.10s | loss 90.43 \n",
      "lambda_min tensor(2.0033e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 779 | time / epoch 33.84s | loss 90.43 \n",
      "lambda_min tensor(1.9676e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 780 | time / epoch 33.86s | loss 90.42 \n",
      "lambda_min tensor(2.1267e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 781 | time / epoch 34.17s | loss 90.42 \n",
      "lambda_min tensor(2.2551e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 782 | time / epoch 34.41s | loss 90.42 \n",
      "lambda_min tensor(2.1654e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 783 | time / epoch 34.16s | loss 90.42 \n",
      "lambda_min tensor(2.4172e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 784 | time / epoch 34.51s | loss 90.42 \n",
      "lambda_min tensor(2.8482e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 785 | time / epoch 34.09s | loss 90.42 \n",
      "lambda_min tensor(2.5368e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 786 | time / epoch 34.05s | loss 90.41 \n",
      "lambda_min tensor(2.0405e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 787 | time / epoch 34.21s | loss 90.41 \n",
      "lambda_min tensor(2.2040e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 788 | time / epoch 34.22s | loss 90.41 \n",
      "lambda_min tensor(2.0380e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 789 | time / epoch 34.15s | loss 90.41 \n",
      "lambda_min tensor(2.1647e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 790 | time / epoch 34.01s | loss 90.41 \n",
      "lambda_min tensor(2.1213e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 791 | time / epoch 34.33s | loss 90.41 \n",
      "lambda_min tensor(2.7393e-05-4.0265e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 792 | time / epoch 33.88s | loss 90.40 \n",
      "lambda_min tensor(2.7334e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 793 | time / epoch 34.11s | loss 90.40 \n",
      "lambda_min tensor(2.0855e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 794 | time / epoch 34.01s | loss 90.40 \n",
      "lambda_min tensor(1.9434e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 795 | time / epoch 33.74s | loss 90.40 \n",
      "lambda_min tensor(2.2483e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 796 | time / epoch 33.69s | loss 90.40 \n",
      "lambda_min tensor(2.8927e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 797 | time / epoch 34.00s | loss 90.40 \n",
      "lambda_min tensor(2.0688e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 798 | time / epoch 33.85s | loss 90.39 \n",
      "lambda_min tensor(2.2692e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 799 | time / epoch 33.59s | loss 90.39 \n",
      "lambda_min tensor(2.2771e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 800 | time / epoch 33.90s | loss 90.39 \n",
      "lambda_min tensor(2.3300e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 801 | time / epoch 33.89s | loss 90.39 \n",
      "lambda_min tensor(2.5165e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 802 | time / epoch 33.77s | loss 90.39 \n",
      "lambda_min tensor(2.7864e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 803 | time / epoch 33.94s | loss 90.38 \n",
      "lambda_min tensor(2.5895e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 804 | time / epoch 33.78s | loss 90.38 \n",
      "lambda_min tensor(1.9457e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 805 | time / epoch 33.97s | loss 90.38 \n",
      "lambda_min tensor(2.8736e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 806 | time / epoch 33.61s | loss 90.38 \n",
      "lambda_min tensor(4.4679e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 807 | time / epoch 34.11s | loss 90.38 \n",
      "lambda_min tensor(2.5755e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 808 | time / epoch 34.18s | loss 90.38 \n",
      "lambda_min tensor(2.3831e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 809 | time / epoch 34.26s | loss 90.37 \n",
      "lambda_min tensor(2.7261e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 810 | time / epoch 34.08s | loss 90.37 \n",
      "lambda_min tensor(2.6197e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 811 | time / epoch 34.18s | loss 90.37 \n",
      "lambda_min tensor(2.1640e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 812 | time / epoch 33.91s | loss 90.37 \n",
      "lambda_min tensor(2.1210e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 813 | time / epoch 34.13s | loss 90.37 \n",
      "lambda_min tensor(3.0934e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 814 | time / epoch 33.92s | loss 90.37 \n",
      "lambda_min tensor(6.6481e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 815 | time / epoch 34.42s | loss 90.36 \n",
      "lambda_min tensor(1.7449e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 816 | time / epoch 34.15s | loss 90.36 \n",
      "lambda_min tensor(2.0123e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 817 | time / epoch 33.79s | loss 90.36 \n",
      "lambda_min tensor(2.8732e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 818 | time / epoch 34.47s | loss 90.36 \n",
      "lambda_min tensor(2.1120e-05-4.7453e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 819 | time / epoch 34.23s | loss 90.36 \n",
      "lambda_min tensor(1.9899e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 820 | time / epoch 34.26s | loss 90.36 \n",
      "lambda_min tensor(2.1091e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 821 | time / epoch 34.05s | loss 90.35 \n",
      "lambda_min tensor(2.4441e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 822 | time / epoch 33.67s | loss 90.35 \n",
      "lambda_min tensor(2.3481e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 823 | time / epoch 34.36s | loss 90.35 \n",
      "lambda_min tensor(2.0106e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 824 | time / epoch 33.49s | loss 90.35 \n",
      "lambda_min tensor(2.7214e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 825 | time / epoch 33.66s | loss 90.35 \n",
      "lambda_min tensor(2.4765e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 826 | time / epoch 33.68s | loss 90.35 \n",
      "lambda_min tensor(2.1230e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 827 | time / epoch 33.68s | loss 90.34 \n",
      "lambda_min tensor(2.5174e-05-3.5752e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 828 | time / epoch 33.34s | loss 90.34 \n",
      "lambda_min tensor(2.2542e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 829 | time / epoch 33.81s | loss 90.34 \n",
      "lambda_min tensor(2.5325e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 830 | time / epoch 33.68s | loss 90.34 \n",
      "lambda_min tensor(2.4855e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 831 | time / epoch 34.00s | loss 90.34 \n",
      "lambda_min tensor(2.2891e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 832 | time / epoch 34.08s | loss 90.34 \n",
      "lambda_min tensor(2.2362e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 833 | time / epoch 34.06s | loss 90.33 \n",
      "lambda_min tensor(3.5307e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 834 | time / epoch 34.65s | loss 90.33 \n",
      "lambda_min tensor(2.0744e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 835 | time / epoch 33.81s | loss 90.33 \n",
      "lambda_min tensor(2.8297e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 836 | time / epoch 33.60s | loss 90.33 \n",
      "lambda_min tensor(2.5581e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 837 | time / epoch 33.96s | loss 90.33 \n",
      "lambda_min tensor(2.0728e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 838 | time / epoch 34.61s | loss 90.33 \n",
      "lambda_min tensor(2.4395e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 839 | time / epoch 34.10s | loss 90.32 \n",
      "lambda_min tensor(2.7559e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 840 | time / epoch 34.33s | loss 90.32 \n",
      "lambda_min tensor(2.5495e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 841 | time / epoch 34.74s | loss 90.32 \n",
      "lambda_min tensor(2.4966e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 842 | time / epoch 34.07s | loss 90.32 \n",
      "lambda_min tensor(2.8676e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 843 | time / epoch 33.76s | loss 90.32 \n",
      "lambda_min tensor(2.1675e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 844 | time / epoch 34.73s | loss 90.32 \n",
      "lambda_min tensor(2.1571e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 845 | time / epoch 33.81s | loss 90.31 \n",
      "lambda_min tensor(2.6699e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 846 | time / epoch 34.24s | loss 90.31 \n",
      "lambda_min tensor(2.3612e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 847 | time / epoch 33.97s | loss 90.31 \n",
      "lambda_min tensor(2.8341e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 848 | time / epoch 33.59s | loss 90.31 \n",
      "lambda_min tensor(2.6003e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 849 | time / epoch 33.65s | loss 90.31 \n",
      "lambda_min tensor(2.7479e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 850 | time / epoch 33.75s | loss 90.31 \n",
      "lambda_min tensor(2.3943e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 851 | time / epoch 33.90s | loss 90.30 \n",
      "lambda_min tensor(2.9735e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 852 | time / epoch 33.66s | loss 90.30 \n",
      "lambda_min tensor(2.1599e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 853 | time / epoch 33.69s | loss 90.30 \n",
      "lambda_min tensor(2.0062e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 854 | time / epoch 33.92s | loss 90.30 \n",
      "lambda_min tensor(2.2434e-05-4.2221e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 855 | time / epoch 34.06s | loss 90.30 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.7070e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 856 | time / epoch 33.92s | loss 90.30 \n",
      "lambda_min tensor(2.1969e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 857 | time / epoch 34.14s | loss 90.29 \n",
      "lambda_min tensor(2.4596e-05-3.8044e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 858 | time / epoch 33.54s | loss 90.29 \n",
      "lambda_min tensor(2.6864e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 859 | time / epoch 33.51s | loss 90.29 \n",
      "lambda_min tensor(2.3791e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 860 | time / epoch 33.66s | loss 90.29 \n",
      "lambda_min tensor(2.4910e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 861 | time / epoch 33.68s | loss 90.29 \n",
      "lambda_min tensor(3.0965e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 862 | time / epoch 33.85s | loss 90.29 \n",
      "lambda_min tensor(2.7351e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 863 | time / epoch 33.86s | loss 90.28 \n",
      "lambda_min tensor(1.5845e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 864 | time / epoch 33.61s | loss 90.28 \n",
      "lambda_min tensor(2.0879e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 865 | time / epoch 33.75s | loss 90.28 \n",
      "lambda_min tensor(2.5244e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 866 | time / epoch 33.99s | loss 90.28 \n",
      "lambda_min tensor(1.9120e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 867 | time / epoch 34.23s | loss 90.28 \n",
      "lambda_min tensor(2.4027e-05-4.2916e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 868 | time / epoch 33.80s | loss 90.28 \n",
      "lambda_min tensor(2.2780e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 869 | time / epoch 34.05s | loss 90.27 \n",
      "lambda_min tensor(2.3819e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 870 | time / epoch 33.81s | loss 90.27 \n",
      "lambda_min tensor(2.8958e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 871 | time / epoch 34.00s | loss 90.27 \n",
      "lambda_min tensor(2.3775e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 872 | time / epoch 34.01s | loss 90.27 \n",
      "lambda_min tensor(2.9317e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 873 | time / epoch 33.97s | loss 90.27 \n",
      "lambda_min tensor(2.9645e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 874 | time / epoch 33.48s | loss 90.27 \n",
      "lambda_min tensor(2.6543e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 875 | time / epoch 33.71s | loss 90.27 \n",
      "lambda_min tensor(2.3388e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 876 | time / epoch 33.90s | loss 90.26 \n",
      "lambda_min tensor(1.9776e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 877 | time / epoch 33.63s | loss 90.26 \n",
      "lambda_min tensor(1.7306e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 878 | time / epoch 33.81s | loss 90.26 \n",
      "lambda_min tensor(2.6942e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 879 | time / epoch 34.71s | loss 90.26 \n",
      "lambda_min tensor(2.7427e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 880 | time / epoch 33.68s | loss 90.26 \n",
      "lambda_min tensor(1.9722e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 881 | time / epoch 33.42s | loss 90.26 \n",
      "lambda_min tensor(2.4812e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 882 | time / epoch 33.73s | loss 90.25 \n",
      "lambda_min tensor(2.0199e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 883 | time / epoch 34.14s | loss 90.25 \n",
      "lambda_min tensor(2.4310e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 884 | time / epoch 34.15s | loss 90.25 \n",
      "lambda_min tensor(2.2207e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 885 | time / epoch 34.39s | loss 90.25 \n",
      "lambda_min tensor(2.3275e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 886 | time / epoch 34.18s | loss 90.25 \n",
      "lambda_min tensor(2.2964e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 887 | time / epoch 33.82s | loss 90.25 \n",
      "lambda_min tensor(2.4374e-05-3.6394e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 888 | time / epoch 33.87s | loss 90.24 \n",
      "lambda_min tensor(2.9559e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 889 | time / epoch 33.87s | loss 90.24 \n",
      "lambda_min tensor(2.3051e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 890 | time / epoch 33.86s | loss 90.24 \n",
      "lambda_min tensor(2.6600e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 891 | time / epoch 34.06s | loss 90.24 \n",
      "lambda_min tensor(4.9204e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 892 | time / epoch 33.52s | loss 90.24 \n",
      "lambda_min tensor(2.3601e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 893 | time / epoch 33.63s | loss 90.24 \n",
      "lambda_min tensor(2.4223e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 894 | time / epoch 33.80s | loss 90.23 \n",
      "lambda_min tensor(2.3765e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 895 | time / epoch 33.62s | loss 90.23 \n",
      "lambda_min tensor(2.7388e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 896 | time / epoch 33.55s | loss 90.23 \n",
      "lambda_min tensor(2.7549e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 897 | time / epoch 33.69s | loss 90.23 \n",
      "lambda_min tensor(2.4592e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 898 | time / epoch 33.86s | loss 90.23 \n",
      "lambda_min tensor(2.2760e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 899 | time / epoch 33.87s | loss 90.23 \n",
      "lambda_min tensor(2.1635e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 900 | time / epoch 33.76s | loss 90.22 \n",
      "lambda_min tensor(1.8131e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 901 | time / epoch 33.72s | loss 90.22 \n",
      "lambda_min tensor(2.1407e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 902 | time / epoch 33.87s | loss 90.22 \n",
      "lambda_min tensor(3.1176e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 903 | time / epoch 34.24s | loss 90.22 \n",
      "lambda_min tensor(4.1906e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 904 | time / epoch 34.03s | loss 90.22 \n",
      "lambda_min tensor(2.3241e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 905 | time / epoch 33.74s | loss 90.22 \n",
      "lambda_min tensor(2.2337e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 906 | time / epoch 33.79s | loss 90.21 \n",
      "lambda_min tensor(2.5024e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 907 | time / epoch 33.62s | loss 90.21 \n",
      "lambda_min tensor(2.3786e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 908 | time / epoch 33.55s | loss 90.21 \n",
      "lambda_min tensor(2.1373e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 909 | time / epoch 34.05s | loss 90.21 \n",
      "lambda_min tensor(2.3519e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 910 | time / epoch 33.77s | loss 90.21 \n",
      "lambda_min tensor(2.4204e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 911 | time / epoch 34.24s | loss 90.21 \n",
      "lambda_min tensor(2.3224e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 912 | time / epoch 33.89s | loss 90.20 \n",
      "lambda_min tensor(2.9367e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 913 | time / epoch 33.90s | loss 90.20 \n",
      "lambda_min tensor(2.6969e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 914 | time / epoch 33.78s | loss 90.20 \n",
      "lambda_min tensor(2.4147e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 915 | time / epoch 33.89s | loss 90.20 \n",
      "lambda_min tensor(2.2817e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 916 | time / epoch 33.68s | loss 90.20 \n",
      "lambda_min tensor(2.4347e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 917 | time / epoch 33.79s | loss 90.20 \n",
      "lambda_min tensor(2.2178e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 918 | time / epoch 33.66s | loss 90.20 \n",
      "lambda_min tensor(2.2835e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 919 | time / epoch 33.92s | loss 90.19 \n",
      "lambda_min tensor(2.8420e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 920 | time / epoch 33.90s | loss 90.19 \n",
      "lambda_min tensor(2.6642e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 921 | time / epoch 33.97s | loss 90.19 \n",
      "lambda_min tensor(1.6330e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 922 | time / epoch 34.12s | loss 90.19 \n",
      "lambda_min tensor(2.5707e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 923 | time / epoch 34.23s | loss 90.19 \n",
      "lambda_min tensor(2.1630e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 924 | time / epoch 33.99s | loss 90.19 \n",
      "lambda_min tensor(1.9170e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 925 | time / epoch 34.33s | loss 90.18 \n",
      "lambda_min tensor(2.2246e-05-3.3122e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 926 | time / epoch 34.45s | loss 90.18 \n",
      "lambda_min tensor(2.5038e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 927 | time / epoch 33.73s | loss 90.18 \n",
      "lambda_min tensor(2.5360e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 928 | time / epoch 33.80s | loss 90.18 \n",
      "lambda_min tensor(2.0866e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 929 | time / epoch 33.75s | loss 90.18 \n",
      "lambda_min tensor(2.1785e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 930 | time / epoch 33.77s | loss 90.18 \n",
      "lambda_min tensor(2.3216e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 931 | time / epoch 33.88s | loss 90.17 \n",
      "lambda_min tensor(2.2263e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 932 | time / epoch 34.28s | loss 90.17 \n",
      "lambda_min tensor(2.4527e-05-2.4620e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 933 | time / epoch 33.52s | loss 90.17 \n",
      "lambda_min tensor(2.5113e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 934 | time / epoch 33.82s | loss 90.17 \n",
      "lambda_min tensor(2.4723e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 935 | time / epoch 34.07s | loss 90.17 \n",
      "lambda_min tensor(2.6809e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 936 | time / epoch 34.01s | loss 90.17 \n",
      "lambda_min tensor(2.4505e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 937 | time / epoch 33.90s | loss 90.16 \n",
      "lambda_min tensor(2.3401e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 938 | time / epoch 33.94s | loss 90.16 \n",
      "lambda_min tensor(2.0969e-05-3.6893e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 939 | time / epoch 33.92s | loss 90.16 \n",
      "lambda_min tensor(2.7271e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 940 | time / epoch 33.76s | loss 90.16 \n",
      "lambda_min tensor(2.3260e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 941 | time / epoch 33.41s | loss 90.16 \n",
      "lambda_min tensor(2.6886e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 942 | time / epoch 33.64s | loss 90.16 \n",
      "lambda_min tensor(2.7405e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 943 | time / epoch 34.01s | loss 90.15 \n",
      "lambda_min tensor(2.8973e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 944 | time / epoch 33.89s | loss 90.15 \n",
      "lambda_min tensor(2.3553e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 945 | time / epoch 33.99s | loss 90.15 \n",
      "lambda_min tensor(1.9238e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 946 | time / epoch 33.98s | loss 90.15 \n",
      "lambda_min tensor(2.1672e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 947 | time / epoch 34.10s | loss 90.15 \n",
      "lambda_min tensor(3.5400e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 948 | time / epoch 33.81s | loss 90.15 \n",
      "lambda_min tensor(2.5798e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 949 | time / epoch 33.70s | loss 90.15 \n",
      "lambda_min tensor(2.2057e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 950 | time / epoch 33.89s | loss 90.14 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.3012e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 951 | time / epoch 33.97s | loss 90.14 \n",
      "lambda_min tensor(4.0565e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 952 | time / epoch 34.00s | loss 90.14 \n",
      "lambda_min tensor(1.8608e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 953 | time / epoch 33.62s | loss 90.14 \n",
      "lambda_min tensor(2.3165e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 954 | time / epoch 34.11s | loss 90.14 \n",
      "lambda_min tensor(2.5459e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 955 | time / epoch 33.99s | loss 90.14 \n",
      "lambda_min tensor(1.9149e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 956 | time / epoch 33.88s | loss 90.13 \n",
      "lambda_min tensor(2.4844e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 957 | time / epoch 34.12s | loss 90.13 \n",
      "lambda_min tensor(2.2895e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 958 | time / epoch 33.86s | loss 90.13 \n",
      "lambda_min tensor(2.1196e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 959 | time / epoch 33.79s | loss 90.13 \n",
      "lambda_min tensor(2.2559e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 960 | time / epoch 34.13s | loss 90.13 \n",
      "lambda_min tensor(2.3847e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 961 | time / epoch 33.83s | loss 90.13 \n",
      "lambda_min tensor(2.5546e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 962 | time / epoch 33.85s | loss 90.12 \n",
      "lambda_min tensor(2.1646e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 963 | time / epoch 34.08s | loss 90.12 \n",
      "lambda_min tensor(2.7792e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 964 | time / epoch 33.96s | loss 90.12 \n",
      "lambda_min tensor(2.2902e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 965 | time / epoch 33.93s | loss 90.12 \n",
      "lambda_min tensor(2.3548e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 966 | time / epoch 34.13s | loss 90.12 \n",
      "lambda_min tensor(2.8947e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 967 | time / epoch 33.53s | loss 90.12 \n",
      "lambda_min tensor(2.6592e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 968 | time / epoch 33.83s | loss 90.12 \n",
      "lambda_min tensor(2.3025e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 969 | time / epoch 33.95s | loss 90.11 \n",
      "lambda_min tensor(2.2204e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 970 | time / epoch 33.48s | loss 90.11 \n",
      "lambda_min tensor(2.7041e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 971 | time / epoch 33.93s | loss 90.11 \n",
      "lambda_min tensor(2.1182e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 972 | time / epoch 33.83s | loss 90.11 \n",
      "lambda_min tensor(2.4076e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 973 | time / epoch 34.02s | loss 90.11 \n",
      "lambda_min tensor(3.0533e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 974 | time / epoch 33.85s | loss 90.11 \n",
      "lambda_min tensor(4.7712e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 975 | time / epoch 33.99s | loss 90.10 \n",
      "lambda_min tensor(2.0785e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 976 | time / epoch 33.94s | loss 90.10 \n",
      "lambda_min tensor(2.3378e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 977 | time / epoch 33.45s | loss 90.10 \n",
      "lambda_min tensor(2.3627e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 978 | time / epoch 34.10s | loss 90.10 \n",
      "lambda_min tensor(2.3224e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 979 | time / epoch 33.82s | loss 90.10 \n",
      "lambda_min tensor(2.4970e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 980 | time / epoch 34.13s | loss 90.10 \n",
      "lambda_min tensor(2.5362e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 981 | time / epoch 33.96s | loss 90.09 \n",
      "lambda_min tensor(2.6833e-05-1.5197e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 982 | time / epoch 34.13s | loss 90.09 \n",
      "lambda_min tensor(1.2861e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 983 | time / epoch 33.73s | loss 90.09 \n",
      "lambda_min tensor(2.3626e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 984 | time / epoch 33.95s | loss 90.09 \n",
      "lambda_min tensor(4.7327e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 985 | time / epoch 33.96s | loss 90.09 \n",
      "lambda_min tensor(2.6751e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 986 | time / epoch 33.85s | loss 90.09 \n",
      "lambda_min tensor(2.3433e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 987 | time / epoch 33.83s | loss 90.09 \n",
      "lambda_min tensor(2.6444e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 988 | time / epoch 34.29s | loss 90.08 \n",
      "lambda_min tensor(1.9617e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 989 | time / epoch 33.49s | loss 90.08 \n",
      "lambda_min tensor(2.0941e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 990 | time / epoch 33.81s | loss 90.08 \n",
      "lambda_min tensor(2.0163e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 991 | time / epoch 33.86s | loss 90.08 \n",
      "lambda_min tensor(2.4250e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 992 | time / epoch 35.13s | loss 90.08 \n",
      "lambda_min tensor(2.7088e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 993 | time / epoch 33.91s | loss 90.08 \n",
      "lambda_min tensor(2.2533e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 994 | time / epoch 33.75s | loss 90.07 \n",
      "lambda_min tensor(2.1112e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 995 | time / epoch 33.80s | loss 90.07 \n",
      "lambda_min tensor(3.7402e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 996 | time / epoch 33.93s | loss 90.07 \n",
      "lambda_min tensor(1.8388e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 997 | time / epoch 34.07s | loss 90.07 \n",
      "lambda_min tensor(1.8709e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 998 | time / epoch 34.32s | loss 90.07 \n",
      "lambda_min tensor(2.4408e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 999 | time / epoch 33.86s | loss 90.07 \n",
      "lambda_min tensor(3.7506e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1000 | time / epoch 33.92s | loss 90.07 \n",
      "lambda_min tensor(2.0887e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1001 | time / epoch 33.49s | loss 90.06 \n",
      "lambda_min tensor(2.5376e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1002 | time / epoch 34.13s | loss 90.06 \n",
      "lambda_min tensor(2.5196e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1003 | time / epoch 33.67s | loss 90.06 \n",
      "lambda_min tensor(2.0854e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1004 | time / epoch 34.07s | loss 90.06 \n",
      "lambda_min tensor(2.5908e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1005 | time / epoch 33.85s | loss 90.06 \n",
      "lambda_min tensor(3.0086e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1006 | time / epoch 34.14s | loss 90.06 \n",
      "lambda_min tensor(1.9089e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1007 | time / epoch 34.18s | loss 90.05 \n",
      "lambda_min tensor(2.1945e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1008 | time / epoch 33.81s | loss 90.05 \n",
      "lambda_min tensor(2.0703e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1009 | time / epoch 33.63s | loss 90.05 \n",
      "lambda_min tensor(2.2595e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1010 | time / epoch 34.05s | loss 90.05 \n",
      "lambda_min tensor(2.5357e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1011 | time / epoch 34.03s | loss 90.05 \n",
      "lambda_min tensor(2.4788e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1012 | time / epoch 33.71s | loss 90.05 \n",
      "lambda_min tensor(2.4772e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1013 | time / epoch 33.75s | loss 90.04 \n",
      "lambda_min tensor(2.1742e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1014 | time / epoch 33.80s | loss 90.04 \n",
      "lambda_min tensor(2.3854e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1015 | time / epoch 33.94s | loss 90.04 \n",
      "lambda_min tensor(2.6070e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1016 | time / epoch 33.64s | loss 90.04 \n",
      "lambda_min tensor(3.5070e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1017 | time / epoch 33.75s | loss 90.04 \n",
      "lambda_min tensor(2.5866e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1018 | time / epoch 33.99s | loss 90.04 \n",
      "lambda_min tensor(1.6861e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1019 | time / epoch 34.40s | loss 90.04 \n",
      "lambda_min tensor(2.3546e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1020 | time / epoch 34.04s | loss 90.03 \n",
      "lambda_min tensor(2.2138e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1021 | time / epoch 34.09s | loss 90.03 \n",
      "lambda_min tensor(2.7978e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1022 | time / epoch 34.45s | loss 90.03 \n",
      "lambda_min tensor(1.9631e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1023 | time / epoch 34.02s | loss 90.03 \n",
      "lambda_min tensor(2.4980e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1024 | time / epoch 34.11s | loss 90.03 \n",
      "lambda_min tensor(2.8585e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1025 | time / epoch 33.84s | loss 90.03 \n",
      "lambda_min tensor(3.0655e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1026 | time / epoch 34.01s | loss 90.02 \n",
      "lambda_min tensor(2.5459e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1027 | time / epoch 33.92s | loss 90.02 \n",
      "lambda_min tensor(2.7375e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1028 | time / epoch 34.41s | loss 90.02 \n",
      "lambda_min tensor(3.4049e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1029 | time / epoch 34.09s | loss 90.02 \n",
      "lambda_min tensor(1.9153e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1030 | time / epoch 34.48s | loss 90.02 \n",
      "lambda_min tensor(3.0655e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1031 | time / epoch 34.15s | loss 90.02 \n",
      "lambda_min tensor(2.1037e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1032 | time / epoch 34.20s | loss 90.02 \n",
      "lambda_min tensor(2.3547e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1033 | time / epoch 33.88s | loss 90.01 \n",
      "lambda_min tensor(1.9042e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1034 | time / epoch 33.92s | loss 90.01 \n",
      "lambda_min tensor(2.3462e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1035 | time / epoch 33.79s | loss 90.01 \n",
      "lambda_min tensor(2.4211e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1036 | time / epoch 33.79s | loss 90.01 \n",
      "lambda_min tensor(3.0443e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1037 | time / epoch 33.92s | loss 90.01 \n",
      "lambda_min tensor(3.0462e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1038 | time / epoch 33.71s | loss 90.01 \n",
      "lambda_min tensor(2.5257e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1039 | time / epoch 34.29s | loss 90.00 \n",
      "lambda_min tensor(2.4670e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1040 | time / epoch 33.64s | loss 90.00 \n",
      "lambda_min tensor(2.2664e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1041 | time / epoch 33.96s | loss 90.00 \n",
      "lambda_min tensor(2.7618e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1042 | time / epoch 34.11s | loss 90.00 \n",
      "lambda_min tensor(3.2084e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1043 | time / epoch 34.19s | loss 90.00 \n",
      "lambda_min tensor(2.4140e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1044 | time / epoch 33.79s | loss 90.00 \n",
      "lambda_min tensor(2.6506e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1045 | time / epoch 33.95s | loss 90.00 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.5382e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1046 | time / epoch 34.01s | loss 89.99 \n",
      "lambda_min tensor(3.1387e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1047 | time / epoch 33.83s | loss 89.99 \n",
      "lambda_min tensor(2.5701e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1048 | time / epoch 34.17s | loss 89.99 \n",
      "lambda_min tensor(2.6334e-05-9.6271e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1049 | time / epoch 34.59s | loss 89.99 \n",
      "lambda_min tensor(2.0217e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1050 | time / epoch 34.31s | loss 89.99 \n",
      "lambda_min tensor(2.7244e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1051 | time / epoch 34.41s | loss 89.99 \n",
      "lambda_min tensor(2.5491e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1052 | time / epoch 34.27s | loss 89.98 \n",
      "lambda_min tensor(1.9877e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1053 | time / epoch 33.89s | loss 89.98 \n",
      "lambda_min tensor(2.0650e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1054 | time / epoch 33.69s | loss 89.98 \n",
      "lambda_min tensor(1.9566e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1055 | time / epoch 33.98s | loss 89.98 \n",
      "lambda_min tensor(2.8425e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1056 | time / epoch 33.98s | loss 89.98 \n",
      "lambda_min tensor(2.1507e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1057 | time / epoch 33.47s | loss 89.98 \n",
      "lambda_min tensor(2.5851e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1058 | time / epoch 33.86s | loss 89.98 \n",
      "lambda_min tensor(2.3873e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1059 | time / epoch 33.85s | loss 89.97 \n",
      "lambda_min tensor(5.1416e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1060 | time / epoch 34.01s | loss 89.97 \n",
      "lambda_min tensor(2.5632e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1061 | time / epoch 33.77s | loss 89.97 \n",
      "lambda_min tensor(1.9976e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1062 | time / epoch 33.74s | loss 89.97 \n",
      "lambda_min tensor(2.9822e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1063 | time / epoch 33.88s | loss 89.97 \n",
      "lambda_min tensor(2.6200e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1064 | time / epoch 33.83s | loss 89.97 \n",
      "lambda_min tensor(1.9670e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1065 | time / epoch 33.84s | loss 89.96 \n",
      "lambda_min tensor(2.2955e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1066 | time / epoch 33.70s | loss 89.96 \n",
      "lambda_min tensor(1.9649e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1067 | time / epoch 33.89s | loss 89.96 \n",
      "lambda_min tensor(1.9479e-05-3.7899e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1068 | time / epoch 34.12s | loss 89.96 \n",
      "lambda_min tensor(2.3025e-05-5.9975e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1069 | time / epoch 34.27s | loss 89.96 \n",
      "lambda_min tensor(2.4976e-05-7.8278e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1070 | time / epoch 33.85s | loss 89.96 \n",
      "lambda_min tensor(2.0108e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1071 | time / epoch 34.27s | loss 89.96 \n",
      "lambda_min tensor(2.0488e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1072 | time / epoch 34.89s | loss 89.95 \n",
      "lambda_min tensor(2.1371e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1073 | time / epoch 33.97s | loss 89.95 \n",
      "lambda_min tensor(2.5427e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1074 | time / epoch 33.63s | loss 89.95 \n",
      "lambda_min tensor(4.7207e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1075 | time / epoch 34.13s | loss 89.95 \n",
      "lambda_min tensor(2.0787e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1076 | time / epoch 33.65s | loss 89.95 \n",
      "lambda_min tensor(1.8123e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1077 | time / epoch 34.07s | loss 89.95 \n",
      "lambda_min tensor(2.4627e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1078 | time / epoch 34.00s | loss 89.95 \n",
      "lambda_min tensor(2.8533e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1079 | time / epoch 33.84s | loss 89.94 \n",
      "lambda_min tensor(2.1459e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1080 | time / epoch 33.75s | loss 89.94 \n",
      "lambda_min tensor(2.4826e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1081 | time / epoch 33.99s | loss 89.94 \n",
      "lambda_min tensor(2.5138e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1082 | time / epoch 33.68s | loss 89.94 \n",
      "lambda_min tensor(1.9062e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1083 | time / epoch 34.14s | loss 89.94 \n",
      "lambda_min tensor(2.2812e-05-6.9713e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1084 | time / epoch 34.01s | loss 89.94 \n",
      "lambda_min tensor(2.1227e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1085 | time / epoch 34.10s | loss 89.93 \n",
      "lambda_min tensor(1.7400e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1086 | time / epoch 33.93s | loss 89.93 \n",
      "lambda_min tensor(2.5117e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1087 | time / epoch 33.73s | loss 89.93 \n",
      "lambda_min tensor(2.4449e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1088 | time / epoch 34.02s | loss 89.93 \n",
      "lambda_min tensor(2.5055e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1089 | time / epoch 33.72s | loss 89.93 \n",
      "lambda_min tensor(2.1493e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1090 | time / epoch 33.66s | loss 89.93 \n",
      "lambda_min tensor(2.4271e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1091 | time / epoch 34.13s | loss 89.93 \n",
      "lambda_min tensor(2.4870e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1092 | time / epoch 34.10s | loss 89.92 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(4.8108e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1093 | time / epoch 34.44s | loss 89.92 \n",
      "lambda_min tensor(2.7535e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1094 | time / epoch 33.58s | loss 89.92 \n",
      "lambda_min tensor(2.5626e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1095 | time / epoch 34.22s | loss 89.92 \n",
      "lambda_min tensor(2.8246e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1096 | time / epoch 33.74s | loss 89.92 \n",
      "lambda_min tensor(1.9903e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1097 | time / epoch 33.99s | loss 89.92 \n",
      "lambda_min tensor(5.0049e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1098 | time / epoch 33.99s | loss 89.91 \n",
      "lambda_min tensor(2.5010e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1099 | time / epoch 33.65s | loss 89.91 \n",
      "lambda_min tensor(2.6406e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1100 | time / epoch 34.45s | loss 89.91 \n",
      "lambda_min tensor(2.0945e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1101 | time / epoch 33.99s | loss 89.91 \n",
      "lambda_min tensor(4.3683e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1102 | time / epoch 33.89s | loss 89.91 \n",
      "lambda_min tensor(1.8808e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1103 | time / epoch 33.49s | loss 89.91 \n",
      "lambda_min tensor(2.2221e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1104 | time / epoch 33.90s | loss 89.91 \n",
      "lambda_min tensor(2.7542e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1105 | time / epoch 33.76s | loss 89.90 \n",
      "lambda_min tensor(2.4307e-05-6.1635e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1106 | time / epoch 33.78s | loss 89.90 \n",
      "lambda_min tensor(2.6332e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1107 | time / epoch 33.80s | loss 89.90 \n",
      "lambda_min tensor(2.4983e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1108 | time / epoch 34.07s | loss 89.90 \n",
      "lambda_min tensor(2.4536e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1109 | time / epoch 33.98s | loss 89.90 \n",
      "lambda_min tensor(2.4702e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1110 | time / epoch 34.31s | loss 89.90 \n",
      "lambda_min tensor(2.4312e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1111 | time / epoch 34.01s | loss 89.90 \n",
      "lambda_min tensor(2.4145e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1112 | time / epoch 33.98s | loss 89.89 \n",
      "lambda_min tensor(2.0717e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1113 | time / epoch 34.33s | loss 89.89 \n",
      "lambda_min tensor(2.1276e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1114 | time / epoch 34.21s | loss 89.89 \n",
      "lambda_min tensor(2.0411e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1115 | time / epoch 33.62s | loss 89.89 \n",
      "lambda_min tensor(2.5315e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1116 | time / epoch 33.86s | loss 89.89 \n",
      "lambda_min tensor(2.0373e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1117 | time / epoch 33.88s | loss 89.89 \n",
      "lambda_min tensor(3.1196e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1118 | time / epoch 34.20s | loss 89.88 \n",
      "lambda_min tensor(2.0053e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1119 | time / epoch 33.63s | loss 89.88 \n",
      "lambda_min tensor(2.1235e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1120 | time / epoch 33.87s | loss 89.88 \n",
      "lambda_min tensor(2.4937e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1121 | time / epoch 34.01s | loss 89.88 \n",
      "lambda_min tensor(2.7063e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1122 | time / epoch 34.16s | loss 89.88 \n",
      "lambda_min tensor(2.7808e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1123 | time / epoch 33.99s | loss 89.88 \n",
      "lambda_min tensor(2.0655e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1124 | time / epoch 33.67s | loss 89.88 \n",
      "lambda_min tensor(1.9068e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1125 | time / epoch 34.07s | loss 89.87 \n",
      "lambda_min tensor(2.6705e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1126 | time / epoch 34.26s | loss 89.87 \n",
      "lambda_min tensor(2.0213e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1127 | time / epoch 34.05s | loss 89.87 \n",
      "lambda_min tensor(2.4182e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1128 | time / epoch 33.73s | loss 89.87 \n",
      "lambda_min tensor(2.9042e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1129 | time / epoch 33.93s | loss 89.87 \n",
      "lambda_min tensor(1.9703e-05-2.1089e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1130 | time / epoch 33.80s | loss 89.87 \n",
      "lambda_min tensor(2.4026e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1131 | time / epoch 34.14s | loss 89.87 \n",
      "lambda_min tensor(1.9935e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1132 | time / epoch 33.71s | loss 89.86 \n",
      "lambda_min tensor(2.0457e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1133 | time / epoch 34.21s | loss 89.86 \n",
      "lambda_min tensor(2.3083e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1134 | time / epoch 33.91s | loss 89.86 \n",
      "lambda_min tensor(2.0185e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1135 | time / epoch 33.78s | loss 89.86 \n",
      "lambda_min tensor(2.4620e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1136 | time / epoch 34.04s | loss 89.86 \n",
      "lambda_min tensor(2.1547e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1137 | time / epoch 34.04s | loss 89.86 \n",
      "lambda_min tensor(2.5900e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1138 | time / epoch 34.09s | loss 89.86 \n",
      "lambda_min tensor(1.8889e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1139 | time / epoch 34.09s | loss 89.85 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.9724e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1140 | time / epoch 33.95s | loss 89.85 \n",
      "lambda_min tensor(2.3628e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1141 | time / epoch 33.86s | loss 89.85 \n",
      "lambda_min tensor(2.0430e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1142 | time / epoch 33.94s | loss 89.85 \n",
      "lambda_min tensor(2.5692e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1143 | time / epoch 34.31s | loss 89.85 \n",
      "lambda_min tensor(4.5359e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1144 | time / epoch 34.10s | loss 89.85 \n",
      "lambda_min tensor(2.8792e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1145 | time / epoch 33.80s | loss 89.84 \n",
      "lambda_min tensor(2.4133e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1146 | time / epoch 33.68s | loss 89.84 \n",
      "lambda_min tensor(2.7168e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1147 | time / epoch 33.89s | loss 89.84 \n",
      "lambda_min tensor(5.0413e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1148 | time / epoch 34.16s | loss 89.84 \n",
      "lambda_min tensor(2.3863e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1149 | time / epoch 33.78s | loss 89.84 \n",
      "lambda_min tensor(2.6464e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1150 | time / epoch 33.89s | loss 89.84 \n",
      "lambda_min tensor(2.8071e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1151 | time / epoch 33.72s | loss 89.84 \n",
      "lambda_min tensor(2.0303e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1152 | time / epoch 33.76s | loss 89.83 \n",
      "lambda_min tensor(2.6505e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1153 | time / epoch 34.31s | loss 89.83 \n",
      "lambda_min tensor(2.5156e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1154 | time / epoch 33.79s | loss 89.83 \n",
      "lambda_min tensor(2.0722e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1155 | time / epoch 33.73s | loss 89.83 \n",
      "lambda_min tensor(2.3827e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1156 | time / epoch 33.53s | loss 89.83 \n",
      "lambda_min tensor(2.5853e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1157 | time / epoch 33.36s | loss 89.83 \n",
      "lambda_min tensor(2.4211e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1158 | time / epoch 33.96s | loss 89.83 \n",
      "lambda_min tensor(2.5723e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1159 | time / epoch 33.69s | loss 89.82 \n",
      "lambda_min tensor(2.3530e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1160 | time / epoch 33.92s | loss 89.82 \n",
      "lambda_min tensor(2.6983e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1161 | time / epoch 33.89s | loss 89.82 \n",
      "lambda_min tensor(2.5584e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1162 | time / epoch 34.01s | loss 89.82 \n",
      "lambda_min tensor(2.5866e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1163 | time / epoch 33.89s | loss 89.82 \n",
      "lambda_min tensor(2.8617e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1164 | time / epoch 34.04s | loss 89.82 \n",
      "lambda_min tensor(2.4149e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1165 | time / epoch 33.69s | loss 89.82 \n",
      "lambda_min tensor(1.9151e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1166 | time / epoch 33.59s | loss 89.81 \n",
      "lambda_min tensor(2.9075e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1167 | time / epoch 34.00s | loss 89.81 \n",
      "lambda_min tensor(2.3480e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1168 | time / epoch 33.67s | loss 89.81 \n",
      "lambda_min tensor(2.2677e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1169 | time / epoch 33.71s | loss 89.81 \n",
      "lambda_min tensor(2.2256e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1170 | time / epoch 33.83s | loss 89.81 \n",
      "lambda_min tensor(2.4042e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1171 | time / epoch 33.90s | loss 89.81 \n",
      "lambda_min tensor(2.3675e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1172 | time / epoch 33.64s | loss 89.81 \n",
      "lambda_min tensor(4.9960e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1173 | time / epoch 33.86s | loss 89.80 \n",
      "lambda_min tensor(2.4115e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1174 | time / epoch 33.74s | loss 89.80 \n",
      "lambda_min tensor(4.6625e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1175 | time / epoch 34.53s | loss 89.80 \n",
      "lambda_min tensor(2.7023e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1176 | time / epoch 33.83s | loss 89.80 \n",
      "lambda_min tensor(2.5310e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1177 | time / epoch 33.59s | loss 89.80 \n",
      "lambda_min tensor(3.8646e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1178 | time / epoch 33.66s | loss 89.80 \n",
      "lambda_min tensor(2.4137e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1179 | time / epoch 34.08s | loss 89.79 \n",
      "lambda_min tensor(4.6516e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1180 | time / epoch 34.40s | loss 89.79 \n",
      "lambda_min tensor(2.1774e-05-2.1628e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1181 | time / epoch 34.41s | loss 89.79 \n",
      "lambda_min tensor(2.2439e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1182 | time / epoch 33.73s | loss 89.79 \n",
      "lambda_min tensor(2.4955e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1183 | time / epoch 33.67s | loss 89.79 \n",
      "lambda_min tensor(1.9244e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1184 | time / epoch 33.97s | loss 89.79 \n",
      "lambda_min tensor(1.8525e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1185 | time / epoch 33.75s | loss 89.79 \n",
      "lambda_min tensor(2.8795e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1186 | time / epoch 34.42s | loss 89.78 \n",
      "lambda_min tensor(2.0209e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1187 | time / epoch 34.64s | loss 89.78 \n",
      "lambda_min tensor(2.3755e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1188 | time / epoch 34.10s | loss 89.78 \n",
      "lambda_min tensor(2.9318e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1189 | time / epoch 33.68s | loss 89.78 \n",
      "lambda_min tensor(2.0597e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1190 | time / epoch 33.78s | loss 89.78 \n",
      "lambda_min tensor(2.6127e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1191 | time / epoch 34.01s | loss 89.78 \n",
      "lambda_min tensor(2.2850e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1192 | time / epoch 34.01s | loss 89.78 \n",
      "lambda_min tensor(2.7210e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1193 | time / epoch 33.98s | loss 89.77 \n",
      "lambda_min tensor(2.4482e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1194 | time / epoch 33.70s | loss 89.77 \n",
      "lambda_min tensor(2.2256e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1195 | time / epoch 34.01s | loss 89.77 \n",
      "lambda_min tensor(2.6847e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1196 | time / epoch 33.65s | loss 89.77 \n",
      "lambda_min tensor(2.3586e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1197 | time / epoch 34.01s | loss 89.77 \n",
      "lambda_min tensor(2.5323e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1198 | time / epoch 34.17s | loss 89.77 \n",
      "lambda_min tensor(2.9927e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1199 | time / epoch 34.06s | loss 89.77 \n",
      "lambda_min tensor(1.9365e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1200 | time / epoch 33.87s | loss 89.76 \n",
      "lambda_min tensor(2.5523e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1201 | time / epoch 34.04s | loss 89.76 \n",
      "lambda_min tensor(2.4086e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1202 | time / epoch 34.33s | loss 89.76 \n",
      "lambda_min tensor(2.3957e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1203 | time / epoch 33.89s | loss 89.76 \n",
      "lambda_min tensor(2.7857e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1204 | time / epoch 33.74s | loss 89.76 \n",
      "lambda_min tensor(2.4091e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1205 | time / epoch 33.73s | loss 89.76 \n",
      "lambda_min tensor(2.0239e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1206 | time / epoch 33.69s | loss 89.76 \n",
      "lambda_min tensor(5.0471e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1207 | time / epoch 33.89s | loss 89.75 \n",
      "lambda_min tensor(1.7642e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1208 | time / epoch 33.62s | loss 89.75 \n",
      "lambda_min tensor(2.0461e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1209 | time / epoch 34.17s | loss 89.75 \n",
      "lambda_min tensor(4.2940e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1210 | time / epoch 34.44s | loss 89.75 \n",
      "lambda_min tensor(1.9727e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1211 | time / epoch 33.88s | loss 89.75 \n",
      "lambda_min tensor(1.9701e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1212 | time / epoch 33.67s | loss 89.75 \n",
      "lambda_min tensor(1.9910e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1213 | time / epoch 34.16s | loss 89.75 \n",
      "lambda_min tensor(2.3740e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1214 | time / epoch 33.86s | loss 89.74 \n",
      "lambda_min tensor(2.2646e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1215 | time / epoch 33.76s | loss 89.74 \n",
      "lambda_min tensor(2.9447e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1216 | time / epoch 33.69s | loss 89.74 \n",
      "lambda_min tensor(2.3992e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1217 | time / epoch 33.64s | loss 89.74 \n",
      "lambda_min tensor(2.2752e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1218 | time / epoch 33.63s | loss 89.74 \n",
      "lambda_min tensor(1.8561e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1219 | time / epoch 33.94s | loss 89.74 \n",
      "lambda_min tensor(2.0103e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1220 | time / epoch 33.74s | loss 89.74 \n",
      "lambda_min tensor(2.5193e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1221 | time / epoch 33.92s | loss 89.73 \n",
      "lambda_min tensor(2.6123e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1222 | time / epoch 34.42s | loss 89.73 \n",
      "lambda_min tensor(2.5895e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1223 | time / epoch 33.70s | loss 89.73 \n",
      "lambda_min tensor(2.6530e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1224 | time / epoch 33.85s | loss 89.73 \n",
      "lambda_min tensor(2.1901e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1225 | time / epoch 33.79s | loss 89.73 \n",
      "lambda_min tensor(2.3862e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1226 | time / epoch 33.63s | loss 89.73 \n",
      "lambda_min tensor(2.6264e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1227 | time / epoch 33.94s | loss 89.73 \n",
      "lambda_min tensor(2.3488e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1228 | time / epoch 33.62s | loss 89.72 \n",
      "lambda_min tensor(2.2025e-05-3.9679e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1229 | time / epoch 33.67s | loss 89.72 \n",
      "lambda_min tensor(2.7509e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1230 | time / epoch 33.81s | loss 89.72 \n",
      "lambda_min tensor(2.1281e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1231 | time / epoch 34.03s | loss 89.72 \n",
      "lambda_min tensor(2.1996e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1232 | time / epoch 33.53s | loss 89.72 \n",
      "lambda_min tensor(5.8405e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1233 | time / epoch 33.64s | loss 89.72 \n",
      "lambda_min tensor(1.9464e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1234 | time / epoch 33.99s | loss 89.72 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.3166e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1235 | time / epoch 34.48s | loss 89.71 \n",
      "lambda_min tensor(1.9396e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1236 | time / epoch 33.67s | loss 89.71 \n",
      "lambda_min tensor(2.7068e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1237 | time / epoch 33.52s | loss 89.71 \n",
      "lambda_min tensor(2.7691e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1238 | time / epoch 33.87s | loss 89.71 \n",
      "lambda_min tensor(2.7153e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1239 | time / epoch 33.85s | loss 89.71 \n",
      "lambda_min tensor(2.3927e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1240 | time / epoch 33.73s | loss 89.71 \n",
      "lambda_min tensor(2.2447e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1241 | time / epoch 33.77s | loss 89.71 \n",
      "lambda_min tensor(6.3216e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1242 | time / epoch 34.89s | loss 89.70 \n",
      "lambda_min tensor(2.0425e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1243 | time / epoch 33.95s | loss 89.70 \n",
      "lambda_min tensor(3.0630e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1244 | time / epoch 34.20s | loss 89.70 \n",
      "lambda_min tensor(2.4583e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1245 | time / epoch 34.08s | loss 89.70 \n",
      "lambda_min tensor(2.4527e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1246 | time / epoch 34.12s | loss 89.70 \n",
      "lambda_min tensor(2.1939e-05-1.1713e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1247 | time / epoch 33.61s | loss 89.70 \n",
      "lambda_min tensor(2.5359e-05-1.2612e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1248 | time / epoch 33.71s | loss 89.70 \n",
      "lambda_min tensor(3.8775e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1249 | time / epoch 33.88s | loss 89.69 \n",
      "lambda_min tensor(2.5036e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1250 | time / epoch 33.98s | loss 89.69 \n",
      "lambda_min tensor(1.8646e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1251 | time / epoch 33.54s | loss 89.69 \n",
      "lambda_min tensor(2.2654e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1252 | time / epoch 33.70s | loss 89.69 \n",
      "lambda_min tensor(2.6150e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1253 | time / epoch 33.67s | loss 89.69 \n",
      "lambda_min tensor(2.3311e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1254 | time / epoch 33.60s | loss 89.69 \n",
      "lambda_min tensor(2.2934e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1255 | time / epoch 34.29s | loss 89.69 \n",
      "lambda_min tensor(1.7487e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1256 | time / epoch 34.01s | loss 89.68 \n",
      "lambda_min tensor(2.3137e-05-1.4188e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1257 | time / epoch 33.76s | loss 89.68 \n",
      "lambda_min tensor(2.6480e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1258 | time / epoch 34.02s | loss 89.68 \n",
      "lambda_min tensor(1.7997e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1259 | time / epoch 33.75s | loss 89.68 \n",
      "lambda_min tensor(1.8532e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1260 | time / epoch 33.85s | loss 89.68 \n",
      "lambda_min tensor(2.2062e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1261 | time / epoch 33.77s | loss 89.68 \n",
      "lambda_min tensor(2.1496e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1262 | time / epoch 33.98s | loss 89.68 \n",
      "lambda_min tensor(2.0976e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1263 | time / epoch 33.88s | loss 89.67 \n",
      "lambda_min tensor(2.3469e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1264 | time / epoch 33.72s | loss 89.67 \n",
      "lambda_min tensor(2.2837e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1265 | time / epoch 33.74s | loss 89.67 \n",
      "lambda_min tensor(2.2135e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1266 | time / epoch 33.92s | loss 89.67 \n",
      "lambda_min tensor(1.8605e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1267 | time / epoch 33.97s | loss 89.67 \n",
      "lambda_min tensor(1.9920e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1268 | time / epoch 33.77s | loss 89.67 \n",
      "lambda_min tensor(1.9460e-05-1.5770e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1269 | time / epoch 33.69s | loss 89.67 \n",
      "lambda_min tensor(2.2922e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1270 | time / epoch 33.70s | loss 89.66 \n",
      "lambda_min tensor(2.6520e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1271 | time / epoch 33.73s | loss 89.66 \n",
      "lambda_min tensor(2.4607e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1272 | time / epoch 34.35s | loss 89.66 \n",
      "lambda_min tensor(2.3432e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1273 | time / epoch 33.89s | loss 89.66 \n",
      "lambda_min tensor(2.7557e-05-1.1111e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1274 | time / epoch 34.02s | loss 89.66 \n",
      "lambda_min tensor(2.3832e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1275 | time / epoch 33.80s | loss 89.66 \n",
      "lambda_min tensor(4.4803e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1276 | time / epoch 34.29s | loss 89.66 \n",
      "lambda_min tensor(2.2856e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1277 | time / epoch 33.90s | loss 89.65 \n",
      "lambda_min tensor(2.2774e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1278 | time / epoch 34.00s | loss 89.65 \n",
      "lambda_min tensor(2.2536e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1279 | time / epoch 34.32s | loss 89.65 \n",
      "lambda_min tensor(3.4836e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1280 | time / epoch 33.64s | loss 89.65 \n",
      "lambda_min tensor(2.5881e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1281 | time / epoch 33.95s | loss 89.65 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.3008e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1282 | time / epoch 34.28s | loss 89.65 \n",
      "lambda_min tensor(2.2920e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1283 | time / epoch 33.67s | loss 89.65 \n",
      "lambda_min tensor(2.4600e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1284 | time / epoch 33.88s | loss 89.64 \n",
      "lambda_min tensor(2.4706e-05-4.0037e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1285 | time / epoch 33.47s | loss 89.64 \n",
      "lambda_min tensor(2.2706e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1286 | time / epoch 33.91s | loss 89.64 \n",
      "lambda_min tensor(1.9504e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1287 | time / epoch 33.88s | loss 89.64 \n",
      "lambda_min tensor(2.6363e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1288 | time / epoch 33.88s | loss 89.64 \n",
      "lambda_min tensor(1.9690e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1289 | time / epoch 33.93s | loss 89.64 \n",
      "lambda_min tensor(2.0810e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1290 | time / epoch 33.93s | loss 89.64 \n",
      "lambda_min tensor(2.7605e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1291 | time / epoch 33.78s | loss 89.63 \n",
      "lambda_min tensor(2.2929e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1292 | time / epoch 33.75s | loss 89.63 \n",
      "lambda_min tensor(4.3513e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1293 | time / epoch 33.84s | loss 89.63 \n",
      "lambda_min tensor(2.3952e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1294 | time / epoch 33.68s | loss 89.63 \n",
      "lambda_min tensor(2.2805e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1295 | time / epoch 33.87s | loss 89.63 \n",
      "lambda_min tensor(1.8967e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1296 | time / epoch 33.70s | loss 89.63 \n",
      "lambda_min tensor(2.0194e-05-3.5632e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1297 | time / epoch 33.89s | loss 89.63 \n",
      "lambda_min tensor(1.9902e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1298 | time / epoch 33.61s | loss 89.62 \n",
      "lambda_min tensor(2.0752e-05-4.8541e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1299 | time / epoch 33.76s | loss 89.62 \n",
      "lambda_min tensor(4.8728e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1300 | time / epoch 33.82s | loss 89.62 \n",
      "lambda_min tensor(3.9593e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1301 | time / epoch 33.83s | loss 89.62 \n",
      "lambda_min tensor(2.2640e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1302 | time / epoch 33.75s | loss 89.62 \n",
      "lambda_min tensor(2.5142e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1303 | time / epoch 33.84s | loss 89.62 \n",
      "lambda_min tensor(2.4885e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1304 | time / epoch 33.84s | loss 89.62 \n",
      "lambda_min tensor(2.1294e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1305 | time / epoch 33.85s | loss 89.62 \n",
      "lambda_min tensor(2.2596e-05-2.4542e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1306 | time / epoch 33.70s | loss 89.61 \n",
      "lambda_min tensor(2.2291e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1307 | time / epoch 34.01s | loss 89.61 \n",
      "lambda_min tensor(2.3619e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1308 | time / epoch 33.51s | loss 89.61 \n",
      "lambda_min tensor(2.4020e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1309 | time / epoch 33.73s | loss 89.61 \n",
      "lambda_min tensor(2.2749e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1310 | time / epoch 34.00s | loss 89.61 \n",
      "lambda_min tensor(2.5306e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1311 | time / epoch 33.58s | loss 89.61 \n",
      "lambda_min tensor(2.4134e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1312 | time / epoch 33.82s | loss 89.61 \n",
      "lambda_min tensor(2.4574e-05-3.4429e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1313 | time / epoch 33.98s | loss 89.60 \n",
      "lambda_min tensor(2.2966e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1314 | time / epoch 33.64s | loss 89.60 \n",
      "lambda_min tensor(2.5361e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1315 | time / epoch 33.84s | loss 89.60 \n",
      "lambda_min tensor(2.2271e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1316 | time / epoch 33.71s | loss 89.60 \n",
      "lambda_min tensor(2.2718e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1317 | time / epoch 33.47s | loss 89.60 \n",
      "lambda_min tensor(2.3371e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1318 | time / epoch 33.52s | loss 89.60 \n",
      "lambda_min tensor(2.3881e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1319 | time / epoch 33.97s | loss 89.60 \n",
      "lambda_min tensor(3.5689e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1320 | time / epoch 33.74s | loss 89.59 \n",
      "lambda_min tensor(2.3262e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1321 | time / epoch 33.77s | loss 89.59 \n",
      "lambda_min tensor(2.2725e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1322 | time / epoch 33.77s | loss 89.59 \n",
      "lambda_min tensor(2.5262e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1323 | time / epoch 33.82s | loss 89.59 \n",
      "lambda_min tensor(2.8027e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1324 | time / epoch 33.45s | loss 89.59 \n",
      "lambda_min tensor(2.3799e-05-3.6821e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1325 | time / epoch 33.44s | loss 89.59 \n",
      "lambda_min tensor(2.5536e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1326 | time / epoch 33.43s | loss 89.59 \n",
      "lambda_min tensor(2.2261e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1327 | time / epoch 33.89s | loss 89.58 \n",
      "lambda_min tensor(3.0080e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1328 | time / epoch 33.88s | loss 89.58 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.2901e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1329 | time / epoch 33.80s | loss 89.58 \n",
      "lambda_min tensor(2.5664e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1330 | time / epoch 33.90s | loss 89.58 \n",
      "lambda_min tensor(2.6902e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1331 | time / epoch 33.81s | loss 89.58 \n",
      "lambda_min tensor(2.7206e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1332 | time / epoch 33.65s | loss 89.58 \n",
      "lambda_min tensor(3.5864e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1333 | time / epoch 34.50s | loss 89.58 \n",
      "lambda_min tensor(1.9177e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1334 | time / epoch 33.78s | loss 89.57 \n",
      "lambda_min tensor(2.4677e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1335 | time / epoch 34.03s | loss 89.57 \n",
      "lambda_min tensor(2.6396e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1336 | time / epoch 33.89s | loss 89.57 \n",
      "lambda_min tensor(1.9967e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1337 | time / epoch 33.78s | loss 89.57 \n",
      "lambda_min tensor(2.4340e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1338 | time / epoch 33.84s | loss 89.57 \n",
      "lambda_min tensor(2.2974e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1339 | time / epoch 33.82s | loss 89.57 \n",
      "lambda_min tensor(2.5821e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1340 | time / epoch 33.78s | loss 89.57 \n",
      "lambda_min tensor(2.5169e-05-8.6356e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1341 | time / epoch 33.85s | loss 89.57 \n",
      "lambda_min tensor(2.3617e-05-4.8188e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1342 | time / epoch 34.47s | loss 89.56 \n",
      "lambda_min tensor(2.5111e-05-3.5816e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1343 | time / epoch 34.11s | loss 89.56 \n",
      "lambda_min tensor(2.3946e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1344 | time / epoch 34.15s | loss 89.56 \n",
      "lambda_min tensor(2.2950e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1345 | time / epoch 33.75s | loss 89.56 \n",
      "lambda_min tensor(2.5937e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1346 | time / epoch 33.90s | loss 89.56 \n",
      "lambda_min tensor(2.1473e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1347 | time / epoch 33.68s | loss 89.56 \n",
      "lambda_min tensor(2.7852e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1348 | time / epoch 34.00s | loss 89.56 \n",
      "lambda_min tensor(2.2310e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1349 | time / epoch 33.88s | loss 89.55 \n",
      "lambda_min tensor(2.8527e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1350 | time / epoch 34.03s | loss 89.55 \n",
      "lambda_min tensor(2.8762e-05-2.6962e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1351 | time / epoch 33.83s | loss 89.55 \n",
      "lambda_min tensor(2.4882e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1352 | time / epoch 34.02s | loss 89.55 \n",
      "lambda_min tensor(2.8213e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1353 | time / epoch 34.17s | loss 89.55 \n",
      "lambda_min tensor(2.1823e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1354 | time / epoch 33.90s | loss 89.55 \n",
      "lambda_min tensor(2.6105e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1355 | time / epoch 33.77s | loss 89.55 \n",
      "lambda_min tensor(2.6176e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1356 | time / epoch 33.75s | loss 89.54 \n",
      "lambda_min tensor(1.9036e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1357 | time / epoch 33.91s | loss 89.54 \n",
      "lambda_min tensor(2.8364e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1358 | time / epoch 33.67s | loss 89.54 \n",
      "lambda_min tensor(2.5749e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1359 | time / epoch 33.90s | loss 89.54 \n",
      "lambda_min tensor(2.5812e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1360 | time / epoch 33.70s | loss 89.54 \n",
      "lambda_min tensor(2.5408e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1361 | time / epoch 34.01s | loss 89.54 \n",
      "lambda_min tensor(1.8818e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1362 | time / epoch 33.87s | loss 89.54 \n",
      "lambda_min tensor(2.3413e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1363 | time / epoch 33.90s | loss 89.53 \n",
      "lambda_min tensor(2.1535e-05-7.9865e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1364 | time / epoch 33.34s | loss 89.53 \n",
      "lambda_min tensor(2.8235e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1365 | time / epoch 33.61s | loss 89.53 \n",
      "lambda_min tensor(2.2586e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1366 | time / epoch 33.92s | loss 89.53 \n",
      "lambda_min tensor(2.2495e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1367 | time / epoch 33.94s | loss 89.53 \n",
      "lambda_min tensor(2.5429e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1368 | time / epoch 33.62s | loss 89.53 \n",
      "lambda_min tensor(3.0471e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1369 | time / epoch 33.72s | loss 89.53 \n",
      "lambda_min tensor(2.4806e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1370 | time / epoch 33.89s | loss 89.53 \n",
      "lambda_min tensor(1.9397e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1371 | time / epoch 33.75s | loss 89.52 \n",
      "lambda_min tensor(2.2423e-05-6.4470e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1372 | time / epoch 34.02s | loss 89.52 \n",
      "lambda_min tensor(2.6930e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1373 | time / epoch 34.32s | loss 89.52 \n",
      "lambda_min tensor(2.1231e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1374 | time / epoch 34.80s | loss 89.52 \n",
      "lambda_min tensor(2.5839e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1375 | time / epoch 34.17s | loss 89.52 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.5862e-05-5.2275e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1376 | time / epoch 33.89s | loss 89.52 \n",
      "lambda_min tensor(2.1246e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1377 | time / epoch 33.92s | loss 89.52 \n",
      "lambda_min tensor(2.6859e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1378 | time / epoch 33.98s | loss 89.51 \n",
      "lambda_min tensor(2.9951e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1379 | time / epoch 34.04s | loss 89.51 \n",
      "lambda_min tensor(2.2858e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1380 | time / epoch 33.78s | loss 89.51 \n",
      "lambda_min tensor(2.1454e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1381 | time / epoch 33.91s | loss 89.51 \n",
      "lambda_min tensor(2.1287e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1382 | time / epoch 34.02s | loss 89.51 \n",
      "lambda_min tensor(2.7256e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1383 | time / epoch 34.11s | loss 89.51 \n",
      "lambda_min tensor(2.0894e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1384 | time / epoch 34.18s | loss 89.51 \n",
      "lambda_min tensor(2.8417e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1385 | time / epoch 34.15s | loss 89.50 \n",
      "lambda_min tensor(2.0081e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1386 | time / epoch 33.81s | loss 89.50 \n",
      "lambda_min tensor(2.6815e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1387 | time / epoch 33.78s | loss 89.50 \n",
      "lambda_min tensor(5.3907e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1388 | time / epoch 34.13s | loss 89.50 \n",
      "lambda_min tensor(2.6008e-05-1.6071e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1389 | time / epoch 34.00s | loss 89.50 \n",
      "lambda_min tensor(2.5679e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1390 | time / epoch 33.94s | loss 89.50 \n",
      "lambda_min tensor(2.6032e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1391 | time / epoch 34.10s | loss 89.50 \n",
      "lambda_min tensor(2.5389e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1392 | time / epoch 34.04s | loss 89.50 \n",
      "lambda_min tensor(2.1455e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1393 | time / epoch 34.00s | loss 89.49 \n",
      "lambda_min tensor(2.1694e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1394 | time / epoch 34.37s | loss 89.49 \n",
      "lambda_min tensor(2.3616e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1395 | time / epoch 33.76s | loss 89.49 \n",
      "lambda_min tensor(2.8029e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1396 | time / epoch 33.79s | loss 89.49 \n",
      "lambda_min tensor(2.5332e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1397 | time / epoch 33.84s | loss 89.49 \n",
      "lambda_min tensor(3.0919e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1398 | time / epoch 34.60s | loss 89.49 \n",
      "lambda_min tensor(2.3945e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1399 | time / epoch 33.67s | loss 89.49 \n",
      "lambda_min tensor(2.1783e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1400 | time / epoch 34.02s | loss 89.48 \n",
      "lambda_min tensor(2.7946e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1401 | time / epoch 34.12s | loss 89.48 \n",
      "lambda_min tensor(4.4898e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1402 | time / epoch 34.20s | loss 89.48 \n",
      "lambda_min tensor(2.0509e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1403 | time / epoch 34.17s | loss 89.48 \n",
      "lambda_min tensor(2.2367e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1404 | time / epoch 33.94s | loss 89.48 \n",
      "lambda_min tensor(2.2578e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1405 | time / epoch 34.13s | loss 89.48 \n",
      "lambda_min tensor(2.0292e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1406 | time / epoch 34.12s | loss 89.48 \n",
      "lambda_min tensor(2.2590e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1407 | time / epoch 33.99s | loss 89.48 \n",
      "lambda_min tensor(2.4312e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1408 | time / epoch 33.74s | loss 89.47 \n",
      "lambda_min tensor(2.5666e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1409 | time / epoch 34.95s | loss 89.47 \n",
      "lambda_min tensor(2.6143e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1410 | time / epoch 34.53s | loss 89.47 \n",
      "lambda_min tensor(2.2107e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1411 | time / epoch 33.69s | loss 89.47 \n",
      "lambda_min tensor(2.3727e-05-3.5042e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1412 | time / epoch 33.86s | loss 89.47 \n",
      "lambda_min tensor(2.2196e-05-2.4716e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1413 | time / epoch 33.89s | loss 89.47 \n",
      "lambda_min tensor(1.9969e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1414 | time / epoch 33.96s | loss 89.47 \n",
      "lambda_min tensor(2.4604e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1415 | time / epoch 34.51s | loss 89.46 \n",
      "lambda_min tensor(2.2337e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1416 | time / epoch 33.68s | loss 89.46 \n",
      "lambda_min tensor(2.5552e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1417 | time / epoch 33.68s | loss 89.46 \n",
      "lambda_min tensor(2.1685e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1418 | time / epoch 33.70s | loss 89.46 \n",
      "lambda_min tensor(2.3142e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1419 | time / epoch 33.74s | loss 89.46 \n",
      "lambda_min tensor(2.7392e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1420 | time / epoch 33.71s | loss 89.46 \n",
      "lambda_min tensor(1.8256e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1421 | time / epoch 33.84s | loss 89.46 \n",
      "lambda_min tensor(5.9613e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1422 | time / epoch 33.80s | loss 89.45 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.2239e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1423 | time / epoch 34.76s | loss 89.45 \n",
      "lambda_min tensor(2.7397e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1424 | time / epoch 33.92s | loss 89.45 \n",
      "lambda_min tensor(2.9093e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1425 | time / epoch 33.77s | loss 89.45 \n",
      "lambda_min tensor(2.2411e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1426 | time / epoch 33.90s | loss 89.45 \n",
      "lambda_min tensor(1.9472e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1427 | time / epoch 33.92s | loss 89.45 \n",
      "lambda_min tensor(2.3664e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1428 | time / epoch 33.93s | loss 89.45 \n",
      "lambda_min tensor(1.9672e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1429 | time / epoch 33.84s | loss 89.45 \n",
      "lambda_min tensor(2.4295e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1430 | time / epoch 33.86s | loss 89.44 \n",
      "lambda_min tensor(2.1435e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1431 | time / epoch 33.71s | loss 89.44 \n",
      "lambda_min tensor(2.2842e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1432 | time / epoch 33.75s | loss 89.44 \n",
      "lambda_min tensor(2.2591e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1433 | time / epoch 33.83s | loss 89.44 \n",
      "lambda_min tensor(2.7587e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1434 | time / epoch 33.78s | loss 89.44 \n",
      "lambda_min tensor(2.6777e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1435 | time / epoch 33.93s | loss 89.44 \n",
      "lambda_min tensor(2.2950e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1436 | time / epoch 34.71s | loss 89.44 \n",
      "lambda_min tensor(2.4556e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1437 | time / epoch 33.79s | loss 89.43 \n",
      "lambda_min tensor(2.5574e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1438 | time / epoch 33.83s | loss 89.43 \n",
      "lambda_min tensor(2.7579e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1439 | time / epoch 33.51s | loss 89.43 \n",
      "lambda_min tensor(5.3061e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1440 | time / epoch 34.38s | loss 89.43 \n",
      "lambda_min tensor(2.4478e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1441 | time / epoch 34.40s | loss 89.43 \n",
      "lambda_min tensor(1.7655e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1442 | time / epoch 33.97s | loss 89.43 \n",
      "lambda_min tensor(2.5109e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1443 | time / epoch 34.24s | loss 89.43 \n",
      "lambda_min tensor(1.9928e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1444 | time / epoch 34.71s | loss 89.43 \n",
      "lambda_min tensor(1.9964e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1445 | time / epoch 34.27s | loss 89.42 \n",
      "lambda_min tensor(1.9667e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1446 | time / epoch 33.75s | loss 89.42 \n",
      "lambda_min tensor(2.3675e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1447 | time / epoch 34.06s | loss 89.42 \n",
      "lambda_min tensor(2.2605e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1448 | time / epoch 33.88s | loss 89.42 \n",
      "lambda_min tensor(2.1346e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1449 | time / epoch 33.98s | loss 89.42 \n",
      "lambda_min tensor(2.0216e-05-1.6452e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1450 | time / epoch 34.10s | loss 89.42 \n",
      "lambda_min tensor(2.1236e-05-3.5077e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1451 | time / epoch 33.98s | loss 89.42 \n",
      "lambda_min tensor(1.9614e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1452 | time / epoch 34.06s | loss 89.41 \n",
      "lambda_min tensor(1.9559e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1453 | time / epoch 34.00s | loss 89.41 \n",
      "lambda_min tensor(2.2856e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1454 | time / epoch 34.19s | loss 89.41 \n",
      "lambda_min tensor(2.2812e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1455 | time / epoch 33.94s | loss 89.41 \n",
      "lambda_min tensor(2.2040e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1456 | time / epoch 33.78s | loss 89.41 \n",
      "lambda_min tensor(2.8990e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1457 | time / epoch 33.83s | loss 89.41 \n",
      "lambda_min tensor(2.7206e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1458 | time / epoch 33.76s | loss 89.41 \n",
      "lambda_min tensor(2.3320e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1459 | time / epoch 34.23s | loss 89.41 \n",
      "lambda_min tensor(2.0014e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1460 | time / epoch 34.29s | loss 89.40 \n",
      "lambda_min tensor(4.3819e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1461 | time / epoch 34.20s | loss 89.40 \n",
      "lambda_min tensor(2.2768e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1462 | time / epoch 34.03s | loss 89.40 \n",
      "lambda_min tensor(2.2301e-05-2.6195e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1463 | time / epoch 33.90s | loss 89.40 \n",
      "lambda_min tensor(2.2992e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1464 | time / epoch 33.82s | loss 89.40 \n",
      "lambda_min tensor(2.2171e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1465 | time / epoch 34.04s | loss 89.40 \n",
      "lambda_min tensor(2.3732e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1466 | time / epoch 33.93s | loss 89.40 \n",
      "lambda_min tensor(2.6042e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1467 | time / epoch 34.29s | loss 89.39 \n",
      "lambda_min tensor(2.0872e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1468 | time / epoch 33.95s | loss 89.39 \n",
      "lambda_min tensor(2.5516e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1469 | time / epoch 33.70s | loss 89.39 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.1804e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1470 | time / epoch 33.86s | loss 89.39 \n",
      "lambda_min tensor(1.9801e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1471 | time / epoch 33.68s | loss 89.39 \n",
      "lambda_min tensor(2.6392e-05-1.3147e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1472 | time / epoch 34.03s | loss 89.39 \n",
      "lambda_min tensor(2.1310e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1473 | time / epoch 34.04s | loss 89.39 \n",
      "lambda_min tensor(2.2340e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1474 | time / epoch 33.81s | loss 89.39 \n",
      "lambda_min tensor(2.7804e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1475 | time / epoch 33.97s | loss 89.38 \n",
      "lambda_min tensor(1.8817e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1476 | time / epoch 33.81s | loss 89.38 \n",
      "lambda_min tensor(2.2024e-05-3.4445e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1477 | time / epoch 33.93s | loss 89.38 \n",
      "lambda_min tensor(2.6381e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1478 | time / epoch 34.16s | loss 89.38 \n",
      "lambda_min tensor(2.3080e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1479 | time / epoch 34.82s | loss 89.38 \n",
      "lambda_min tensor(2.9672e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1480 | time / epoch 33.70s | loss 89.38 \n",
      "lambda_min tensor(2.2711e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1481 | time / epoch 34.08s | loss 89.38 \n",
      "lambda_min tensor(2.2207e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1482 | time / epoch 34.32s | loss 89.38 \n",
      "lambda_min tensor(2.5357e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1483 | time / epoch 33.87s | loss 89.37 \n",
      "lambda_min tensor(4.1403e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1484 | time / epoch 33.64s | loss 89.37 \n",
      "lambda_min tensor(2.2409e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1485 | time / epoch 34.15s | loss 89.37 \n",
      "lambda_min tensor(2.9054e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1486 | time / epoch 33.65s | loss 89.37 \n",
      "lambda_min tensor(2.6958e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1487 | time / epoch 33.65s | loss 89.37 \n",
      "lambda_min tensor(2.6646e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1488 | time / epoch 33.69s | loss 89.37 \n",
      "lambda_min tensor(1.9737e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1489 | time / epoch 33.62s | loss 89.37 \n",
      "lambda_min tensor(3.4250e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1490 | time / epoch 34.06s | loss 89.36 \n",
      "lambda_min tensor(2.6286e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1491 | time / epoch 33.89s | loss 89.36 \n",
      "lambda_min tensor(2.1548e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1492 | time / epoch 33.65s | loss 89.36 \n",
      "lambda_min tensor(2.5189e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1493 | time / epoch 33.77s | loss 89.36 \n",
      "lambda_min tensor(2.4060e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1494 | time / epoch 33.85s | loss 89.36 \n",
      "lambda_min tensor(2.5378e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1495 | time / epoch 33.83s | loss 89.36 \n",
      "lambda_min tensor(2.0531e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1496 | time / epoch 33.69s | loss 89.36 \n",
      "lambda_min tensor(2.2271e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1497 | time / epoch 34.29s | loss 89.36 \n",
      "lambda_min tensor(2.5108e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1498 | time / epoch 33.89s | loss 89.35 \n",
      "lambda_min tensor(2.4430e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1499 | time / epoch 33.84s | loss 89.35 \n",
      "lambda_min tensor(2.6180e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1500 | time / epoch 33.60s | loss 89.35 \n",
      "lambda_min tensor(2.7020e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1501 | time / epoch 33.79s | loss 89.35 \n",
      "lambda_min tensor(1.8841e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1502 | time / epoch 33.65s | loss 89.35 \n",
      "lambda_min tensor(2.6331e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1503 | time / epoch 33.92s | loss 89.35 \n",
      "lambda_min tensor(1.9947e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1504 | time / epoch 33.67s | loss 89.35 \n",
      "lambda_min tensor(2.2835e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1505 | time / epoch 33.85s | loss 89.34 \n",
      "lambda_min tensor(2.4609e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1506 | time / epoch 33.70s | loss 89.34 \n",
      "lambda_min tensor(2.4559e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1507 | time / epoch 34.27s | loss 89.34 \n",
      "lambda_min tensor(2.4588e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1508 | time / epoch 33.92s | loss 89.34 \n",
      "lambda_min tensor(4.4742e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1509 | time / epoch 34.18s | loss 89.34 \n",
      "lambda_min tensor(2.0193e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1510 | time / epoch 33.79s | loss 89.34 \n",
      "lambda_min tensor(2.5033e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1511 | time / epoch 33.73s | loss 89.34 \n",
      "lambda_min tensor(2.7396e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1512 | time / epoch 33.81s | loss 89.34 \n",
      "lambda_min tensor(2.0171e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1513 | time / epoch 34.53s | loss 89.33 \n",
      "lambda_min tensor(2.5015e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1514 | time / epoch 34.91s | loss 89.33 \n",
      "lambda_min tensor(2.6052e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1515 | time / epoch 33.94s | loss 89.33 \n",
      "lambda_min tensor(2.2397e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1516 | time / epoch 33.78s | loss 89.33 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(1.9924e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1517 | time / epoch 33.85s | loss 89.33 \n",
      "lambda_min tensor(3.0562e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1518 | time / epoch 33.74s | loss 89.33 \n",
      "lambda_min tensor(2.0072e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1519 | time / epoch 34.14s | loss 89.33 \n",
      "lambda_min tensor(2.1420e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1520 | time / epoch 34.07s | loss 89.33 \n",
      "lambda_min tensor(2.6696e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1521 | time / epoch 33.98s | loss 89.32 \n",
      "lambda_min tensor(1.9523e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1522 | time / epoch 33.82s | loss 89.32 \n",
      "lambda_min tensor(2.3917e-05-2.4013e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1523 | time / epoch 33.95s | loss 89.32 \n",
      "lambda_min tensor(2.6361e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1524 | time / epoch 33.62s | loss 89.32 \n",
      "lambda_min tensor(2.0724e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1525 | time / epoch 33.99s | loss 89.32 \n",
      "lambda_min tensor(2.3553e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1526 | time / epoch 34.89s | loss 89.32 \n",
      "lambda_min tensor(2.5664e-05-5.3708e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1527 | time / epoch 34.31s | loss 89.32 \n",
      "lambda_min tensor(1.8529e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1528 | time / epoch 33.86s | loss 89.31 \n",
      "lambda_min tensor(2.5509e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1529 | time / epoch 33.75s | loss 89.31 \n",
      "lambda_min tensor(2.8339e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1530 | time / epoch 35.02s | loss 89.31 \n",
      "lambda_min tensor(2.9482e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1531 | time / epoch 34.19s | loss 89.31 \n",
      "lambda_min tensor(2.5997e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1532 | time / epoch 33.82s | loss 89.31 \n",
      "lambda_min tensor(2.0807e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1533 | time / epoch 33.60s | loss 89.31 \n",
      "lambda_min tensor(2.0878e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1534 | time / epoch 33.72s | loss 89.31 \n",
      "lambda_min tensor(2.8243e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1535 | time / epoch 33.66s | loss 89.31 \n",
      "lambda_min tensor(2.6940e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1536 | time / epoch 33.71s | loss 89.30 \n",
      "lambda_min tensor(2.2023e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1537 | time / epoch 33.93s | loss 89.30 \n",
      "lambda_min tensor(2.0459e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1538 | time / epoch 33.75s | loss 89.30 \n",
      "lambda_min tensor(2.0550e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1539 | time / epoch 34.03s | loss 89.30 \n",
      "lambda_min tensor(2.9566e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1540 | time / epoch 33.82s | loss 89.30 \n",
      "lambda_min tensor(2.4489e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1541 | time / epoch 33.56s | loss 89.30 \n",
      "lambda_min tensor(2.4523e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1542 | time / epoch 33.78s | loss 89.30 \n",
      "lambda_min tensor(2.5823e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1543 | time / epoch 33.86s | loss 89.30 \n",
      "lambda_min tensor(2.1219e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1544 | time / epoch 33.89s | loss 89.29 \n",
      "lambda_min tensor(1.8019e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1545 | time / epoch 33.81s | loss 89.29 \n",
      "lambda_min tensor(1.8102e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1546 | time / epoch 33.59s | loss 89.29 \n",
      "lambda_min tensor(2.5812e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1547 | time / epoch 33.93s | loss 89.29 \n",
      "lambda_min tensor(2.1692e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1548 | time / epoch 33.92s | loss 89.29 \n",
      "lambda_min tensor(2.6466e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1549 | time / epoch 33.91s | loss 89.29 \n",
      "lambda_min tensor(2.4986e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1550 | time / epoch 33.87s | loss 89.29 \n",
      "lambda_min tensor(3.0761e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1551 | time / epoch 33.59s | loss 89.29 \n",
      "lambda_min tensor(2.2652e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1552 | time / epoch 33.59s | loss 89.28 \n",
      "lambda_min tensor(3.0741e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1553 | time / epoch 33.83s | loss 89.28 \n",
      "lambda_min tensor(2.1975e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1554 | time / epoch 33.67s | loss 89.28 \n",
      "lambda_min tensor(2.2261e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1555 | time / epoch 33.87s | loss 89.28 \n",
      "lambda_min tensor(2.2227e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1556 | time / epoch 33.88s | loss 89.28 \n",
      "lambda_min tensor(2.2215e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1557 | time / epoch 33.59s | loss 89.28 \n",
      "lambda_min tensor(2.5461e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1558 | time / epoch 33.77s | loss 89.28 \n",
      "lambda_min tensor(2.4418e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1559 | time / epoch 33.86s | loss 89.27 \n",
      "lambda_min tensor(2.5378e-05-9.4671e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1560 | time / epoch 33.93s | loss 89.27 \n",
      "lambda_min tensor(2.5487e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1561 | time / epoch 33.68s | loss 89.27 \n",
      "lambda_min tensor(2.5920e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1562 | time / epoch 33.57s | loss 89.27 \n",
      "lambda_min tensor(2.1905e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1563 | time / epoch 33.93s | loss 89.27 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.0554e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1564 | time / epoch 33.65s | loss 89.27 \n",
      "lambda_min tensor(2.2483e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1565 | time / epoch 34.10s | loss 89.27 \n",
      "lambda_min tensor(2.8389e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1566 | time / epoch 33.85s | loss 89.27 \n",
      "lambda_min tensor(2.3409e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1567 | time / epoch 33.73s | loss 89.26 \n",
      "lambda_min tensor(2.3469e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1568 | time / epoch 33.78s | loss 89.26 \n",
      "lambda_min tensor(2.3345e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1569 | time / epoch 33.80s | loss 89.26 \n",
      "lambda_min tensor(2.6963e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1570 | time / epoch 34.06s | loss 89.26 \n",
      "lambda_min tensor(2.3873e-05-3.1685e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1571 | time / epoch 34.01s | loss 89.26 \n",
      "lambda_min tensor(2.1357e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1572 | time / epoch 33.79s | loss 89.26 \n",
      "lambda_min tensor(2.5072e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1573 | time / epoch 33.89s | loss 89.26 \n",
      "lambda_min tensor(2.5721e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1574 | time / epoch 33.66s | loss 89.26 \n",
      "lambda_min tensor(2.5102e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1575 | time / epoch 33.76s | loss 89.25 \n",
      "lambda_min tensor(2.9012e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1576 | time / epoch 33.64s | loss 89.25 \n",
      "lambda_min tensor(2.4379e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1577 | time / epoch 33.72s | loss 89.25 \n",
      "lambda_min tensor(2.6057e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1578 | time / epoch 33.80s | loss 89.25 \n",
      "lambda_min tensor(2.4400e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1579 | time / epoch 33.74s | loss 89.25 \n",
      "lambda_min tensor(1.8212e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1580 | time / epoch 33.78s | loss 89.25 \n",
      "lambda_min tensor(2.8647e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1581 | time / epoch 33.91s | loss 89.25 \n",
      "lambda_min tensor(1.8042e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1582 | time / epoch 33.77s | loss 89.25 \n",
      "lambda_min tensor(2.5175e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1583 | time / epoch 33.70s | loss 89.24 \n",
      "lambda_min tensor(2.2796e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1584 | time / epoch 33.42s | loss 89.24 \n",
      "lambda_min tensor(2.0022e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1585 | time / epoch 33.89s | loss 89.24 \n",
      "lambda_min tensor(2.7427e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1586 | time / epoch 33.82s | loss 89.24 \n",
      "lambda_min tensor(1.8555e-05-4.5881e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1587 | time / epoch 33.96s | loss 89.24 \n",
      "lambda_min tensor(2.5592e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1588 | time / epoch 33.75s | loss 89.24 \n",
      "lambda_min tensor(2.7021e-05-6.1941e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1589 | time / epoch 33.90s | loss 89.24 \n",
      "lambda_min tensor(1.9316e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1590 | time / epoch 33.84s | loss 89.24 \n",
      "lambda_min tensor(2.5757e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1591 | time / epoch 33.98s | loss 89.23 \n",
      "lambda_min tensor(2.5540e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1592 | time / epoch 33.65s | loss 89.23 \n",
      "lambda_min tensor(2.5857e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1593 | time / epoch 33.61s | loss 89.23 \n",
      "lambda_min tensor(1.9940e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1594 | time / epoch 33.31s | loss 89.23 \n",
      "lambda_min tensor(1.9523e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1595 | time / epoch 33.61s | loss 89.23 \n",
      "lambda_min tensor(2.1412e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1596 | time / epoch 33.48s | loss 89.23 \n",
      "lambda_min tensor(2.2592e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1597 | time / epoch 33.83s | loss 89.23 \n",
      "lambda_min tensor(2.2666e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1598 | time / epoch 34.07s | loss 89.23 \n",
      "lambda_min tensor(2.2393e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1599 | time / epoch 33.59s | loss 89.22 \n",
      "lambda_min tensor(2.6405e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1600 | time / epoch 33.69s | loss 89.22 \n",
      "lambda_min tensor(4.1419e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1601 | time / epoch 33.87s | loss 89.22 \n",
      "lambda_min tensor(2.5061e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1602 | time / epoch 33.68s | loss 89.22 \n",
      "lambda_min tensor(2.1213e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1603 | time / epoch 33.75s | loss 89.22 \n",
      "lambda_min tensor(2.4289e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1604 | time / epoch 33.62s | loss 89.22 \n",
      "lambda_min tensor(3.2774e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1605 | time / epoch 33.62s | loss 89.22 \n",
      "lambda_min tensor(2.6323e-05-2.4099e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1606 | time / epoch 33.43s | loss 89.21 \n",
      "lambda_min tensor(2.9839e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1607 | time / epoch 33.62s | loss 89.21 \n",
      "lambda_min tensor(1.5729e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1608 | time / epoch 33.71s | loss 89.21 \n",
      "lambda_min tensor(2.5409e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1609 | time / epoch 33.86s | loss 89.21 \n",
      "lambda_min tensor(2.6264e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1610 | time / epoch 33.73s | loss 89.21 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.5001e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1611 | time / epoch 33.79s | loss 89.21 \n",
      "lambda_min tensor(2.3554e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1612 | time / epoch 33.55s | loss 89.21 \n",
      "lambda_min tensor(2.6299e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1613 | time / epoch 33.75s | loss 89.21 \n",
      "lambda_min tensor(2.6977e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1614 | time / epoch 33.52s | loss 89.20 \n",
      "lambda_min tensor(2.1672e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1615 | time / epoch 33.52s | loss 89.20 \n",
      "lambda_min tensor(2.3568e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1616 | time / epoch 33.49s | loss 89.20 \n",
      "lambda_min tensor(2.4067e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1617 | time / epoch 33.85s | loss 89.20 \n",
      "lambda_min tensor(2.4091e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1618 | time / epoch 33.59s | loss 89.20 \n",
      "lambda_min tensor(2.5831e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1619 | time / epoch 34.30s | loss 89.20 \n",
      "lambda_min tensor(2.6228e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1620 | time / epoch 33.77s | loss 89.20 \n",
      "lambda_min tensor(2.0873e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1621 | time / epoch 33.74s | loss 89.20 \n",
      "lambda_min tensor(2.4781e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1622 | time / epoch 33.57s | loss 89.19 \n",
      "lambda_min tensor(1.9712e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1623 | time / epoch 33.91s | loss 89.19 \n",
      "lambda_min tensor(2.3785e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1624 | time / epoch 33.85s | loss 89.19 \n",
      "lambda_min tensor(2.4462e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1625 | time / epoch 33.42s | loss 89.19 \n",
      "lambda_min tensor(2.5873e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1626 | time / epoch 33.44s | loss 89.19 \n",
      "lambda_min tensor(2.6176e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1627 | time / epoch 34.17s | loss 89.19 \n",
      "lambda_min tensor(2.0647e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1628 | time / epoch 33.64s | loss 89.19 \n",
      "lambda_min tensor(2.8390e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1629 | time / epoch 33.51s | loss 89.19 \n",
      "lambda_min tensor(2.0064e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1630 | time / epoch 33.77s | loss 89.18 \n",
      "lambda_min tensor(2.5105e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1631 | time / epoch 33.66s | loss 89.18 \n",
      "lambda_min tensor(2.5198e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1632 | time / epoch 33.79s | loss 89.18 \n",
      "lambda_min tensor(2.8488e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1633 | time / epoch 33.85s | loss 89.18 \n",
      "lambda_min tensor(2.6030e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1634 | time / epoch 33.66s | loss 89.18 \n",
      "lambda_min tensor(2.5842e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1635 | time / epoch 34.00s | loss 89.18 \n",
      "lambda_min tensor(1.8178e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1636 | time / epoch 34.21s | loss 89.18 \n",
      "lambda_min tensor(2.2199e-05-4.5586e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1637 | time / epoch 33.78s | loss 89.18 \n",
      "lambda_min tensor(2.1023e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1638 | time / epoch 33.89s | loss 89.17 \n",
      "lambda_min tensor(2.7971e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1639 | time / epoch 33.63s | loss 89.17 \n",
      "lambda_min tensor(2.1541e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1640 | time / epoch 34.04s | loss 89.17 \n",
      "lambda_min tensor(2.5248e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1641 | time / epoch 33.68s | loss 89.17 \n",
      "lambda_min tensor(3.5675e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1642 | time / epoch 34.00s | loss 89.17 \n",
      "lambda_min tensor(2.3546e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1643 | time / epoch 33.65s | loss 89.17 \n",
      "lambda_min tensor(2.0950e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1644 | time / epoch 33.78s | loss 89.17 \n",
      "lambda_min tensor(2.5657e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1645 | time / epoch 33.95s | loss 89.17 \n",
      "lambda_min tensor(2.3329e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1646 | time / epoch 33.69s | loss 89.16 \n",
      "lambda_min tensor(1.9475e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1647 | time / epoch 34.14s | loss 89.16 \n",
      "lambda_min tensor(2.7952e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1648 | time / epoch 33.79s | loss 89.16 \n",
      "lambda_min tensor(1.8766e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1649 | time / epoch 33.75s | loss 89.16 \n",
      "lambda_min tensor(2.0343e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1650 | time / epoch 33.77s | loss 89.16 \n",
      "lambda_min tensor(2.0525e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1651 | time / epoch 34.00s | loss 89.16 \n",
      "lambda_min tensor(2.0654e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1652 | time / epoch 33.77s | loss 89.16 \n",
      "lambda_min tensor(2.4022e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1653 | time / epoch 33.86s | loss 89.16 \n",
      "lambda_min tensor(2.4190e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1654 | time / epoch 33.96s | loss 89.15 \n",
      "lambda_min tensor(2.2090e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1655 | time / epoch 33.44s | loss 89.15 \n",
      "lambda_min tensor(2.7325e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1656 | time / epoch 34.06s | loss 89.15 \n",
      "lambda_min tensor(2.1764e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1657 | time / epoch 33.90s | loss 89.15 \n",
      "lambda_min tensor(2.2213e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1658 | time / epoch 33.83s | loss 89.15 \n",
      "lambda_min tensor(2.7245e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1659 | time / epoch 34.27s | loss 89.15 \n",
      "lambda_min tensor(2.1834e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1660 | time / epoch 33.65s | loss 89.15 \n",
      "lambda_min tensor(2.5086e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1661 | time / epoch 34.22s | loss 89.15 \n",
      "lambda_min tensor(2.5413e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1662 | time / epoch 33.56s | loss 89.14 \n",
      "lambda_min tensor(2.4038e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1663 | time / epoch 33.79s | loss 89.14 \n",
      "lambda_min tensor(2.1347e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1664 | time / epoch 33.76s | loss 89.14 \n",
      "lambda_min tensor(2.1252e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1665 | time / epoch 34.19s | loss 89.14 \n",
      "lambda_min tensor(1.7132e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1666 | time / epoch 33.82s | loss 89.14 \n",
      "lambda_min tensor(2.3877e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1667 | time / epoch 33.82s | loss 89.14 \n",
      "lambda_min tensor(2.1832e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1668 | time / epoch 33.73s | loss 89.14 \n",
      "lambda_min tensor(1.9991e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1669 | time / epoch 33.72s | loss 89.14 \n",
      "lambda_min tensor(2.3508e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1670 | time / epoch 33.57s | loss 89.13 \n",
      "lambda_min tensor(2.2938e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1671 | time / epoch 33.83s | loss 89.13 \n",
      "lambda_min tensor(2.7022e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1672 | time / epoch 33.94s | loss 89.13 \n",
      "lambda_min tensor(1.9473e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1673 | time / epoch 33.76s | loss 89.13 \n",
      "lambda_min tensor(2.1147e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1674 | time / epoch 33.76s | loss 89.13 \n",
      "lambda_min tensor(4.4547e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1675 | time / epoch 33.84s | loss 89.13 \n",
      "lambda_min tensor(2.1178e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1676 | time / epoch 33.66s | loss 89.13 \n",
      "lambda_min tensor(2.1751e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1677 | time / epoch 34.00s | loss 89.13 \n",
      "lambda_min tensor(2.4631e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1678 | time / epoch 34.45s | loss 89.12 \n",
      "lambda_min tensor(2.4391e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1679 | time / epoch 33.84s | loss 89.12 \n",
      "lambda_min tensor(2.8329e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1680 | time / epoch 33.80s | loss 89.12 \n",
      "lambda_min tensor(2.0569e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1681 | time / epoch 33.79s | loss 89.12 \n",
      "lambda_min tensor(2.4096e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1682 | time / epoch 33.74s | loss 89.12 \n",
      "lambda_min tensor(2.0136e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1683 | time / epoch 34.07s | loss 89.12 \n",
      "lambda_min tensor(2.2336e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1684 | time / epoch 33.59s | loss 89.12 \n",
      "lambda_min tensor(2.3929e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1685 | time / epoch 33.66s | loss 89.12 \n",
      "lambda_min tensor(2.9910e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1686 | time / epoch 33.81s | loss 89.11 \n",
      "lambda_min tensor(2.4329e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1687 | time / epoch 33.70s | loss 89.11 \n",
      "lambda_min tensor(2.3636e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1688 | time / epoch 33.95s | loss 89.11 \n",
      "lambda_min tensor(2.4158e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1689 | time / epoch 34.51s | loss 89.11 \n",
      "lambda_min tensor(2.5575e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1690 | time / epoch 33.75s | loss 89.11 \n",
      "lambda_min tensor(2.2373e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1691 | time / epoch 33.90s | loss 89.11 \n",
      "lambda_min tensor(2.4883e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1692 | time / epoch 33.67s | loss 89.11 \n",
      "lambda_min tensor(2.8490e-05-2.5762e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1693 | time / epoch 33.56s | loss 89.11 \n",
      "lambda_min tensor(2.3747e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1694 | time / epoch 33.61s | loss 89.10 \n",
      "lambda_min tensor(2.2879e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1695 | time / epoch 33.75s | loss 89.10 \n",
      "lambda_min tensor(2.5732e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1696 | time / epoch 33.55s | loss 89.10 \n",
      "lambda_min tensor(2.0018e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1697 | time / epoch 33.89s | loss 89.10 \n",
      "lambda_min tensor(2.8148e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1698 | time / epoch 33.78s | loss 89.10 \n",
      "lambda_min tensor(2.3335e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1699 | time / epoch 33.43s | loss 89.10 \n",
      "lambda_min tensor(2.2421e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1700 | time / epoch 33.73s | loss 89.10 \n",
      "lambda_min tensor(2.6966e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1701 | time / epoch 33.64s | loss 89.10 \n",
      "lambda_min tensor(2.4787e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1702 | time / epoch 33.75s | loss 89.10 \n",
      "lambda_min tensor(2.0372e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1703 | time / epoch 33.63s | loss 89.09 \n",
      "lambda_min tensor(2.9561e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1704 | time / epoch 33.58s | loss 89.09 \n",
      "lambda_min tensor(2.3359e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1705 | time / epoch 33.59s | loss 89.09 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.8138e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1706 | time / epoch 33.73s | loss 89.09 \n",
      "lambda_min tensor(2.9745e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1707 | time / epoch 34.68s | loss 89.09 \n",
      "lambda_min tensor(4.1719e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1708 | time / epoch 34.54s | loss 89.09 \n",
      "lambda_min tensor(2.4753e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1709 | time / epoch 33.81s | loss 89.09 \n",
      "lambda_min tensor(2.4270e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1710 | time / epoch 33.66s | loss 89.09 \n",
      "lambda_min tensor(2.4821e-05-5.3183e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1711 | time / epoch 33.72s | loss 89.08 \n",
      "lambda_min tensor(2.4019e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1712 | time / epoch 34.05s | loss 89.08 \n",
      "lambda_min tensor(2.3824e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1713 | time / epoch 33.65s | loss 89.08 \n",
      "lambda_min tensor(2.2137e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1714 | time / epoch 33.64s | loss 89.08 \n",
      "lambda_min tensor(5.6511e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1715 | time / epoch 33.98s | loss 89.08 \n",
      "lambda_min tensor(1.7653e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1716 | time / epoch 33.75s | loss 89.08 \n",
      "lambda_min tensor(1.8669e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1717 | time / epoch 33.59s | loss 89.08 \n",
      "lambda_min tensor(2.2517e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1718 | time / epoch 33.69s | loss 89.08 \n",
      "lambda_min tensor(2.6217e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1719 | time / epoch 33.83s | loss 89.07 \n",
      "lambda_min tensor(2.2841e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1720 | time / epoch 33.71s | loss 89.07 \n",
      "lambda_min tensor(2.3621e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1721 | time / epoch 33.75s | loss 89.07 \n",
      "lambda_min tensor(2.2514e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1722 | time / epoch 33.83s | loss 89.07 \n",
      "lambda_min tensor(2.1456e-05-1.5267e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1723 | time / epoch 33.54s | loss 89.07 \n",
      "lambda_min tensor(2.3828e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1724 | time / epoch 33.68s | loss 89.07 \n",
      "lambda_min tensor(2.5107e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1725 | time / epoch 33.57s | loss 89.07 \n",
      "lambda_min tensor(2.4594e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1726 | time / epoch 33.57s | loss 89.07 \n",
      "lambda_min tensor(2.4220e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1727 | time / epoch 33.82s | loss 89.06 \n",
      "lambda_min tensor(2.6374e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1728 | time / epoch 33.58s | loss 89.06 \n",
      "lambda_min tensor(1.9172e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1729 | time / epoch 33.79s | loss 89.06 \n",
      "lambda_min tensor(2.5562e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1730 | time / epoch 33.71s | loss 89.06 \n",
      "lambda_min tensor(2.5828e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1731 | time / epoch 33.52s | loss 89.06 \n",
      "lambda_min tensor(2.4300e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1732 | time / epoch 33.54s | loss 89.06 \n",
      "lambda_min tensor(2.3617e-05-7.3416e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1733 | time / epoch 33.80s | loss 89.06 \n",
      "lambda_min tensor(2.0833e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1734 | time / epoch 33.74s | loss 89.06 \n",
      "lambda_min tensor(2.3470e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1735 | time / epoch 33.85s | loss 89.05 \n",
      "lambda_min tensor(2.7882e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1736 | time / epoch 33.66s | loss 89.05 \n",
      "lambda_min tensor(1.8531e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1737 | time / epoch 34.36s | loss 89.05 \n",
      "lambda_min tensor(2.8257e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1738 | time / epoch 34.86s | loss 89.05 \n",
      "lambda_min tensor(2.7518e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1739 | time / epoch 34.32s | loss 89.05 \n",
      "lambda_min tensor(2.9957e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1740 | time / epoch 33.91s | loss 89.05 \n",
      "lambda_min tensor(2.2906e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1741 | time / epoch 33.66s | loss 89.05 \n",
      "lambda_min tensor(1.9873e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1742 | time / epoch 34.01s | loss 89.05 \n",
      "lambda_min tensor(2.7840e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1743 | time / epoch 34.65s | loss 89.04 \n",
      "lambda_min tensor(4.4314e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1744 | time / epoch 33.73s | loss 89.04 \n",
      "lambda_min tensor(2.3549e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1745 | time / epoch 33.95s | loss 89.04 \n",
      "lambda_min tensor(2.4132e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1746 | time / epoch 33.82s | loss 89.04 \n",
      "lambda_min tensor(2.3533e-05-2.5096e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1747 | time / epoch 33.94s | loss 89.04 \n",
      "lambda_min tensor(2.0378e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1748 | time / epoch 33.86s | loss 89.04 \n",
      "lambda_min tensor(2.3205e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1749 | time / epoch 33.79s | loss 89.04 \n",
      "lambda_min tensor(2.0705e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1750 | time / epoch 33.83s | loss 89.04 \n",
      "lambda_min tensor(2.7818e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1751 | time / epoch 33.69s | loss 89.04 \n",
      "lambda_min tensor(3.9118e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1752 | time / epoch 34.21s | loss 89.03 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.1730e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1753 | time / epoch 33.96s | loss 89.03 \n",
      "lambda_min tensor(2.2777e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1754 | time / epoch 33.84s | loss 89.03 \n",
      "lambda_min tensor(2.5784e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1755 | time / epoch 33.61s | loss 89.03 \n",
      "lambda_min tensor(1.9654e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1756 | time / epoch 33.93s | loss 89.03 \n",
      "lambda_min tensor(2.2340e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1757 | time / epoch 33.89s | loss 89.03 \n",
      "lambda_min tensor(2.7752e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1758 | time / epoch 33.79s | loss 89.03 \n",
      "lambda_min tensor(2.3815e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1759 | time / epoch 33.90s | loss 89.03 \n",
      "lambda_min tensor(2.0393e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1760 | time / epoch 35.19s | loss 89.02 \n",
      "lambda_min tensor(2.1611e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1761 | time / epoch 33.89s | loss 89.02 \n",
      "lambda_min tensor(1.7288e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1762 | time / epoch 34.11s | loss 89.02 \n",
      "lambda_min tensor(2.6064e-05-2.3879e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1763 | time / epoch 34.04s | loss 89.02 \n",
      "lambda_min tensor(2.5846e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1764 | time / epoch 34.01s | loss 89.02 \n",
      "lambda_min tensor(1.7280e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1765 | time / epoch 34.13s | loss 89.02 \n",
      "lambda_min tensor(2.9299e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1766 | time / epoch 34.06s | loss 89.02 \n",
      "lambda_min tensor(2.6256e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1767 | time / epoch 33.72s | loss 89.02 \n",
      "lambda_min tensor(2.0888e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1768 | time / epoch 34.07s | loss 89.01 \n",
      "lambda_min tensor(2.1313e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1769 | time / epoch 34.09s | loss 89.01 \n",
      "lambda_min tensor(3.6632e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1770 | time / epoch 34.27s | loss 89.01 \n",
      "lambda_min tensor(2.2005e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1771 | time / epoch 34.31s | loss 89.01 \n",
      "lambda_min tensor(1.9772e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1772 | time / epoch 34.06s | loss 89.01 \n",
      "lambda_min tensor(2.4922e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1773 | time / epoch 34.04s | loss 89.01 \n",
      "lambda_min tensor(2.7014e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1774 | time / epoch 34.10s | loss 89.01 \n",
      "lambda_min tensor(1.9829e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1775 | time / epoch 34.70s | loss 89.01 \n",
      "lambda_min tensor(4.8505e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1776 | time / epoch 34.31s | loss 89.00 \n",
      "lambda_min tensor(2.2142e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1777 | time / epoch 34.51s | loss 89.00 \n",
      "lambda_min tensor(1.8118e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1778 | time / epoch 34.36s | loss 89.00 \n",
      "lambda_min tensor(2.4220e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1779 | time / epoch 34.10s | loss 89.00 \n",
      "lambda_min tensor(2.2581e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1780 | time / epoch 34.01s | loss 89.00 \n",
      "lambda_min tensor(2.2617e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1781 | time / epoch 34.22s | loss 89.00 \n",
      "lambda_min tensor(2.5736e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1782 | time / epoch 34.11s | loss 89.00 \n",
      "lambda_min tensor(2.6641e-05-1.1376e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1783 | time / epoch 34.26s | loss 89.00 \n",
      "lambda_min tensor(2.2237e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1784 | time / epoch 34.14s | loss 89.00 \n",
      "lambda_min tensor(2.3182e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1785 | time / epoch 34.09s | loss 88.99 \n",
      "lambda_min tensor(2.0786e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1786 | time / epoch 34.11s | loss 88.99 \n",
      "lambda_min tensor(2.7828e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1787 | time / epoch 33.89s | loss 88.99 \n",
      "lambda_min tensor(2.2575e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1788 | time / epoch 34.33s | loss 88.99 \n",
      "lambda_min tensor(2.1341e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1789 | time / epoch 34.17s | loss 88.99 \n",
      "lambda_min tensor(2.7911e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1790 | time / epoch 34.29s | loss 88.99 \n",
      "lambda_min tensor(2.9121e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1791 | time / epoch 34.08s | loss 88.99 \n",
      "lambda_min tensor(2.2676e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1792 | time / epoch 34.03s | loss 88.99 \n",
      "lambda_min tensor(2.5561e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1793 | time / epoch 34.03s | loss 88.98 \n",
      "lambda_min tensor(2.2941e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1794 | time / epoch 34.08s | loss 88.98 \n",
      "lambda_min tensor(2.9072e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1795 | time / epoch 34.10s | loss 88.98 \n",
      "lambda_min tensor(2.4150e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1796 | time / epoch 34.27s | loss 88.98 \n",
      "lambda_min tensor(2.6201e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1797 | time / epoch 34.21s | loss 88.98 \n",
      "lambda_min tensor(2.0015e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1798 | time / epoch 33.75s | loss 88.98 \n",
      "lambda_min tensor(2.3707e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1799 | time / epoch 33.73s | loss 88.98 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_min tensor(2.7446e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1800 | time / epoch 33.95s | loss 88.98 \n",
      "lambda_min tensor(2.1260e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1801 | time / epoch 33.95s | loss 88.97 \n",
      "lambda_min tensor(3.6839e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1802 | time / epoch 33.68s | loss 88.97 \n",
      "lambda_min tensor(2.7025e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1803 | time / epoch 33.74s | loss 88.97 \n",
      "lambda_min tensor(3.0538e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1804 | time / epoch 33.66s | loss 88.97 \n",
      "lambda_min tensor(2.4866e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1805 | time / epoch 33.92s | loss 88.97 \n",
      "lambda_min tensor(2.1502e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1806 | time / epoch 33.86s | loss 88.97 \n",
      "lambda_min tensor(1.7183e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1807 | time / epoch 34.18s | loss 88.97 \n",
      "lambda_min tensor(2.5138e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1808 | time / epoch 33.77s | loss 88.97 \n",
      "lambda_min tensor(2.6713e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1809 | time / epoch 34.02s | loss 88.97 \n",
      "lambda_min tensor(2.3161e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1810 | time / epoch 33.89s | loss 88.96 \n",
      "lambda_min tensor(2.4576e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1811 | time / epoch 33.78s | loss 88.96 \n",
      "lambda_min tensor(2.0991e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1812 | time / epoch 33.69s | loss 88.96 \n",
      "lambda_min tensor(2.7797e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1813 | time / epoch 33.86s | loss 88.96 \n",
      "lambda_min tensor(1.8160e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1814 | time / epoch 34.03s | loss 88.96 \n",
      "lambda_min tensor(2.4005e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1815 | time / epoch 34.05s | loss 88.96 \n",
      "lambda_min tensor(4.8079e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1816 | time / epoch 33.98s | loss 88.96 \n",
      "lambda_min tensor(3.0877e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1817 | time / epoch 33.80s | loss 88.96 \n",
      "lambda_min tensor(2.7256e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1818 | time / epoch 33.77s | loss 88.95 \n",
      "lambda_min tensor(2.5498e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1819 | time / epoch 34.02s | loss 88.95 \n",
      "lambda_min tensor(2.1420e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1820 | time / epoch 34.29s | loss 88.95 \n",
      "lambda_min tensor(2.9172e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1821 | time / epoch 33.88s | loss 88.95 \n",
      "lambda_min tensor(2.2695e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1822 | time / epoch 33.84s | loss 88.95 \n",
      "lambda_min tensor(2.2577e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1823 | time / epoch 34.23s | loss 88.95 \n",
      "lambda_min tensor(1.9021e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1824 | time / epoch 33.93s | loss 88.95 \n",
      "lambda_min tensor(1.9882e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1825 | time / epoch 33.67s | loss 88.95 \n",
      "lambda_min tensor(2.5368e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1826 | time / epoch 33.87s | loss 88.95 \n",
      "lambda_min tensor(1.7682e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1827 | time / epoch 34.05s | loss 88.94 \n",
      "lambda_min tensor(2.6151e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1828 | time / epoch 34.08s | loss 88.94 \n",
      "lambda_min tensor(2.7684e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1829 | time / epoch 33.60s | loss 88.94 \n",
      "lambda_min tensor(2.0014e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1830 | time / epoch 34.85s | loss 88.94 \n",
      "lambda_min tensor(4.9132e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1831 | time / epoch 34.62s | loss 88.94 \n",
      "lambda_min tensor(2.8573e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1832 | time / epoch 33.70s | loss 88.94 \n",
      "lambda_min tensor(3.1000e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1833 | time / epoch 33.82s | loss 88.94 \n",
      "lambda_min tensor(3.2018e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1834 | time / epoch 34.00s | loss 88.94 \n",
      "lambda_min tensor(3.0526e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1835 | time / epoch 33.86s | loss 88.93 \n",
      "lambda_min tensor(2.2940e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1836 | time / epoch 33.79s | loss 88.93 \n",
      "lambda_min tensor(2.2890e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1837 | time / epoch 34.05s | loss 88.93 \n",
      "lambda_min tensor(2.3302e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1838 | time / epoch 34.07s | loss 88.93 \n",
      "lambda_min tensor(2.0359e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1839 | time / epoch 34.12s | loss 88.93 \n",
      "lambda_min tensor(2.2801e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1840 | time / epoch 34.22s | loss 88.93 \n",
      "lambda_min tensor(2.2646e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1841 | time / epoch 34.76s | loss 88.93 \n",
      "lambda_min tensor(2.0979e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1842 | time / epoch 34.07s | loss 88.93 \n",
      "lambda_min tensor(2.1266e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1843 | time / epoch 33.99s | loss 88.92 \n",
      "lambda_min tensor(2.4133e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1844 | time / epoch 33.65s | loss 88.92 \n",
      "lambda_min tensor(2.6184e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1845 | time / epoch 33.67s | loss 88.92 \n",
      "lambda_min tensor(2.4702e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1846 | time / epoch 33.96s | loss 88.92 \n",
      "lambda_min tensor(1.8228e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1847 | time / epoch 33.94s | loss 88.92 \n",
      "lambda_min tensor(2.3311e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1848 | time / epoch 34.15s | loss 88.92 \n",
      "lambda_min tensor(2.0391e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1849 | time / epoch 34.16s | loss 88.92 \n",
      "lambda_min tensor(2.6032e-05-4.4048e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1850 | time / epoch 34.15s | loss 88.92 \n",
      "lambda_min tensor(1.8804e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1851 | time / epoch 33.95s | loss 88.92 \n",
      "lambda_min tensor(2.3819e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1852 | time / epoch 33.80s | loss 88.91 \n",
      "lambda_min tensor(2.3550e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1853 | time / epoch 34.00s | loss 88.91 \n",
      "lambda_min tensor(2.6683e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1854 | time / epoch 33.98s | loss 88.91 \n",
      "lambda_min tensor(3.0364e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1855 | time / epoch 33.78s | loss 88.91 \n",
      "lambda_min tensor(2.1371e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1856 | time / epoch 33.83s | loss 88.91 \n",
      "lambda_min tensor(2.6015e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1857 | time / epoch 34.24s | loss 88.91 \n",
      "lambda_min tensor(2.2005e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1858 | time / epoch 34.50s | loss 88.91 \n",
      "lambda_min tensor(2.0088e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1859 | time / epoch 33.79s | loss 88.91 \n",
      "lambda_min tensor(2.3068e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1860 | time / epoch 33.95s | loss 88.90 \n",
      "lambda_min tensor(2.3638e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1861 | time / epoch 33.86s | loss 88.90 \n",
      "lambda_min tensor(2.6541e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1862 | time / epoch 34.87s | loss 88.90 \n",
      "lambda_min tensor(2.3341e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1863 | time / epoch 33.93s | loss 88.90 \n",
      "lambda_min tensor(1.8362e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1864 | time / epoch 34.54s | loss 88.90 \n",
      "lambda_min tensor(2.3147e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1865 | time / epoch 35.28s | loss 88.90 \n",
      "lambda_min tensor(4.8748e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1866 | time / epoch 34.13s | loss 88.90 \n",
      "lambda_min tensor(2.6083e-05-1.9714e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1867 | time / epoch 34.04s | loss 88.90 \n",
      "lambda_min tensor(2.3522e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1868 | time / epoch 33.74s | loss 88.90 \n",
      "lambda_min tensor(2.3720e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1869 | time / epoch 34.05s | loss 88.89 \n",
      "lambda_min tensor(1.8579e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1870 | time / epoch 34.06s | loss 88.89 \n",
      "lambda_min tensor(2.0190e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1871 | time / epoch 34.00s | loss 88.89 \n",
      "lambda_min tensor(1.9587e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1872 | time / epoch 34.11s | loss 88.89 \n",
      "lambda_min tensor(2.3894e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1873 | time / epoch 33.73s | loss 88.89 \n",
      "lambda_min tensor(2.8964e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1874 | time / epoch 33.71s | loss 88.89 \n",
      "lambda_min tensor(2.5518e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1875 | time / epoch 33.76s | loss 88.89 \n",
      "lambda_min tensor(2.8365e-05-4.1006e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1876 | time / epoch 33.75s | loss 88.89 \n",
      "lambda_min tensor(2.1471e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1877 | time / epoch 33.79s | loss 88.88 \n",
      "lambda_min tensor(2.6698e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1878 | time / epoch 34.02s | loss 88.88 \n",
      "lambda_min tensor(2.9027e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1879 | time / epoch 33.72s | loss 88.88 \n",
      "lambda_min tensor(2.0823e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1880 | time / epoch 33.67s | loss 88.88 \n",
      "lambda_min tensor(2.9591e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1881 | time / epoch 34.15s | loss 88.88 \n",
      "lambda_min tensor(1.9644e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1882 | time / epoch 33.86s | loss 88.88 \n",
      "lambda_min tensor(2.5417e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1883 | time / epoch 33.56s | loss 88.88 \n",
      "lambda_min tensor(2.0666e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1884 | time / epoch 33.81s | loss 88.88 \n",
      "lambda_min tensor(3.0059e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1885 | time / epoch 33.97s | loss 88.88 \n",
      "lambda_min tensor(2.4592e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1886 | time / epoch 33.87s | loss 88.87 \n",
      "lambda_min tensor(2.2520e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1887 | time / epoch 34.68s | loss 88.87 \n",
      "lambda_min tensor(2.3556e-05-3.2794e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1888 | time / epoch 33.90s | loss 88.87 \n",
      "lambda_min tensor(2.3403e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1889 | time / epoch 33.86s | loss 88.87 \n",
      "lambda_min tensor(2.2516e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1890 | time / epoch 33.94s | loss 88.87 \n",
      "lambda_min tensor(2.7858e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1891 | time / epoch 33.85s | loss 88.87 \n",
      "lambda_min tensor(2.5439e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1892 | time / epoch 33.91s | loss 88.87 \n",
      "lambda_min tensor(1.7357e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1893 | time / epoch 33.73s | loss 88.87 \n",
      "lambda_min tensor(2.2340e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1894 | time / epoch 33.70s | loss 88.86 \n",
      "lambda_min tensor(1.8459e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1895 | time / epoch 33.93s | loss 88.86 \n",
      "lambda_min tensor(2.8353e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1896 | time / epoch 33.88s | loss 88.86 \n",
      "lambda_min tensor(2.4344e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1897 | time / epoch 33.81s | loss 88.86 \n",
      "lambda_min tensor(2.3021e-05-4.1778e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1898 | time / epoch 33.78s | loss 88.86 \n",
      "lambda_min tensor(2.4094e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1899 | time / epoch 34.68s | loss 88.86 \n",
      "lambda_min tensor(2.6036e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1900 | time / epoch 34.40s | loss 88.86 \n",
      "lambda_min tensor(2.0947e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1901 | time / epoch 33.89s | loss 88.86 \n",
      "lambda_min tensor(2.3139e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1902 | time / epoch 33.96s | loss 88.86 \n",
      "lambda_min tensor(2.6826e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1903 | time / epoch 33.80s | loss 88.85 \n",
      "lambda_min tensor(1.8262e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1904 | time / epoch 34.09s | loss 88.85 \n",
      "lambda_min tensor(2.1456e-05-6.1266e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1905 | time / epoch 33.70s | loss 88.85 \n",
      "lambda_min tensor(3.0062e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1906 | time / epoch 33.79s | loss 88.85 \n",
      "lambda_min tensor(4.6965e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1907 | time / epoch 34.16s | loss 88.85 \n",
      "lambda_min tensor(2.0916e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1908 | time / epoch 33.77s | loss 88.85 \n",
      "lambda_min tensor(2.4157e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1909 | time / epoch 33.83s | loss 88.85 \n",
      "lambda_min tensor(2.2705e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1910 | time / epoch 33.99s | loss 88.85 \n",
      "lambda_min tensor(2.6709e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1911 | time / epoch 33.85s | loss 88.85 \n",
      "lambda_min tensor(2.0925e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1912 | time / epoch 33.94s | loss 88.84 \n",
      "lambda_min tensor(1.8625e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1913 | time / epoch 33.64s | loss 88.84 \n",
      "lambda_min tensor(1.9090e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1914 | time / epoch 33.88s | loss 88.84 \n",
      "lambda_min tensor(2.2207e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1915 | time / epoch 33.84s | loss 88.84 \n",
      "lambda_min tensor(2.0697e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1916 | time / epoch 34.20s | loss 88.84 \n",
      "lambda_min tensor(2.1092e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1917 | time / epoch 33.91s | loss 88.84 \n",
      "lambda_min tensor(2.5429e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1918 | time / epoch 34.16s | loss 88.84 \n",
      "lambda_min tensor(2.2196e-05-5.5925e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1919 | time / epoch 33.82s | loss 88.84 \n",
      "lambda_min tensor(2.9326e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1920 | time / epoch 33.92s | loss 88.83 \n",
      "lambda_min tensor(2.7378e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1921 | time / epoch 34.21s | loss 88.83 \n",
      "lambda_min tensor(2.9256e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1922 | time / epoch 33.75s | loss 88.83 \n",
      "lambda_min tensor(2.8275e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1923 | time / epoch 33.64s | loss 88.83 \n",
      "lambda_min tensor(2.6242e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1924 | time / epoch 33.94s | loss 88.83 \n",
      "lambda_min tensor(3.0789e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1925 | time / epoch 33.78s | loss 88.83 \n",
      "lambda_min tensor(2.8998e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1926 | time / epoch 33.95s | loss 88.83 \n",
      "lambda_min tensor(2.1413e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1927 | time / epoch 33.87s | loss 88.83 \n",
      "lambda_min tensor(2.1628e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1928 | time / epoch 33.81s | loss 88.83 \n",
      "lambda_min tensor(2.1312e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1929 | time / epoch 33.97s | loss 88.82 \n",
      "lambda_min tensor(2.2677e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1930 | time / epoch 33.81s | loss 88.82 \n",
      "lambda_min tensor(2.4725e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1931 | time / epoch 34.00s | loss 88.82 \n",
      "lambda_min tensor(2.7104e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1932 | time / epoch 33.85s | loss 88.82 \n",
      "lambda_min tensor(2.2821e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1933 | time / epoch 34.15s | loss 88.82 \n",
      "lambda_min tensor(5.8826e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1934 | time / epoch 35.01s | loss 88.82 \n",
      "lambda_min tensor(2.2036e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1935 | time / epoch 33.95s | loss 88.82 \n",
      "lambda_min tensor(1.8934e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1936 | time / epoch 33.74s | loss 88.82 \n",
      "lambda_min tensor(2.3073e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1937 | time / epoch 34.12s | loss 88.82 \n",
      "lambda_min tensor(2.3326e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1938 | time / epoch 33.75s | loss 88.81 \n",
      "lambda_min tensor(1.8953e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1939 | time / epoch 34.08s | loss 88.81 \n",
      "lambda_min tensor(2.1295e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1940 | time / epoch 33.86s | loss 88.81 \n",
      "lambda_min tensor(2.9860e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1941 | time / epoch 34.06s | loss 88.81 \n",
      "lambda_min tensor(2.2463e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1942 | time / epoch 33.86s | loss 88.81 \n",
      "lambda_min tensor(2.2961e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1943 | time / epoch 33.69s | loss 88.81 \n",
      "lambda_min tensor(2.1603e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1944 | time / epoch 33.83s | loss 88.81 \n",
      "lambda_min tensor(2.0893e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1945 | time / epoch 33.92s | loss 88.81 \n",
      "lambda_min tensor(2.0996e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1946 | time / epoch 33.72s | loss 88.80 \n",
      "lambda_min tensor(3.9414e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1947 | time / epoch 33.79s | loss 88.80 \n",
      "lambda_min tensor(2.2737e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1948 | time / epoch 35.35s | loss 88.80 \n",
      "lambda_min tensor(2.2950e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1949 | time / epoch 33.76s | loss 88.80 \n",
      "lambda_min tensor(2.3670e-05-8.8892e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1950 | time / epoch 34.09s | loss 88.80 \n",
      "lambda_min tensor(2.3775e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1951 | time / epoch 34.32s | loss 88.80 \n",
      "lambda_min tensor(2.1250e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1952 | time / epoch 33.99s | loss 88.80 \n",
      "lambda_min tensor(2.7052e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1953 | time / epoch 33.95s | loss 88.80 \n",
      "lambda_min tensor(2.4261e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1954 | time / epoch 33.75s | loss 88.80 \n",
      "lambda_min tensor(5.1109e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1955 | time / epoch 34.02s | loss 88.79 \n",
      "lambda_min tensor(2.1941e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1956 | time / epoch 33.95s | loss 88.79 \n",
      "lambda_min tensor(2.1645e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1957 | time / epoch 33.89s | loss 88.79 \n",
      "lambda_min tensor(2.2355e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1958 | time / epoch 34.05s | loss 88.79 \n",
      "lambda_min tensor(2.4834e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1959 | time / epoch 33.97s | loss 88.79 \n",
      "lambda_min tensor(2.1889e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1960 | time / epoch 33.81s | loss 88.79 \n",
      "lambda_min tensor(2.2249e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1961 | time / epoch 34.00s | loss 88.79 \n",
      "lambda_min tensor(2.4734e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1962 | time / epoch 33.86s | loss 88.79 \n",
      "lambda_min tensor(2.0054e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1963 | time / epoch 34.24s | loss 88.79 \n",
      "lambda_min tensor(2.4631e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1964 | time / epoch 34.03s | loss 88.78 \n",
      "lambda_min tensor(2.5514e-05-5.6244e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1965 | time / epoch 33.85s | loss 88.78 \n",
      "lambda_min tensor(2.5015e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1966 | time / epoch 33.84s | loss 88.78 \n",
      "lambda_min tensor(2.2500e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1967 | time / epoch 33.66s | loss 88.78 \n",
      "lambda_min tensor(1.7936e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1968 | time / epoch 34.00s | loss 88.78 \n",
      "lambda_min tensor(2.1417e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1969 | time / epoch 34.84s | loss 88.78 \n",
      "lambda_min tensor(3.0323e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1970 | time / epoch 34.74s | loss 88.78 \n",
      "lambda_min tensor(2.0892e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1971 | time / epoch 33.83s | loss 88.78 \n",
      "lambda_min tensor(2.3789e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1972 | time / epoch 33.94s | loss 88.77 \n",
      "lambda_min tensor(2.0482e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1973 | time / epoch 34.01s | loss 88.77 \n",
      "lambda_min tensor(5.1777e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1974 | time / epoch 34.19s | loss 88.77 \n",
      "lambda_min tensor(2.2099e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1975 | time / epoch 33.82s | loss 88.77 \n",
      "lambda_min tensor(2.1878e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1976 | time / epoch 33.83s | loss 88.77 \n",
      "lambda_min tensor(2.0669e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1977 | time / epoch 33.98s | loss 88.77 \n",
      "lambda_min tensor(4.5089e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1978 | time / epoch 33.89s | loss 88.77 \n",
      "lambda_min tensor(2.5931e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1979 | time / epoch 33.94s | loss 88.77 \n",
      "lambda_min tensor(2.5830e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1980 | time / epoch 34.06s | loss 88.77 \n",
      "lambda_min tensor(2.4266e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1981 | time / epoch 33.70s | loss 88.76 \n",
      "lambda_min tensor(2.1442e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1982 | time / epoch 34.16s | loss 88.76 \n",
      "lambda_min tensor(2.7525e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1983 | time / epoch 33.88s | loss 88.76 \n",
      "lambda_min tensor(1.9478e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1984 | time / epoch 34.06s | loss 88.76 \n",
      "lambda_min tensor(2.4588e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1985 | time / epoch 34.06s | loss 88.76 \n",
      "lambda_min tensor(1.9645e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1986 | time / epoch 33.98s | loss 88.76 \n",
      "lambda_min tensor(4.2456e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1987 | time / epoch 33.98s | loss 88.76 \n",
      "lambda_min tensor(2.0053e-05+0.j, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1988 | time / epoch 33.92s | loss 88.76 \n",
      "lambda_min tensor(1.7511e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1989 | time / epoch 33.91s | loss 88.76 \n",
      "lambda_min tensor(1.9902e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1990 | time / epoch 33.77s | loss 88.75 \n",
      "lambda_min tensor(2.3050e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1991 | time / epoch 33.95s | loss 88.75 \n",
      "lambda_min tensor(2.0552e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1992 | time / epoch 34.47s | loss 88.75 \n",
      "lambda_min tensor(2.7802e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1993 | time / epoch 33.92s | loss 88.75 \n",
      "lambda_min tensor(3.0291e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1994 | time / epoch 33.93s | loss 88.75 \n",
      "lambda_min tensor(2.2641e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1995 | time / epoch 33.95s | loss 88.75 \n",
      "lambda_min tensor(2.1331e-05-1.2420e-08j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1996 | time / epoch 34.07s | loss 88.75 \n",
      "lambda_min tensor(2.2741e-05-5.2103e-09j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1997 | time / epoch 34.04s | loss 88.75 \n",
      "lambda_min tensor(2.7790e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1998 | time / epoch 34.25s | loss 88.75 \n",
      "lambda_min tensor(2.2403e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 1999 | time / epoch 33.92s | loss 88.74 \n",
      "lambda_min tensor(2.1396e-05+0.j, grad_fn=<SelectBackward0>)\n",
      "singular_max tensor(0.7983+0.j, grad_fn=<SqrtBackward0>)\n",
      "| end of epoch 2000 | time / epoch 33.83s | loss 88.74 \n"
     ]
    }
   ],
   "source": [
    "epochs =2000 #2000      # Number of epochs\n",
    "Wstd = 0.4\n",
    "lr = 0.0001\n",
    "width=5000\n",
    "\n",
    "loss_plot5000=setup_and_train(epochs, lr, 5000, Wstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e026ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =2000 #2000      # Number of epochs\n",
    "Wstd = 0.4\n",
    "lr = 0.0001\n",
    "\n",
    "width=3000\n",
    "loss_plot3000=setup_and_train(epochs, lr, 3000, Wstd)\n",
    "\n",
    "width=4000\n",
    "loss_plot4000=setup_and_train(epochs, lr, 4000, Wstd)\n",
    "\n",
    "width=5000\n",
    "loss_plot5000=setup_and_train(epochs, lr, 5000, Wstd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6f95d3a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(range(epochs), loss_plot3000,'r--',marker='>',markevery=500)\n",
    "plt.plot(range(epochs), loss_plot4000,'b-',marker='o',markevery=500)\n",
    "plt.plot(range(epochs), loss_plot5000,'m-.',marker='<',markevery=500)\n",
    "\n",
    "plt.xlabel(r'$\\tau$')\n",
    "plt.ylabel(r'$\\log(\\Phi(\\tau))$')\n",
    "plt.legend(['m=3000','m=4000','m=5000'])\n",
    "plt.axis([0,2000,70,110])\n",
    "plt.savefig('code_DEM_CIFAR10.pdf') \n",
    "plt.savefig('code_DEM_CIFAR10.eps') \n",
    "plt.grid(color='k', linestyle='--', linewidth=.05)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f369c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetReLU(nn.Module):\n",
    "    def __init__(self, width,Wstd):\n",
    "        super(Net, self).__init__()\n",
    "        self.wmatrix=nn.Linear(width,width)\n",
    "        torch.nn.init.normal_(self.wmatrix.weight, mean=0, std=Wstd)   #nn.normal的参数中std是标准差 正态分布N(u,d^2)  方差为d^2,标准差为d，\n",
    "\n",
    "\n",
    "    def forward(self, z, x):\n",
    "        y = F.relu(self.wmatrix(z)+x) * (math.sqrt(1 / width))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "620d8ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_train_ReLU(epochs, lr, width, Wstd):\n",
    "    ######################################################################\n",
    "    # Model setup\n",
    "    f = NetReLU(width, Wstd)\n",
    "    linear_input = nn.Linear(1 *  28 * 28, width)\n",
    "    linear_output = nn.Linear(width, output_size)\n",
    "    torch.nn.init.normal_(linear_input.weight, mean=0, std=1)\n",
    "    torch.nn.init.normal_(linear_output.weight, mean=0, std=1)\n",
    "    model = nn.Sequential(linear_input,\n",
    "                          DEQFixedPoint(f, FPiter, tol=1e-2, max_iter=25),\n",
    "                          linear_output).to(device)\n",
    "    model.to(device);\n",
    "    newmodel = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "    ######################################################################\n",
    "    # Define criterion and optimizer\n",
    "    criterion = torch.nn.MSELoss(reduce=True, size_average=False)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.0)\n",
    "\n",
    "  \n",
    "    ###################################2###################################\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    loss_plot=[]\n",
    "    \n",
    "  \n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        epoch_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        log_interval = 100\n",
    "        train_acc = 0.0\n",
    "        for batch, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            if hasattr(torch.cuda, 'empty_cache'):\n",
    "               torch.cuda.empty_cache()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            outVector=newmodel(inputs)\n",
    "            if width <1000:\n",
    "               matrixA = torch.mm(outVector.T, outVector)\n",
    "            else:\n",
    "               matrixA = torch.mm(outVector, outVector.T)\n",
    "            (lambdamin,lambdaVec) = torch.linalg.eig(matrixA)\n",
    "            print(\"lambda_min\", lambdamin[-1])\n",
    "            WMatrix = f.wmatrix.weight * (math.sqrt(1 / width))\n",
    "            matrixA = torch.mm(WMatrix.T, WMatrix)\n",
    "            (singmax, singularVec) = torch.linalg.eig(matrixA)\n",
    "            print(\"singular_max\", torch.sqrt(singmax[0]))\n",
    "\n",
    "            loss= criterion(outputs.reshape(labels.shape),labels.float())\n",
    "            if hasattr(torch.cuda, 'empty_cache'): \n",
    "               torch.cuda.empty_cache()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        cur_loss = running_loss / (batch + 1)\n",
    "        print('| end of epoch {:3d} | time / epoch {:5.2f}s | loss {:5.2f} '.format\n",
    "              (epoch + 1, (time.time() - epoch_start_time), cur_loss))\n",
    "        loss_plot.append(cur_loss)  \n",
    "        running_loss = 0.\n",
    "    return loss_plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b383eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =2000 #2000      # Number of epochs\n",
    "Wstd = 0.4\n",
    "lr = 0.0001\n",
    "width=3000\n",
    "\n",
    "\n",
    "loss_plot3000ReLU=setup_and_train(epochs, lr, 3000, Wstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8dad3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetTANH(nn.Module):\n",
    "    def __init__(self, width,Wstd):\n",
    "        super(Net, self).__init__()\n",
    "        self.wmatrix=nn.Linear(width,width)\n",
    "        torch.nn.init.normal_(self.wmatrix.weight, mean=0, std=Wstd)   \n",
    "\n",
    "\n",
    "    def forward(self, z, x):\n",
    "        y = F.tanh(self.wmatrix(z)+x) * (math.sqrt(1 / width))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "14214e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_train_ReLU(epochs, lr, width, Wstd):\n",
    "    ######################################################################\n",
    "    # Model setup\n",
    "    f = NetTANH(width, Wstd)\n",
    "    linear_input = nn.Linear(1 *  28 * 28, width)\n",
    "    linear_output = nn.Linear(width, output_size)\n",
    "    torch.nn.init.normal_(linear_input.weight, mean=0, std=1)\n",
    "    torch.nn.init.normal_(linear_output.weight, mean=0, std=1)\n",
    "    model = nn.Sequential(linear_input,\n",
    "                          DEQFixedPoint(f, FPiter, tol=1e-2, max_iter=25),\n",
    "                          linear_output).to(device)\n",
    "    model.to(device);\n",
    "    newmodel = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "    ######################################################################\n",
    "    # Define criterion and optimizer\n",
    "    criterion = torch.nn.MSELoss(reduce=True, size_average=False)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.0)\n",
    "\n",
    "  \n",
    "    ###################################2###################################\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    loss_plot=[]\n",
    "    \n",
    "  \n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        epoch_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        log_interval = 100\n",
    "        train_acc = 0.0\n",
    "        for batch, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            if hasattr(torch.cuda, 'empty_cache'):\n",
    "               torch.cuda.empty_cache()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            outVector=newmodel(inputs)\n",
    "            if width <1000:\n",
    "               matrixA = torch.mm(outVector.T, outVector)\n",
    "            else:\n",
    "               matrixA = torch.mm(outVector, outVector.T)\n",
    "            (lambdamin,lambdaVec) = torch.linalg.eig(matrixA)\n",
    "            print(\"lambda_min\", lambdamin[-1])\n",
    "            WMatrix = f.wmatrix.weight * (math.sqrt(1 / width))\n",
    "            matrixA = torch.mm(WMatrix.T, WMatrix)\n",
    "            (singmax, singularVec) = torch.linalg.eig(matrixA)\n",
    "            print(\"singular_max\", torch.sqrt(singmax[0]))\n",
    "\n",
    "            loss= criterion(outputs.reshape(labels.shape),labels.float())\n",
    "            if hasattr(torch.cuda, 'empty_cache'): \n",
    "               torch.cuda.empty_cache()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        cur_loss = running_loss / (batch + 1)\n",
    "        print('| end of epoch {:3d} | time / epoch {:5.2f}s | loss {:5.2f} '.format\n",
    "              (epoch + 1, (time.time() - epoch_start_time), cur_loss))\n",
    "        loss_plot.append(cur_loss)  \n",
    "        running_loss = 0.\n",
    "    return loss_plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a0e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =2000 #2000      # Number of epochs\n",
    "Wstd = 0.4\n",
    "lr = 0.0001\n",
    "width=3000\n",
    "\n",
    "\n",
    "loss_plot3000tanh=setup_and_train(epochs, lr, 3000, Wstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "816be4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2)\n",
    "plt.plot(range(epochs), loss_plot3000ReLU,'r--',marker='>',markevery=500)\n",
    "plt.plot(range(epochs), loss_plot3000,'b-',marker='o',markevery=500)\n",
    "plt.plot(range(epochs), loss_plot3000tanh,'m-.',marker='<',markevery=500)\n",
    "\n",
    "plt.xlabel(r'$\\tau$')\n",
    "plt.ylabel(r'$\\log(\\Phi(\\tau))$')\n",
    "plt.legend(['ReLU','Sigmoid','Tanh'])\n",
    "plt.savefig('L2loss_mnist_'+str(width)+'_'+str(Wstd)+'.png')\n",
    "plt.axis([0,2000,80,110])\n",
    "plt.savefig('code_DEM_comp_cifar.pdf') \n",
    "plt.savefig('code_DEM_comp_cifar.eps') \n",
    "plt.grid(color='k', linestyle='--', linewidth=.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
